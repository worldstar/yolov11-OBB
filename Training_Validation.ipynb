{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: supervision in ./.local/lib/python3.12/site-packages (0.25.1)\n",
      "Requirement already satisfied: contourpy>=1.0.7 in ./.local/lib/python3.12/site-packages (from supervision) (1.3.2)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from supervision) (0.7.1)\n",
      "Requirement already satisfied: matplotlib>=3.6.0 in ./.local/lib/python3.12/site-packages (from supervision) (3.10.3)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.12/dist-packages (from supervision) (1.26.4)\n",
      "Requirement already satisfied: opencv-python>=4.5.5.64 in ./.local/lib/python3.12/site-packages (from supervision) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=9.4 in ./.local/lib/python3.12/site-packages (from supervision) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.12/dist-packages (from supervision) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.local/lib/python3.12/site-packages (from supervision) (2.28.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from supervision) (1.15.2)\n",
      "Requirement already satisfied: tqdm>=4.62.3 in ./.local/lib/python3.12/site-packages (from supervision) (4.65.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.12/site-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.12/site-packages (from matplotlib>=3.6.0->supervision) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.12/site-packages (from matplotlib>=3.6.0->supervision) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.12/site-packages (from matplotlib>=3.6.0->supervision) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.6.0->supervision) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.12/site-packages (from requests>=2.26.0->supervision) (3.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.local/lib/python3.12/site-packages (from requests>=2.26.0->supervision) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->supervision) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: ultralytics 8.3.165\n",
      "Uninstalling ultralytics-8.3.165:\n",
      "  Successfully uninstalled ultralytics-8.3.165\n",
      "fatal: destination path 'yolo_alternative_loss_functions' already exists and is not an empty directory.\n",
      "/home/u3618315/yolo_alternative_loss_functions\n",
      "Obtaining file:///home/u3618315/yolo_alternative_loss_functions\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.165) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (3.10.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.165) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (2.28.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.165) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (4.65.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.165) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.165) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/u3618315/.local/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/u3618315/.local/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/u3618315/.local/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/u3618315/.local/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/u3618315/.local/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics==8.3.165) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics==8.3.165) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.3.165) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.3.165) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/u3618315/.local/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics==8.3.165) (3.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/u3618315/.local/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics==8.3.165) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.3.165) (2025.4.26)\n",
      "Requirement already satisfied: filelock in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.165) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.165) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.165) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.165) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/u3618315/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics==8.3.165) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.3.165) (3.0.2)\n",
      "Building wheels for collected packages: ultralytics\n",
      "  Building editable for ultralytics (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ultralytics: filename=ultralytics-8.3.165-0.editable-py3-none-any.whl size=23171 sha256=34fbecb2b09a8d4099f2b8c4843f7d23943eee2604b25a7fce3bb506161f0d1a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tigm9fbb/wheels/d9/3f/4c/d6fa4a9d1dd83a906739c6a40087987e4a534b5f64edee3348\n",
      "Successfully built ultralytics\n",
      "Installing collected packages: ultralytics\n",
      "Successfully installed ultralytics-8.3.165\n"
     ]
    }
   ],
   "source": [
    "j = 0 #switch j between 0 & 1 to run this block twice\n",
    "for i in range (j,2): #switch j between 0 & 1\n",
    "    if i == 0:\n",
    "        !pip uninstall ultralytics -y\n",
    "        !git clone https://github.com/Suppersine/yolo_alternative_loss_functions.git\n",
    "    %cd yolo_alternative_loss_functions\n",
    "    !pip install -e .\n",
    "    \n",
    "    \n",
    "    if i == 0:\n",
    "        import os\n",
    "        os.kill(os.getpid(), 9)  # This will restart the runtime\n",
    "    else:\n",
    "        import sys\n",
    "        sys.path.insert(0, '/home/u3618315/yolo_alternative_loss_functions')\n",
    "        \n",
    "        # Now you can import ultralytics modules\n",
    "        import ultralytics\n",
    "        from ultralytics import YOLO\n",
    "        print(ultralytics.__file__)  # Should point to your cloned directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u3618315/yolo_alternative_loss_functions\n",
      "Select a loss/IoU mode:\n",
      "1. GBB\n",
      "2. CSL\n",
      "3. KLD_none\n",
      "4. KLD_sqrt\n",
      "5. KLD_ln\n",
      "6. KLD_exp\n",
      "7. KLD_neg_exp\n",
      "8. KFIOU_dflt\n",
      "9. KFIOU_ln\n",
      "10. KFIOU_exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number corresponding to your choice (default: GBB):  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KLD_exp loss/IoU mode selected\n",
      "Variable saved to datacar.pkl\n"
     ]
    }
   ],
   "source": [
    "#Extracted from picklesave.py, always run this first in the 2nd iteration (i=1) in the next block below, because the loss.py file needs to load the saved .pkl data.\n",
    "%cd yolo_alternative_loss_functions\n",
    "import pickle\n",
    "\n",
    "# List of available modes\n",
    "modes = [\"GBB\", \"CSL\", \"KLD_none\", \"KLD_sqrt\", \"KLD_ln\", \"KLD_exp\", \"KLD_neg_exp\", \"KFIOU_dflt\", \"KFIOU_ln\", \"KFIOU_exp\"]\n",
    "\n",
    "# Default mode\n",
    "mode = 'GBB'\n",
    "\n",
    "print(\"Select a loss/IoU mode:\")\n",
    "for i, m in enumerate(modes):\n",
    "    print(f\"{i+1}. {m}\")\n",
    "\n",
    "try:\n",
    "    user_input = input(f\"Enter the number corresponding to your choice (default: {mode}): \")\n",
    "\n",
    "    if user_input.strip(): # Check if the input is not empty\n",
    "        selected_index = int(user_input) - 1 # Convert to 0-based index\n",
    "        if 0 <= selected_index < len(modes):\n",
    "            mode = modes[selected_index]\n",
    "        else:\n",
    "            print(f\"Invalid number. Sticking with default mode: {mode}\")\n",
    "    else:\n",
    "        print(f\"No input provided. Sticking with default mode: {mode}\")\n",
    "\n",
    "except ValueError:\n",
    "    print(f\"Invalid input. Please enter a number. Sticking with default mode: {mode}\")\n",
    "\n",
    "print(f\"{mode} loss/IoU mode selected\")\n",
    "\n",
    "# Assign the selected mode (as a string) to myvar\n",
    "myvar = mode\n",
    "\n",
    "with open(\"datacar.pkl\", \"wb\") as f:\n",
    "    pickle.dump(myvar, f)\n",
    "\n",
    "print(\"Variable saved to datacar.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'yolo_alternative_loss_functions'\n",
      "/home/u3618315/yolo_alternative_loss_functions\n",
      "Obtaining file:///home/u3618315/yolo_alternative_loss_functions\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.165) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (3.10.3)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (11.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.165) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (2.28.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.165) (1.15.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (2.6.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (0.21.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (4.65.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.165) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.12/dist-packages (from ultralytics==8.3.165) (2.2.3)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in /home/u3618315/.local/lib/python3.12/site-packages (from ultralytics==8.3.165) (2.0.14)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/u3618315/.local/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/u3618315/.local/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/u3618315/.local/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/u3618315/.local/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/u3618315/.local/lib/python3.12/site-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics==8.3.165) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics==8.3.165) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.1.4->ultralytics==8.3.165) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics==8.3.165) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.3.165) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/u3618315/.local/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics==8.3.165) (3.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/u3618315/.local/lib/python3.12/site-packages (from requests>=2.23.0->ultralytics==8.3.165) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics==8.3.165) (2025.4.26)\n",
      "Requirement already satisfied: filelock in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.165) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.165) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.165) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics==8.3.165) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/u3618315/.local/lib/python3.12/site-packages (from torch>=1.8.0->ultralytics==8.3.165) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/u3618315/.local/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics==8.3.165) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics==8.3.165) (3.0.2)\n",
      "Building wheels for collected packages: ultralytics\n",
      "  Building editable for ultralytics (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ultralytics: filename=ultralytics-8.3.165-0.editable-py3-none-any.whl size=23171 sha256=3be6e8b05cf5876746179d09bfcca4b617c33f4ad7d7f3a94eea85e6b3d9e47f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-1w459lrp/wheels/d9/3f/4c/d6fa4a9d1dd83a906739c6a40087987e4a534b5f64edee3348\n",
      "Successfully built ultralytics\n",
      "Installing collected packages: ultralytics\n",
      "  Attempting uninstall: ultralytics\n",
      "    Found existing installation: ultralytics 8.3.165\n",
      "    Uninstalling ultralytics-8.3.165:\n",
      "      Successfully uninstalled ultralytics-8.3.165\n",
      "Successfully installed ultralytics-8.3.165\n",
      "The KLD_exp Loss & IOU mode has been selected\n",
      "/home/u3618315/yolo_alternative_loss_functions/ultralytics/__init__.py\n"
     ]
    }
   ],
   "source": [
    "j = 1 #switch j between 0 & 1 to run this block twice\n",
    "for i in range (j,2): #switch j between 0 & 1\n",
    "    if i == 0:\n",
    "        !pip uninstall ultralytics -y\n",
    "        !git clone https://github.com/Suppersine/yolo_alternative_loss_functions.git\n",
    "    %cd yolo_alternative_loss_functions\n",
    "    !pip install -e .\n",
    "    \n",
    "    \n",
    "    if i == 0:\n",
    "        import os\n",
    "        os.kill(os.getpid(), 9)  # This will restart the runtime\n",
    "    else:\n",
    "        import sys\n",
    "        sys.path.insert(0, '/home/u3618315/yolo_alternative_loss_functions')\n",
    "        \n",
    "        # Now you can import ultralytics modules\n",
    "        import ultralytics\n",
    "        from ultralytics import YOLO\n",
    "        print(ultralytics.__file__)  # Should point to your cloned directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u3618315/yolo_alternative_loss_functions/ultralytics/__init__.py\n"
     ]
    }
   ],
   "source": [
    "#check ultralytics address\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "print(ultralytics.__file__)  # Should point to your cloned directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:\n",
      "    /home/u3618315/.jupyter\n",
      "    /home/u3618315/.local/etc/jupyter\n",
      "    /usr/etc/jupyter\n",
      "    /usr/local/etc/jupyter\n",
      "    /etc/jupyter\n",
      "data:\n",
      "    /home/u3618315/.local/share/jupyter\n",
      "    /usr/local/share/jupyter\n",
      "    /usr/share/jupyter\n",
      "runtime:\n",
      "    /home/u3618315/.local/share/jupyter/runtime\n"
     ]
    }
   ],
   "source": [
    "#once the address checking is done, start training the model with (y)our custom dataset\n",
    "!jupyter --paths\n",
    "\n",
    "filedir = '/home/u3618315/obb_dataset/'\n",
    "yamldir = '/home/u3618315/obb_dataset/datav11.yaml'\n",
    "homedir = '/home/u3618315/'\n",
    "yolodir = '/home/u3618315/yolo_alternative_loss_functions/'\n",
    "\n",
    "#!pip install zip\n",
    "#!sudo apt-get update && apt-get install -y zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The KLD_exp Loss & IOU mode has been selected\n",
      "Ultralytics 8.3.165 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/u3618315/obb_dataset/datav11.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=300, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-obb.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/obb/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=obb, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=15 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    823759  ultralytics.nn.modules.head.OBB              [4, 1, [64, 128, 256]]        \n",
      "YOLOv8n-obb summary: 144 layers, 3,083,295 parameters, 3,083,279 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 391/397 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2391.0Â±580.3 MB/s, size: 183.2 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/u3618315/obb_dataset/train/labels.cache... 1288 images, 3 \u001b[0m\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1534.2Â±944.0 MB/s, size: 215.7 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/u3618315/obb_dataset/val/labels.cache... 184 images, 1 backg\u001b[0m\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Plotting labels to runs/obb/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/obb/train\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/300      2.38G -1.802e+04       4.84      4.842         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0325     0.0229     0.0207    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/300      2.39G -1.109e+05      4.068      8.139         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229   0.000604    0.00229   0.000307   3.07e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/300      2.41G -1.336e+05      3.463      13.18         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/300      2.43G -1.444e+05      3.269      19.47         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00424     0.0183    0.00306   0.000485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/300      2.43G -1.468e+05      3.261      20.28          8        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/300      2.45G -1.406e+05      4.074      20.41         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/300      2.45G -1.346e+05      3.442      21.52         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/300      2.45G -1.315e+05      3.051      20.48         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/300      2.45G -1.243e+05      3.251      19.61         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/300      2.45G -1.143e+05      2.687      19.31         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/300      2.45G -1.169e+05       2.51      19.21         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/300      2.45G -1.205e+05      2.512      19.06         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.254     0.0122    0.00308   0.000616\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/300      2.45G -1.171e+05      2.381       18.8         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00397     0.0122    0.00255   0.000439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/300      2.46G -1.136e+05      2.319      18.83         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00515     0.0061    0.00361   0.000722\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/300      2.46G -1.105e+05      2.343      18.71         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00633     0.0122    0.00158   0.000317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/300      2.46G -1.032e+05      2.346       18.5         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0106     0.0183    0.00373   0.000643\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/300      2.46G -1.113e+05      2.215      18.64         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00682     0.0061    0.00256   0.000512\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/300      2.46G -1.042e+05      2.179      18.58         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0146     0.0061    0.00827    0.00165\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/300      2.46G -1.126e+05      2.132      18.63         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0754     0.0183     0.0125    0.00249\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/300      2.46G -1.084e+05      2.072      18.44         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0617     0.0122      0.011     0.0022\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/300      2.46G -1.019e+05       2.08      18.56         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0165     0.0183    0.00547    0.00109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/300      2.46G -1.116e+05      2.051      18.35         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.014     0.0183    0.00302   0.000603\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/300      2.46G -1.202e+05       2.02      18.66         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0454     0.0183    0.00966    0.00193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/300      2.46G   -1.1e+05      1.937      18.51         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0289     0.0183    0.00744    0.00149\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/300      2.46G -1.192e+05      1.951      18.53         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.079     0.0183     0.0194    0.00387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/300      2.46G -1.025e+05      1.868      18.37         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0067     0.0183    0.00384   0.000768\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/300      2.46G -1.088e+05      1.823       18.4         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0165     0.0122    0.00626    0.00125\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/300      2.46G -1.158e+05      1.852       18.4         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0151     0.0183    0.00526    0.00105\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/300      2.46G   -1.1e+05      1.822      18.44         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0294     0.0183    0.00619    0.00124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/300      2.46G -1.087e+05      1.754      18.28         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.031     0.0183     0.0108    0.00243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/300      2.46G -1.071e+05      1.772      18.24         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0474     0.0183     0.0174    0.00348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/300      2.46G   -1.1e+05      1.739      18.26         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0209     0.0183     0.0124    0.00248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/300      2.46G -1.085e+05       1.74       18.2         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.475     0.0183     0.0225    0.00449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/300      2.46G -1.068e+05        1.7      18.09         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0629     0.0183     0.0192    0.00383\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/300      2.46G -1.082e+05      1.661      18.22         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.714     0.0183     0.0225    0.00495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/300      2.46G -1.139e+05      1.686      18.23         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.025     0.0183      0.014     0.0028\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/300      2.46G -1.075e+05      1.641      18.14         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.311     0.0183     0.0184    0.00413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/300      2.46G -1.148e+05      1.631      18.15         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.476     0.0183     0.0239    0.00559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/300      2.46G -1.113e+05      1.647      18.19         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.725     0.0183      0.023     0.0046\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/300      2.46G  -1.08e+05      1.631      18.06         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0953     0.0183      0.021    0.00501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/300      2.46G -1.133e+05      1.633      18.17         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.657     0.0183      0.021     0.0042\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/300      2.46G -1.055e+05      1.608      18.13         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183      0.023    0.00459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/300      2.46G  -1.16e+05       1.59      18.05         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0247    0.00494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/300      2.46G -1.151e+05      1.586      18.15         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0229    0.00457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/300      2.46G -1.049e+05      1.573      18.03         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.75     0.0178     0.0239    0.00478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/300      2.46G -1.095e+05      1.559      18.11         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183      0.025    0.00501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/300      2.46G -1.142e+05      1.584      18.19         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.977     0.0122     0.0165    0.00331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/300      2.46G -1.156e+05      1.598      18.21         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.326     0.0183     0.0206    0.00411\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/300      2.46G -1.089e+05      1.552       18.1         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0239    0.00478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/300      2.46G -1.064e+05      1.562      17.99         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0238    0.00557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/300      2.46G -1.056e+05      1.573      18.06         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0238    0.00475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/300      2.46G -1.083e+05      1.574      18.05         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.394     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/300      2.46G -1.016e+05      1.579      18.09         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.989     0.0183     0.0223    0.00446\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/300      2.46G -1.068e+05      1.545         18         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0234    0.00467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/300      2.46G -1.135e+05      1.516         18         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.727     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/300      2.46G -1.177e+05      1.513      18.06         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0234    0.00467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/300      2.46G -1.015e+05      1.522      17.95         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183     0.0242    0.00483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/300      2.46G -1.084e+05      1.507      17.93         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0246    0.00492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/300      2.46G -1.083e+05      1.515      17.97         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0231    0.00509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/300      2.46G -1.098e+05      1.526      18.05         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.105     0.0183     0.0228     0.0054\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/300      2.46G  -1.09e+05      1.503      18.04         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.703     0.0183     0.0231    0.00541\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/300      2.46G -1.078e+05      1.494      17.99         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.992     0.0183     0.0249    0.00583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/300      2.46G -1.138e+05      1.506      18.11         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.186     0.0183     0.0236    0.00473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/300      2.46G -1.177e+05      1.501      17.99         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0245    0.00573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/300      2.46G -1.044e+05      1.494      17.94         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0249    0.00583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/300      2.46G -1.169e+05      1.499      18.04         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.977     0.0183     0.0247    0.00494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/300      2.46G -1.118e+05      1.504      18.02         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0575     0.0183     0.0211    0.00511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/300      2.46G -1.088e+05      1.497      17.99         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0236    0.00551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/300      2.46G -1.055e+05      1.482      17.91         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.978     0.0183      0.024    0.00561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/300      2.46G -1.146e+05       1.47      17.98         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/300      2.46G -1.092e+05      1.474      18.02         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.728     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/300      2.46G -1.183e+05      1.485      17.96         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183      0.025    0.00501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/300      2.46G -1.162e+05      1.489      18.07         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183      0.023    0.00538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/300      2.46G -1.132e+05      1.495      18.01         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0235    0.00549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/300      2.46G -1.032e+05      1.466      17.92         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0246    0.00492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     76/300      2.46G -1.056e+05      1.457      17.95         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0239    0.00559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     77/300      2.46G -1.139e+05      1.453      17.89         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.979     0.0183     0.0242    0.00485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     78/300      2.46G -1.104e+05      1.448      17.86         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0248    0.00549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     79/300      2.46G -1.081e+05      1.422      17.82         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.48     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     80/300      2.46G -1.164e+05       1.44      17.95         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.989     0.0183     0.0238    0.00555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     81/300      2.46G -1.077e+05      1.458       17.9         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     82/300      2.46G -1.116e+05      1.432      17.93         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0239    0.00478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     83/300      2.46G -1.132e+05      1.454      17.92         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     84/300      2.46G -1.099e+05      1.446      17.84         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0245    0.00573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     85/300      2.46G -1.094e+05      1.448      17.92         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0242    0.00533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     86/300      2.46G -1.076e+05      1.436      17.84         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.989     0.0183     0.0253    0.00549\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     87/300      2.46G  -1.22e+05      1.448      17.96         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     88/300      2.46G -1.132e+05      1.438      17.98         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.727     0.0183     0.0252    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     89/300      2.46G -1.094e+05      1.429      17.87         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0239    0.00517\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     90/300      2.47G -1.126e+05      1.451      17.88         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     91/300      2.48G -1.048e+05      1.426      17.84         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0247    0.00578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     92/300      2.48G -1.137e+05      1.415      17.82         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.722     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     93/300      2.48G -1.041e+05      1.429      17.78         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.472     0.0183     0.0249    0.00583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     94/300      2.48G -1.046e+05      1.427      17.82         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0122     0.0194    0.00478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     95/300      2.48G -1.168e+05      1.435       17.9         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.976     0.0183     0.0252    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     96/300      2.48G -1.092e+05      1.416      17.77         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.978     0.0183     0.0246    0.00575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     97/300      2.48G -1.111e+05      1.425      17.85         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.468     0.0183     0.0252    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     98/300      2.48G  -1.04e+05      1.389      17.71         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0245    0.00573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     99/300      2.48G -1.155e+05      1.436      17.96         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0245    0.00573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    100/300      2.48G -1.018e+05        1.4      17.74         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0373     0.0183     0.0201    0.00402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    101/300      2.48G -1.088e+05      1.423      17.83         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.722     0.0183     0.0236    0.00552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    102/300      2.48G -1.088e+05       1.41      17.88         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    103/300      2.48G -1.115e+05      1.405      17.89         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.723     0.0183     0.0246    0.00575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    104/300      2.48G -1.068e+05      1.398      17.82         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.472     0.0183     0.0246    0.00575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    105/300      2.48G -1.068e+05      1.404      17.79         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.721     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    106/300      2.48G -1.109e+05      1.409      17.84         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183      0.025    0.00501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    107/300      2.48G -1.097e+05      1.408      17.84         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.725     0.0183     0.0252    0.00503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    108/300      2.48G -1.073e+05      1.408      17.82         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    109/300      2.48G -1.153e+05      1.418      17.86         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.99     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    110/300      2.48G -1.096e+05      1.403      17.87         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    111/300      2.48G -1.118e+05      1.387      17.81         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    112/300      2.48G -1.111e+05      1.417      17.85         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    113/300      2.48G -1.062e+05      1.378       17.7         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    114/300      2.48G -1.115e+05      1.397      17.82         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    115/300      2.48G -1.052e+05      1.369      17.74         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    116/300      2.48G  -1.13e+05      1.384      17.77         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    117/300      2.48G   -1.1e+05      1.405      17.79         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    118/300      2.48G -1.106e+05      1.379      17.72         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    119/300      2.48G -1.064e+05      1.381      17.78         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0247    0.00578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    120/300      2.48G -1.087e+05      1.377      17.71         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183      0.025    0.00586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    121/300      2.48G -1.199e+05      1.391      17.83         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    122/300      2.48G -1.086e+05      1.398      17.76         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0249    0.00583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    123/300      2.48G   -1.1e+05      1.364      17.78         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0249    0.00499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    124/300      2.48G -1.059e+05      1.378      17.76         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    125/300      2.48G -9.904e+04      1.362      17.65         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    126/300      2.48G -1.034e+05      1.381      17.72         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0252    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    127/300      2.48G -1.179e+05      1.396      17.87         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.729     0.0183     0.0249    0.00583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    128/300      2.48G -1.088e+05      1.388      17.78         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    129/300      2.48G -1.036e+05       1.38      17.71         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0247    0.00578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    130/300      2.48G -1.079e+05       1.39      17.75         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0252    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    131/300      2.48G -1.132e+05      1.371      17.82         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    132/300      2.48G -1.189e+05      1.365      17.77         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    133/300      2.48G -1.142e+05      1.367      17.78         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    134/300      2.48G -1.094e+05      1.367      17.73         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.475     0.0183     0.0248    0.00496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    135/300      2.48G -1.137e+05      1.387      17.77         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.977     0.0183     0.0252    0.00503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    136/300      2.48G -1.119e+05      1.381      17.71         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    137/300      2.48G -1.112e+05      1.371      17.71         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    138/300      2.48G -1.076e+05      1.365      17.68         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    139/300      2.48G -1.124e+05      1.373      17.76         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    140/300      2.48G -1.033e+05      1.369      17.63         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0248     0.0058\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    141/300      2.48G -1.132e+05      1.392      17.81         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    142/300      2.48G -1.115e+05      1.366      17.67         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    143/300      2.48G -1.136e+05      1.367      17.71         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    144/300      2.48G -1.126e+05      1.361      17.66         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    145/300      2.48G -1.108e+05      1.358      17.65         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.232     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    146/300      2.48G  -1.02e+05      1.349      17.66         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    147/300      2.48G -1.114e+05      1.355       17.7         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.472     0.0183     0.0266    0.00623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    148/300      2.48G -1.125e+05      1.368       17.7         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.73     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    149/300      2.48G -1.176e+05      1.357      17.72         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    150/300      2.48G -1.136e+05      1.376       17.8         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    151/300      2.48G -1.241e+05      1.356      17.78         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    152/300      2.48G -1.088e+05      1.364      17.67         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0266    0.00623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    153/300      2.48G -1.159e+05      1.354      17.76         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    154/300      2.48G -1.076e+05      1.351      17.69         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    155/300      2.48G -1.039e+05      1.342      17.63         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    156/300      2.48G -1.163e+05      1.352      17.72         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0266    0.00623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    157/300      2.48G -1.134e+05      1.354      17.61         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.729     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    158/300      2.48G -1.123e+05      1.351      17.75         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    159/300      2.48G -1.124e+05      1.356       17.7         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0266    0.00532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    160/300      2.48G -1.114e+05      1.349      17.68         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    161/300      2.48G -1.124e+05      1.356      17.69         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    162/300      2.48G -1.058e+05      1.331       17.6         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0266    0.00623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    163/300      2.48G -1.114e+05      1.342      17.63         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    164/300      2.48G  -1.13e+05      1.356      17.75         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    165/300      2.48G -1.166e+05      1.357      17.78         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0394     0.0183     0.0211     0.0051\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    166/300      2.48G -1.154e+05      1.345      17.69         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0264    0.00587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    167/300      2.48G -1.085e+05      1.341      17.65         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0268    0.00536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    168/300      2.48G -1.113e+05      1.335      17.56         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0266    0.00532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    169/300      2.48G -1.047e+05      1.344      17.55         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    170/300      2.48G -1.084e+05      1.334      17.66         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    171/300      2.48G -1.122e+05      1.336      17.58         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    172/300      2.48G -1.164e+05      1.342      17.68         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    173/300      2.48G -1.186e+05      1.332      17.62         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    174/300      2.48G  -1.06e+05       1.34      17.61         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    175/300      2.48G -1.121e+05      1.341      17.65         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    176/300      2.48G -1.202e+05      1.352       17.8         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    177/300      2.48G -1.118e+05      1.345      17.63         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    178/300      2.48G -1.182e+05      1.347      17.75         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    179/300      2.48G -1.051e+05      1.329      17.57         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.728     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    180/300      2.48G -1.085e+05      1.321      17.52         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    181/300      2.48G -1.063e+05      1.337       17.6         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    182/300      2.48G  -1.15e+05      1.323      17.54         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    183/300      2.48G -1.058e+05      1.325      17.64         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0266    0.00623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    184/300      2.48G -1.067e+05      1.317       17.5         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    185/300      2.48G -1.013e+05       1.32       17.5         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.477     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    186/300      2.48G -1.151e+05      1.333      17.61         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.729     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    187/300      2.48G -1.191e+05      1.331       17.6         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    188/300      2.48G -1.138e+05       1.33      17.66         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    189/300      2.48G -1.144e+05       1.33      17.55         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0266    0.00623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    190/300      2.48G -1.105e+05      1.322      17.58         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    191/300      2.48G -1.144e+05      1.342      17.67         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0266    0.00623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    192/300      2.48G -1.123e+05      1.339      17.63         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    193/300      2.48G  -1.12e+05      1.327      17.52         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    194/300      2.48G -1.158e+05      1.339       17.7         30        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    195/300      2.48G -1.168e+05      1.341      17.71         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.725     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    196/300      2.48G -1.075e+05      1.318      17.53         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.728     0.0183     0.0266    0.00623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    197/300      2.48G -1.088e+05      1.321      17.57         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    198/300      2.48G -1.124e+05      1.326      17.63         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0266    0.00532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    199/300      2.48G -1.215e+05      1.332      17.66         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0266    0.00623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    200/300      2.48G -1.092e+05      1.328      17.55         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    201/300      2.48G -1.092e+05      1.327      17.58         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    202/300      2.48G -1.034e+05      1.315      17.55         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    203/300      2.48G -1.115e+05      1.332      17.61         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    204/300      2.48G -1.194e+05      1.334      17.61         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.976     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    205/300      2.48G -1.058e+05      1.308      17.51         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    206/300      2.48G -1.079e+05      1.312      17.49         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.73     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    207/300      2.48G -1.189e+05      1.302      17.44         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    208/300      2.48G -1.186e+05        1.3      17.47         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0122     0.0212    0.00518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    209/300      2.48G -1.158e+05      1.323      17.61         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    210/300      2.48G -1.168e+05      1.319      17.55         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.727     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    211/300      2.48G -1.115e+05      1.306      17.45          9        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    212/300      2.48G -1.222e+05      1.313      17.56         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.729     0.0183     0.0276    0.00646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    213/300      2.48G -1.124e+05      1.324      17.55         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    214/300      2.48G -1.081e+05      1.327      17.56         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    215/300      2.48G -1.107e+05      1.327      17.57         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.48     0.0183      0.027      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    216/300      2.48G -1.173e+05      1.328      17.63         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0268    0.00596\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    217/300      2.48G -1.192e+05      1.319      17.58         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    218/300      2.48G -1.236e+05      1.317      17.52         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.483     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    219/300      2.48G -1.141e+05      1.317      17.53         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    220/300      2.48G  -1.11e+05      1.315      17.59         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0272    0.00544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    221/300      2.48G -1.114e+05      1.301      17.47         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.73     0.0183     0.0279    0.00652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    222/300      2.48G -1.117e+05      1.306      17.56         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.728     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    223/300      2.48G -1.075e+05      1.313      17.58         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.725     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    224/300      2.48G -1.152e+05      1.303      17.51         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.471     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    225/300      2.48G -1.109e+05      1.319      17.53         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183     0.0268    0.00536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    226/300      2.48G -1.093e+05      1.305      17.57         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.473     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    227/300      2.48G -1.141e+05      1.318      17.53         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.231     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    228/300      2.48G -1.161e+05      1.313      17.63         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    229/300      2.48G -1.156e+05      1.319      17.55         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    230/300      2.48G -1.112e+05      1.312      17.52          8        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.475     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    231/300      2.48G -1.088e+05      1.309      17.55         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.476     0.0183     0.0268    0.00627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    232/300      2.48G -1.224e+05      1.314      17.57         32        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.474     0.0183     0.0266    0.00623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    233/300      2.48G -1.076e+05      1.301      17.48         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0281    0.00658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    234/300      2.48G -1.091e+05      1.309      17.54         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    235/300      2.48G -1.135e+05      1.318      17.58         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    236/300      2.48G -1.095e+05      1.308      17.53         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.73     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    237/300      2.48G -1.104e+05      1.312      17.49         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.73     0.0183     0.0268    0.00527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    238/300      2.48G -1.089e+05      1.307      17.46         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183      0.027    0.00531\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    239/300      2.48G -1.076e+05      1.309      17.49         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.483     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    240/300      2.48G -1.069e+05      1.311      17.45         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    241/300      2.48G -1.167e+05      1.301      17.53         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    242/300      2.48G -1.127e+05      1.298      17.48         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    243/300      2.48G -1.145e+05      1.299      17.52         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.482     0.0183     0.0276    0.00646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    244/300      2.48G -1.084e+05      1.302      17.49         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.482     0.0183     0.0279    0.00557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    245/300      2.48G   -1.1e+05      1.317      17.53         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.483     0.0183     0.0284    0.00664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    246/300      2.48G -1.065e+05      1.298      17.44         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.477     0.0183     0.0276    0.00646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    247/300      2.48G -1.111e+05      1.306      17.46         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0274    0.00548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    248/300      2.48G -1.126e+05      1.304      17.46         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0281    0.00658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    249/300      2.48G -1.078e+05      1.303      17.44         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0274    0.00548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    250/300      2.48G -1.137e+05      1.302      17.49         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    251/300      2.48G -1.123e+05      1.305      17.37         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0274    0.00548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    252/300      2.48G -1.051e+05      1.305      17.51         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.477     0.0183     0.0279    0.00652\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    253/300      2.48G -1.126e+05      1.303      17.51         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0276    0.00544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    254/300      2.48G -1.107e+05      1.299       17.4         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    255/300      2.48G  -1.13e+05      1.304      17.49         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    256/300      2.48G -1.098e+05      1.295      17.43         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0276    0.00646\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    257/300      2.48G  -1.04e+05      1.297      17.38         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    258/300      2.48G -1.172e+05      1.314      17.53         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0274    0.00539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    259/300      2.48G -1.094e+05      1.296       17.5         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    260/300      2.48G -1.139e+05      1.287      17.43         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0276    0.00544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    261/300      2.48G -1.077e+05      1.294      17.42         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    262/300      2.48G -1.111e+05      1.299      17.42         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    263/300      2.48G -1.057e+05       1.29      17.41         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    264/300      2.48G -1.126e+05      1.292      17.44         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    265/300      2.48G -1.129e+05      1.299      17.45         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    266/300      2.48G -1.129e+05      1.286      17.37         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    267/300      2.48G -1.141e+05      1.287      17.37         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    268/300      2.48G -1.113e+05      1.297      17.45         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    269/300      2.48G -1.109e+05      1.294      17.37         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.481     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    270/300      2.48G  -1.08e+05      1.295      17.43         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.482     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    271/300      2.48G -1.092e+05      1.291      17.43         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.483     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    272/300      2.48G  -1.16e+05       1.29      17.41         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.484     0.0183     0.0272    0.00535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    273/300      2.48G  -1.08e+05      1.293      17.43         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0272    0.00535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    274/300      2.48G -1.109e+05      1.294      17.39         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.483     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    275/300      2.48G -1.123e+05      1.302       17.5         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    276/300      2.48G -1.068e+05      1.284      17.36         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    277/300      2.48G   -1.1e+05      1.283      17.36         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.481     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    278/300      2.48G -1.157e+05      1.306      17.47         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.483     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    279/300      2.48G -1.066e+05      1.286      17.39         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    280/300      2.48G -1.118e+05      1.292      17.48         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    281/300      2.48G  -1.17e+05      1.298      17.52         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.48     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    282/300      2.48G -1.065e+05      1.293      17.46         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    283/300      2.48G -1.053e+05      1.284      17.36         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.481     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    284/300      2.48G -1.091e+05      1.297      17.44         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.479     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    285/300      2.48G -1.173e+05      1.298      17.44         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0274    0.00539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    286/300      2.48G -1.111e+05       1.29      17.41         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0274    0.00539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    287/300      2.48G -1.099e+05      1.291      17.44         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.482     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    288/300      2.48G -1.027e+05      1.274      17.26         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.483     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    289/300      2.48G -1.033e+05      1.296      17.47         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.483     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    290/300      2.48G -1.104e+05      1.278      17.35         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.482     0.0183     0.0274    0.00641\n",
      "Closing dataloader mosaic\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    291/300      2.48G -3.492e+04       1.15      15.97          9        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.484     0.0183      0.027    0.00631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    292/300      2.48G -3.258e+04      1.136      15.85         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.483     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    293/300      2.48G -3.506e+04      1.152      15.96         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.483     0.0183     0.0272    0.00636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    294/300      2.48G  -3.36e+04      1.143      15.89         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.481     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    295/300      2.48G -3.518e+04      1.147      15.92         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.477     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    296/300      2.48G -3.503e+04      1.147      15.92         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.477     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    297/300      2.48G -3.446e+04      1.145      15.91         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.477     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    298/300      2.48G -3.469e+04      1.142       15.9         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.478     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    299/300      2.48G -3.442e+04      1.135      15.84         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.478     0.0183     0.0274    0.00641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    300/300      2.48G -3.501e+04      1.142      15.89         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.477     0.0183     0.0274    0.00641\n",
      "\n",
      "300 epochs completed in 0.720 hours.\n",
      "Optimizer stripped from runs/obb/train/weights/last.pt, 6.5MB\n",
      "Optimizer stripped from runs/obb/train/weights/best.pt, 6.5MB\n",
      "\n",
      "Validating runs/obb/train/weights/best.pt...\n",
      "Ultralytics 8.3.165 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "YOLOv8n-obb summary (fused): 81 layers, 3,077,999 parameters, 0 gradients, 8.3 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.483     0.0183     0.0284    0.00664\n",
      "        LCA-brightness         52         54          0          0          0          0\n",
      "        LCA-dilatation        103        109          0          0          0          0\n",
      "        RCA-brightness         25         25          1          0          0          0\n",
      "        RCA-dilatation         41         41      0.933     0.0732      0.113     0.0265\n",
      "Speed: 0.4ms preprocess, 0.9ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/obb/train\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# Load a model (N-submodel)\n",
    "# model = YOLO(\"yolov8n-obb.yaml\")  # build a new model from YAML\n",
    "model = YOLO(\"yolov8n-obb.pt\")  # load a pretrained model (recommended for training)\n",
    "# model = YOLO(\"yolov8n-obb.yaml\").load(\"yolov8n.pt\")  # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "#results = model.train(data=yamldir, epochs=300, imgsz=640)\n",
    "!yolo task=obb mode=train model=yolov8n-obb.pt data={yamldir} epochs=300 imgsz=640 plots=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s-obb.pt to 'yolov8s-obb.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22.2M/22.2M [00:01<00:00, 13.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The KLD_exp Loss & IOU mode has been selected\n",
      "Ultralytics 8.3.165 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/u3618315/obb_dataset/datav11.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=300, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s-obb.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/obb/train2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=obb, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=15 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2403775  ultralytics.nn.modules.head.OBB              [4, 1, [128, 256, 512]]       \n",
      "YOLOv8s-obb summary: 144 layers, 11,423,327 parameters, 11,423,311 gradients, 29.6 GFLOPs\n",
      "\n",
      "Transferred 391/397 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2394.5Â±630.9 MB/s, size: 183.2 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/u3618315/obb_dataset/train/labels.cache... 1288 images, 3 \u001b[0m\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1357.9Â±991.4 MB/s, size: 215.7 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/u3618315/obb_dataset/val/labels.cache... 184 images, 1 backg\u001b[0m\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Plotting labels to runs/obb/train2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/obb/train2\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/300      3.66G -2.877e+04      4.688      5.004         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0184     0.0414     0.0104    0.00216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/300       3.7G -1.349e+05      3.836      10.84         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/300      3.73G -1.343e+05      3.459      16.33         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/300      3.77G   -1.4e+05       3.11       18.5         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/300      3.77G -1.343e+05      3.622      20.94          8        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00162     0.0183   0.000875   8.75e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/300      3.81G -1.253e+05      3.415      20.11         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/300      3.81G -1.123e+05      3.234      19.86         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/300      3.81G -1.164e+05      3.787      18.51         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/300      3.81G -1.115e+05      3.255      20.43         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/300      3.81G -1.095e+05      3.023      19.44         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00229     0.0122    0.00121   0.000121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/300      3.81G  -1.16e+05      2.714      19.29         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.001     0.0061   0.000517   5.17e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/300      3.81G -1.133e+05      2.672      19.31         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229   0.000794     0.0061   0.000409   8.17e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/300      3.81G -1.111e+05       2.59      19.01         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0026     0.0183    0.00142   0.000284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/300      3.84G -1.104e+05      2.546      18.97         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00251     0.0183    0.00142   0.000284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/300      3.84G -1.088e+05      2.453      18.79         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00264     0.0183    0.00144   0.000288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/300      3.84G -1.014e+05      2.368      18.65         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0049     0.0122    0.00256   0.000513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/300      3.84G -1.092e+05      2.252      18.64         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00331     0.0183    0.00161   0.000323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/300      3.84G -1.031e+05      2.257      18.54         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00408     0.0183    0.00224   0.000448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/300      3.84G -1.104e+05      2.232       18.6         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0427     0.0183     0.0106    0.00213\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/300      3.84G -1.074e+05      2.225      18.57         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00366     0.0183    0.00521    0.00104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/300      3.84G -1.005e+05       2.19      18.49         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00247     0.0122    0.00183   0.000366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/300      3.84G -1.107e+05       2.11      18.48         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0172     0.0183     0.0038    0.00076\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/300      3.84G -1.204e+05      2.091      18.63         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0161     0.0183    0.00298   0.000596\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/300      3.88G -1.106e+05      2.066      18.56         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00429     0.0183    0.00207   0.000414\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/300      3.88G -1.195e+05      2.038      18.58         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0207     0.0122    0.00439   0.000878\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/300      3.88G -1.026e+05      1.932      18.35         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00698     0.0183    0.00279   0.000559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/300      3.88G -1.087e+05      1.954      18.45         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00345     0.0122    0.00287   0.000575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/300      3.88G -1.165e+05      2.076      18.42         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00892     0.0183    0.00334   0.000667\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/300      3.88G -1.106e+05      2.132      18.64         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00567     0.0183    0.00294   0.000589\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/300      3.88G -1.091e+05      1.971       18.5         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0157     0.0122    0.00505    0.00101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/300      3.88G -1.075e+05       1.91      18.27         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.053     0.0183     0.0153    0.00307\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/300      3.88G -1.112e+05      1.916      18.46         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0829     0.0183     0.0194    0.00387\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/300      3.88G -1.092e+05      1.913      18.31         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.84     0.0183     0.0136    0.00271\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/300      3.88G -1.078e+05      1.964      18.35         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.276     0.0122    0.00981    0.00196\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/300      3.88G -1.087e+05      1.941      18.36         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0196     0.0183    0.00544    0.00109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/300      3.88G -1.144e+05      1.874      18.38         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0811     0.0183     0.0173    0.00345\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/300      3.88G -1.102e+05      1.799      18.31         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0257     0.0183     0.0124    0.00248\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/300      3.88G -1.156e+05      1.786      18.27         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.095     0.0122     0.0156    0.00312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/300      3.88G -1.146e+05      1.811      18.25         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.685     0.0183     0.0222    0.00445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/300      3.88G -1.082e+05      1.829      18.27         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0735     0.0183     0.0179    0.00358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/300      3.88G  -1.14e+05      1.861      18.36         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00615     0.0183    0.00342   0.000683\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/300      3.88G -1.072e+05      1.854      18.31         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.73     0.0183     0.0217    0.00433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/300      3.88G -1.173e+05      1.864      18.39         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.465     0.0183     0.0207    0.00414\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/300      3.88G -1.173e+05      1.884      18.38         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.829     0.0122      0.012    0.00239\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/300      3.88G  -1.06e+05      1.778      18.22         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.539     0.0122    0.00793    0.00159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/300      3.88G -1.143e+05      1.875       18.3         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0233     0.0183     0.0104    0.00207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/300      3.88G -1.172e+05      1.862      18.42         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0506     0.0183     0.0163    0.00326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/300      3.88G -1.183e+05      1.886      18.49         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00743     0.0183    0.00435    0.00087\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/300      3.88G -1.103e+05      1.853      18.35         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0512     0.0183     0.0156    0.00312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/300      3.88G -1.081e+05      1.831      18.27         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0111     0.0145    0.00412   0.000825\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/300      3.88G -1.098e+05      1.798      18.24         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.673     0.0183     0.0232    0.00465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/300      3.88G -1.111e+05      1.738      18.14         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.462     0.0183     0.0218    0.00437\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/300      3.88G -1.055e+05      1.764      18.21         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0343     0.0183     0.0133    0.00267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/300      3.88G -1.075e+05      1.741      18.21         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.718     0.0183     0.0215     0.0043\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/300      3.88G -1.161e+05      1.821      18.31         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00532     0.0122    0.00294   0.000588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/300      3.88G   -1.2e+05      1.796      18.24         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0101     0.0183    0.00652     0.0013\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/300      3.88G -1.032e+05      1.761      18.15         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0566     0.0122     0.0161    0.00322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/300      3.88G -1.115e+05      1.762      18.17         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.552     0.0183    0.00939    0.00188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/300      3.88G -1.122e+05      1.778       18.2         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0353     0.0122     0.0102    0.00203\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/300      3.88G  -1.12e+05       1.75      18.27         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229        0.6     0.0183     0.0203    0.00407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/300      3.88G -1.102e+05      1.717      18.26         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.313     0.0122     0.0135    0.00347\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/300      3.88G -1.118e+05      1.703      18.24         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.661     0.0183     0.0206    0.00412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/300      3.88G -1.162e+05      1.736      18.32         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.723     0.0183     0.0229    0.00457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/300      3.88G -1.188e+05      1.739      18.26         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.965     0.0183     0.0247    0.00494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/300      3.88G -1.056e+05       1.76      18.19         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.738     0.0183     0.0226    0.00451\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/300      3.88G -1.196e+05      1.743      18.29         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.359     0.0183      0.021     0.0042\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/300      3.88G -1.137e+05      1.684      18.21         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.972     0.0183     0.0232    0.00543\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/300      3.88G -1.099e+05      1.677      18.15         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0248    0.00496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/300      3.88G -1.057e+05      1.697      18.08         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00926     0.0122    0.00578    0.00116\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/300      3.88G -1.148e+05      1.696      18.18         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.632     0.0122     0.0229    0.00458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/300      3.88G -1.102e+05      1.696      18.21         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0285     0.0122     0.0103    0.00206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/300      3.88G -1.214e+05      1.672      18.25         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.602     0.0122     0.0175     0.0035\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/300      3.88G  -1.21e+05      1.687      18.26         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.607     0.0122      0.018     0.0036\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/300      3.88G -1.165e+05      1.661      18.12         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.341     0.0183     0.0213    0.00459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/300      3.88G -1.133e+05      1.656      18.11         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.979     0.0183     0.0242    0.00483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     76/300      3.88G -1.197e+05      1.649      18.16         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.926     0.0061    0.00954    0.00191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     77/300      3.88G -1.264e+05      1.697      18.07         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     78/300      3.88G -1.239e+05      1.676      18.17         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0179     0.0183     0.0156    0.00343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     79/300      3.88G -1.213e+05      1.635      18.11         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0161     0.0122    0.00934    0.00187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     80/300      3.88G -1.295e+05      1.632       18.2         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0172     0.0122     0.0165     0.0033\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     81/300      3.88G -1.222e+05      1.625      18.11         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0242     0.0183     0.0191    0.00382\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     82/300      3.88G -1.268e+05      1.599      18.17         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0156     0.0122    0.00851     0.0017\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     83/300      3.88G -1.316e+05      1.606      18.06         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.642     0.0122     0.0241    0.00524\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     84/300      3.88G -1.324e+05      1.639      18.14         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0125     0.0122     0.0066    0.00132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     85/300      3.88G -1.363e+05      1.613      18.16         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     86/300      3.88G -1.315e+05      1.624      18.03         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0385     0.0122     0.0267    0.00534\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     87/300      3.88G -1.482e+05      1.603      18.19         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0152     0.0122     0.0146    0.00292\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     88/300      3.88G -1.381e+05      1.612      18.19         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0167     0.0061     0.0102    0.00204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     89/300      3.88G -1.364e+05      1.589      18.05         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     90/300      3.88G -1.429e+05      1.601       18.1         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0192     0.0061     0.0101    0.00201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     91/300      3.88G -1.273e+05      1.637      18.07         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     92/300      3.88G -1.401e+05      1.609      18.04         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     93/300      3.88G -1.266e+05      1.613      17.96         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     94/300      3.88G -1.273e+05      1.664      18.11         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     95/300      3.88G -1.418e+05      1.658      18.15         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     96/300      3.88G  -1.35e+05      1.629      18.02         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     97/300      3.88G -1.407e+05      1.639      18.19         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     98/300      3.88G -1.268e+05      1.556      17.96         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     99/300      3.88G -1.452e+05      1.599      18.12         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    100/300      3.88G -1.272e+05       1.55      17.95         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    101/300      3.88G -1.346e+05       1.56      18.05         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0278     0.0061     0.0156    0.00312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    102/300      3.88G -1.331e+05      1.559       18.1         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    103/300      3.88G -1.366e+05      1.548      18.09         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    104/300      3.88G -1.325e+05      1.544         18         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    105/300      3.88G -1.358e+05      1.583      18.05         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    106/300      3.88G -1.429e+05      1.589      18.06         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    107/300      3.88G  -1.32e+05      1.548      18.04         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    108/300      3.88G -1.336e+05       1.54         18         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    109/300      3.88G -1.426e+05      1.565      18.04         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    110/300      3.88G -1.351e+05      1.568      18.09         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    111/300      3.88G -1.389e+05      1.519         18         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    112/300      3.88G -1.353e+05       1.53      18.01         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    113/300      3.88G -1.314e+05      1.535      17.92         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    114/300      3.88G -1.383e+05      1.539      18.05         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    115/300      3.88G -1.302e+05      1.518      17.95         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    116/300      3.88G -1.443e+05      1.513      17.94         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    117/300      3.88G  -1.35e+05      1.536      18.04         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    118/300      3.88G -1.397e+05      1.464      17.91         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    119/300      3.88G -1.317e+05        1.5      17.91         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    120/300      3.88G -1.333e+05      1.515      17.93         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    121/300      3.88G   -1.5e+05      1.511      17.99         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    122/300      3.88G -1.374e+05       1.52      17.96         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    123/300      3.88G -1.368e+05      1.495      17.93         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    124/300      3.88G -1.306e+05      1.489      17.97         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    125/300      3.88G -1.204e+05      1.473      17.83         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    126/300      3.88G -1.266e+05      1.508       17.9         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    127/300      3.88G -1.448e+05      1.517      18.03         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    128/300      3.88G -1.331e+05      1.486      18.01         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    129/300      3.88G -1.252e+05      1.471      17.88         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    130/300      3.88G -1.369e+05      1.507      17.93         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    131/300      3.88G -1.413e+05      1.476      17.96         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    132/300      3.88G -1.477e+05      1.454      17.94         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    133/300      3.88G -1.442e+05      1.502      17.96         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    134/300      3.88G -1.336e+05       1.47      17.91         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    135/300      3.88G -1.432e+05      1.489      17.91         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    136/300      3.88G -1.386e+05      1.476      17.88         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    137/300      3.88G -1.366e+05      1.474      17.91         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    138/300      3.88G -1.396e+05      1.477       17.9         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    139/300      3.88G   -1.4e+05      1.486      17.98         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    140/300      3.88G -1.288e+05      1.468      17.81         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    141/300      3.88G -1.478e+05      1.494      17.96         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    142/300      3.88G -1.349e+05      1.484      17.88         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    143/300      3.88G -1.403e+05      1.482      17.92         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    144/300      3.88G -1.405e+05       1.46      17.88         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    145/300      3.88G  -1.37e+05      1.466      17.85         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    146/300      3.88G -1.256e+05      1.468      17.89         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    147/300      3.88G -1.419e+05       1.48      17.87         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    148/300      3.88G -1.402e+05      1.468       17.9         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    149/300      3.88G -1.474e+05      1.446      17.87         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    150/300      3.88G -1.415e+05       1.48      17.95         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    151/300      3.88G  -1.52e+05      1.456      17.98         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    152/300      3.88G -1.387e+05      1.473      17.84         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    153/300      3.88G -1.451e+05      1.467      17.96         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    154/300      3.88G -1.314e+05       1.46      17.82         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    155/300      3.88G -1.305e+05      1.437      17.78         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    156/300      3.88G -1.448e+05      1.458      17.92         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    157/300      3.88G -1.407e+05       1.45      17.83         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    158/300      3.88G -1.381e+05       1.45      17.93         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    159/300      3.88G -1.373e+05      1.455      17.88         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    160/300      3.88G -1.408e+05       1.47      17.89         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    161/300      3.88G -1.388e+05      1.464      17.93         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    162/300      3.88G -1.292e+05      1.439      17.76         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    163/300      3.88G -1.367e+05       1.46      17.85         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    164/300      3.88G -1.443e+05      1.452      17.87         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    165/300      3.88G -1.432e+05      1.447      17.95         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    166/300      3.88G -1.445e+05      1.447      17.84         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    167/300      3.88G -1.363e+05      1.418      17.85         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    168/300      3.88G -1.381e+05      1.426      17.75         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    169/300      3.88G -1.315e+05      1.432      17.77         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    170/300      3.88G -1.376e+05      1.425      17.85         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    171/300      3.88G -1.396e+05      1.423      17.74         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    172/300      3.88G -1.456e+05      1.428      17.86         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    173/300      3.88G -1.428e+05      1.422      17.82         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    174/300      3.88G -1.289e+05      1.421      17.81         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    175/300      3.88G -1.402e+05      1.421      17.84         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    176/300      3.88G -1.479e+05      1.428      17.96         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    177/300      3.88G -1.479e+05      1.438      17.85         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    178/300      3.88G  -1.48e+05      1.433      17.92         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    179/300      3.88G -1.305e+05      1.394      17.71         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    180/300      3.88G -1.364e+05      1.422      17.73         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    181/300      3.88G -1.306e+05      1.417      17.83         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    182/300      3.88G -1.458e+05      1.405      17.72         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    183/300      3.88G -1.339e+05      1.413      17.81         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    184/300      3.88G -1.332e+05      1.397      17.65         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    185/300      3.88G -1.249e+05       1.39      17.72         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    186/300      3.88G  -1.45e+05      1.409       17.8         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 100 epochs. Best results observed at epoch 86, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=100) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "186 epochs completed in 0.530 hours.\n",
      "Optimizer stripped from runs/obb/train2/weights/last.pt, 23.2MB\n",
      "Optimizer stripped from runs/obb/train2/weights/best.pt, 23.2MB\n",
      "\n",
      "Validating runs/obb/train2/weights/best.pt...\n",
      "Ultralytics 8.3.165 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "YOLOv8s-obb summary (fused): 81 layers, 11,413,119 parameters, 0 gradients, 29.4 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0385     0.0122     0.0267    0.00534\n",
      "        LCA-brightness         52         54          0          0          0          0\n",
      "        LCA-dilatation        103        109          0          0          0          0\n",
      "        RCA-brightness         25         25          0          0          0          0\n",
      "        RCA-dilatation         41         41      0.154     0.0488      0.107     0.0214\n",
      "Speed: 0.2ms preprocess, 1.2ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/obb/train2\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# Load a model (N-submodel)\n",
    "# model = YOLO(\"yolov8n-obb.yaml\")  # build a new model from YAML\n",
    "model = YOLO(\"yolov8s-obb.pt\")  # load a pretrained model (recommended for training)\n",
    "# model = YOLO(\"yolov8n-obb.yaml\").load(\"yolov8n.pt\")  # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "#results = model.train(data=yamldir, epochs=300, imgsz=640)\n",
    "!yolo task=obb mode=train model=yolov8s-obb.pt data={yamldir} epochs=300 imgsz=640 plots=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-obb.pt to 'yolo11n-obb.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.53M/5.53M [00:00<00:00, 14.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The KLD_exp Loss & IOU mode has been selected\n",
      "Ultralytics 8.3.165 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/u3618315/obb_dataset/datav11.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=300, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-obb.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/obb/train3, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=obb, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    503119  ultralytics.nn.modules.head.OBB              [4, 1, [64, 128, 256]]        \n",
      "YOLO11n-obb summary: 196 layers, 2,662,287 parameters, 2,662,271 gradients, 6.7 GFLOPs\n",
      "\n",
      "Transferred 535/541 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2468.8Â±624.7 MB/s, size: 183.2 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/u3618315/obb_dataset/train/labels.cache... 1288 images, 3 \u001b[0m\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1480.7Â±1017.7 MB/s, size: 215.7 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/u3618315/obb_dataset/val/labels.cache... 184 images, 1 backg\u001b[0m\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Plotting labels to runs/obb/train3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 87 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/obb/train3\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/300      2.55G -1.888e+04      5.785      5.142         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/300      2.57G -9.796e+04      4.503      8.461         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/300      2.58G -1.287e+05      3.842      13.53         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/300      2.58G -1.414e+05      3.247      15.87         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/300      2.58G -1.483e+05      2.965      20.89          8        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00365     0.0122    0.00217   0.000317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/300      2.58G -1.432e+05      2.871      22.31         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/300      2.58G -1.429e+05       3.19      20.93         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00198     0.0183    0.00114    0.00015\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/300       2.6G -1.385e+05      2.863      19.81         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/300      2.61G -1.223e+05      2.925      20.68         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00146     0.0122   0.000751   7.51e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/300      2.61G  -1.21e+05      2.799      19.68         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229   0.000552     0.0061   0.000289   2.89e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/300      2.61G -1.253e+05      2.721      19.55         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/300      2.62G -1.209e+05      2.519      19.24         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/300      2.62G -1.137e+05      2.361      19.04         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00207     0.0183    0.00117   0.000191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/300      2.62G -1.105e+05      2.277      18.94         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00295     0.0183    0.00175   0.000285\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/300      2.62G -1.102e+05      2.181      18.92         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00429     0.0183    0.00233   0.000366\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/300      2.62G  -1.03e+05      2.109      18.66         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.539     0.0183    0.00693    0.00139\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/300      2.62G   -1.1e+05      1.995      18.68         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0277     0.0183    0.00727    0.00145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/300      2.62G -1.027e+05      1.985      18.61         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0065     0.0122     0.0016    0.00032\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/300      2.62G   -1.1e+05      1.941      18.65         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0276     0.0183    0.00532    0.00106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/300      2.62G  -1.07e+05      1.917      18.53         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0301     0.0183    0.00629    0.00126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/300      2.62G -9.986e+04      1.895      18.52         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0197     0.0183    0.00399   0.000629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/300      2.62G -1.105e+05      1.889      18.57         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0508     0.0183     0.0134    0.00267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/300      2.62G -1.166e+05      1.875      18.69         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0347     0.0183    0.00734    0.00151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/300      2.62G -1.092e+05      1.811      18.58         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0183     0.0183     0.0048    0.00096\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/300      2.62G -1.171e+05      1.806      18.52         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.666     0.0183     0.0212    0.00423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/300      2.62G -1.015e+05      1.758       18.4         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0647     0.0183     0.0169    0.00339\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/300      2.62G -1.073e+05      1.747      18.37         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.575     0.0183     0.0201    0.00402\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/300      2.62G  -1.15e+05       1.74      18.45         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.618     0.0183     0.0199    0.00397\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/300      2.62G -1.094e+05      1.727      18.46         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0617     0.0183     0.0144     0.0031\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/300      2.62G -1.084e+05      1.683      18.43         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0399     0.0183     0.0169    0.00337\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/300      2.62G -1.061e+05      1.685      18.22         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.669     0.0183     0.0205    0.00439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/300      2.62G -1.099e+05      1.678      18.39         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.363     0.0183     0.0152    0.00305\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/300      2.62G -1.077e+05      1.665      18.19         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.422     0.0183      0.023    0.00506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/300      2.62G -1.063e+05      1.644      18.22         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.368     0.0183     0.0235     0.0047\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/300      2.62G -1.073e+05      1.658      18.29         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0626     0.0183     0.0171    0.00207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/300      2.62G -1.128e+05      1.669      18.31         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.137     0.0183     0.0204    0.00445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/300      2.62G -1.066e+05      1.631      18.22         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0224    0.00448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/300      2.62G -1.134e+05      1.615      18.27         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.466     0.0183     0.0243    0.00487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/300      2.62G -1.106e+05      1.619      18.26         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0225     0.0045\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/300      2.62G -1.068e+05      1.614      18.18         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.975     0.0183     0.0232    0.00465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/300      2.62G -1.117e+05      1.651      18.29         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.97     0.0183     0.0237    0.00474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/300      2.62G -1.043e+05      1.622      18.21         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0244    0.00489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/300      2.62G -1.144e+05      1.601      18.15         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.68     0.0183     0.0243    0.00487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/300      2.62G -1.144e+05      1.599      18.28         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183      0.024     0.0048\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/300      2.62G -1.041e+05      1.572       18.1         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0236    0.00471\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/300      2.62G -1.092e+05      1.589      18.19         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0239    0.00478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/300      2.62G -1.139e+05      1.582      18.29         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.974     0.0183     0.0232    0.00464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/300      2.62G -1.146e+05       1.61      18.23         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.706     0.0122     0.0172    0.00344\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/300      2.62G -1.078e+05      1.579      18.18         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.965     0.0183     0.0229    0.00457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/300      2.62G -1.054e+05      1.574      18.13         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.722     0.0122     0.0171    0.00341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/300      2.62G -1.049e+05      1.569       18.1         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.468     0.0183     0.0242    0.00567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/300      2.62G -1.078e+05      1.571      18.13         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.978     0.0183     0.0247    0.00494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/300      2.62G -1.001e+05       1.59      18.14         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.935     0.0183     0.0238    0.00475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/300      2.62G -1.045e+05      1.537       18.1         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.974     0.0183     0.0241    0.00482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/300      2.62G -1.116e+05      1.524      18.07         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0136     0.0183     0.0086    0.00172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/300      2.63G -1.157e+05      1.516      18.11         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.956     0.0183     0.0234    0.00467\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/300      2.63G -1.002e+05      1.538      18.01         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.409     0.0183     0.0218    0.00435\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/300      2.63G -1.074e+05      1.523      18.04         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0244    0.00489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/300      2.63G -1.068e+05      1.546      18.01         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.936     0.0183     0.0239    0.00478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/300      2.63G -1.082e+05      1.551      18.09         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.394     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/300      2.63G -1.071e+05      1.518      18.06         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.972     0.0183     0.0239    0.00559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/300      2.63G -1.062e+05      1.517      18.07         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.989     0.0183     0.0247    0.00547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/300      2.63G  -1.12e+05      1.519      18.18         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0241    0.00482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/300      2.63G -1.161e+05      1.512       18.1         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0242    0.00567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/300      2.63G  -1.03e+05      1.495      18.03         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.973     0.0183     0.0247    0.00494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/300      2.63G -1.158e+05      1.502      18.08         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0242    0.00485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/300      2.63G -1.107e+05      1.503      18.07         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0247    0.00547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/300      2.63G -1.074e+05      1.494         18         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.99     0.0183     0.0247    0.00547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/300      2.63G -1.041e+05      1.493      17.93         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0238    0.00477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/300      2.63G -1.136e+05        1.5      18.06         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0238    0.00477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/300      2.63G -1.083e+05      1.486      18.06         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.229     0.0183     0.0254    0.00508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/300      2.63G -1.175e+05      1.491         18         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0234    0.00515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/300      2.63G -1.149e+05      1.494      18.09         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0248    0.00496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/300      2.63G  -1.12e+05      1.478      18.01         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0237    0.00523\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/300      2.63G -1.022e+05      1.466      17.98         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0232    0.00465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     76/300      2.63G -1.052e+05      1.473      18.01         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0243    0.00538\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     77/300      2.63G -1.131e+05      1.462      17.97         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0246    0.00544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     78/300      2.63G -1.103e+05      1.453      17.92         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0253    0.00506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     79/300      2.63G -1.073e+05       1.45      17.84         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.99     0.0183     0.0246    0.00575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     80/300      2.63G -1.156e+05      1.458      18.04         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.932     0.0183      0.024    0.00561\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     81/300      2.63G -1.068e+05      1.462      17.97         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0238    0.00477\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     82/300      2.63G  -1.11e+05      1.452      17.97         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.99     0.0183     0.0244    0.00489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     83/300      2.63G -1.133e+05      1.475      17.97         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0252    0.00503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     84/300      2.63G -1.096e+05      1.468      17.91         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0249    0.00499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     85/300      2.63G -1.089e+05      1.463      17.96         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0235     0.0047\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     86/300      2.63G  -1.07e+05      1.454      17.91         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.481     0.0183     0.0244    0.00489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     87/300      2.63G -1.216e+05      1.463      17.98         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0236    0.00473\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     88/300      2.63G  -1.14e+05      1.487       18.1         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.975     0.0183     0.0242    0.00483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     89/300      2.64G -1.094e+05      1.458      17.97         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0244    0.00489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     90/300      2.64G -1.112e+05      1.469      17.95         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0242    0.00483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     91/300      2.64G -1.046e+05       1.45      17.92         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.99     0.0183      0.025    0.00554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     92/300      2.64G -1.135e+05       1.44      17.93         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.486     0.0183     0.0255    0.00511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     93/300      2.64G -1.039e+05      1.451      17.81         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183      0.024     0.0048\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     94/300      2.64G -1.042e+05      1.442      17.89         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0264    0.00587\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     95/300      2.64G -1.158e+05      1.451      17.96         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0247    0.00494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     96/300      2.64G  -1.09e+05      1.425      17.85         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0243    0.00527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     97/300      2.64G -1.109e+05      1.463      17.98         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0246    0.00492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     98/300      2.64G -1.036e+05      1.423      17.81         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0248     0.0058\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     99/300      2.64G -1.152e+05      1.461      18.02         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.991     0.0183      0.024     0.0053\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    100/300      2.64G  -1.02e+05      1.434       17.8         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0252    0.00503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    101/300      2.64G -1.082e+05      1.436       17.9         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.966     0.0183     0.0242    0.00483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    102/300      2.64G -1.081e+05      1.424      17.96         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0243    0.00527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    103/300      2.64G -1.108e+05      1.417      17.94         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0252    0.00503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    104/300      2.64G -1.065e+05      1.414      17.89         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0248    0.00496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    105/300      2.64G -1.069e+05      1.432      17.89         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0253     0.0056\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    106/300      2.64G -1.112e+05      1.429       17.9         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.989     0.0183     0.0252    0.00557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    107/300      2.64G -1.096e+05      1.421      17.94         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0238    0.00475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    108/300      2.64G  -1.07e+05       1.42      17.89         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0241    0.00482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    109/300      2.64G -1.151e+05      1.433      17.91         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.99     0.0183     0.0248    0.00496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    110/300      2.64G  -1.09e+05      1.423      17.92         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0249    0.00499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    111/300      2.64G  -1.12e+05      1.414      17.89         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0242    0.00535\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    112/300      2.64G -1.109e+05      1.422       17.9         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.989     0.0183     0.0245    0.00542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    113/300      2.64G -1.058e+05      1.394      17.74         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.99     0.0183     0.0249    0.00552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    114/300      2.64G -1.116e+05      1.424      17.91         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.991     0.0183     0.0244    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    115/300      2.64G -1.049e+05      1.405      17.81         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0244    0.00571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    116/300      2.64G -1.131e+05      1.406      17.83         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.989     0.0183     0.0248     0.0058\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    117/300      2.64G -1.106e+05      1.423      17.91         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.99     0.0183     0.0245    0.00573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    118/300      2.64G -1.105e+05      1.412       17.8         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.991     0.0183      0.025    0.00544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    119/300      2.64G -1.064e+05      1.389      17.81         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0247    0.00547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    120/300      2.64G -1.081e+05      1.381      17.79         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183      0.025    0.00501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    121/300      2.64G -1.197e+05      1.396      17.87         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0244     0.0054\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    122/300      2.64G -1.084e+05      1.407      17.87         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0257    0.00569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    123/300      2.64G   -1.1e+05      1.396       17.8         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    124/300      2.64G -1.054e+05      1.396      17.87         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0249    0.00499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    125/300      2.64G  -9.86e+04      1.387      17.73         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0258    0.00572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    126/300      2.64G -1.032e+05      1.397      17.79         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183      0.025    0.00501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    127/300      2.64G -1.177e+05      1.415      17.93         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0242    0.00483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    128/300      2.64G -1.084e+05      1.394      17.82         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.727     0.0183     0.0243    0.00487\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    129/300      2.64G  -1.03e+05      1.387      17.77         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.724     0.0183     0.0249    0.00552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    130/300      2.64G -1.084e+05      1.398      17.83         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183      0.025    0.00501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    131/300      2.64G -1.122e+05      1.383      17.87         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0244    0.00489\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    132/300      2.64G -1.187e+05      1.389      17.87         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0246    0.00492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    133/300      2.64G -1.144e+05      1.386      17.87         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0252    0.00557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    134/300      2.64G -1.092e+05      1.387      17.78         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0257    0.00569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    135/300      2.64G -1.142e+05      1.402      17.85         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0248    0.00496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    136/300      2.64G -1.116e+05      1.396      17.79         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    137/300      2.64G -1.111e+05      1.392       17.8         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0252    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    138/300      2.64G -1.076e+05      1.385      17.75         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.989     0.0183     0.0242    0.00567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    139/300      2.64G -1.117e+05      1.388      17.84         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.989     0.0183     0.0242    0.00485\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    140/300      2.64G -1.031e+05      1.361      17.68         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.989     0.0183     0.0248    0.00496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    141/300      2.64G -1.129e+05      1.403      17.86         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0249    0.00552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    142/300      2.64G -1.114e+05      1.378      17.78         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    143/300      2.64G  -1.13e+05      1.373      17.77         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    144/300      2.64G -1.125e+05      1.371      17.71         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0253    0.00506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    145/300      2.64G -1.105e+05      1.374      17.72         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0247    0.00547\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    146/300      2.64G -1.025e+05      1.376      17.73         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0248    0.00496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    147/300      2.64G -1.112e+05      1.372      17.77         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0254    0.00563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    148/300      2.64G -1.123e+05      1.376      17.75         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    149/300      2.64G -1.176e+05      1.371       17.8         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183      0.025    0.00554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    150/300      2.64G -1.135e+05      1.383      17.82         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.989     0.0183     0.0245    0.00542\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    151/300      2.64G -1.244e+05      1.364      17.83         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.99     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    152/300      2.64G -1.085e+05      1.378      17.72         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0253    0.00506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    153/300      2.64G -1.153e+05      1.367      17.82         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0252    0.00503\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    154/300      2.64G -1.071e+05      1.365      17.68         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    155/300      2.64G -1.039e+05      1.353      17.68         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0245    0.00573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    156/300      2.64G -1.161e+05      1.377      17.74         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0248    0.00496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    157/300      2.64G -1.135e+05      1.368       17.7         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.99     0.0183      0.025    0.00501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    158/300      2.64G  -1.12e+05      1.364      17.81         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.99     0.0183     0.0258    0.00562\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    159/300      2.64G -1.123e+05      1.368      17.76         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.99     0.0183     0.0254    0.00563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    160/300      2.64G -1.114e+05      1.357      17.75         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.989     0.0183     0.0255    0.00511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    161/300      2.64G -1.122e+05      1.365      17.75         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    162/300      2.64G  -1.06e+05      1.355      17.65         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0255    0.00511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    163/300      2.64G -1.113e+05      1.367      17.66         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    164/300      2.64G -1.127e+05      1.367      17.79         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0252    0.00557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    165/300      2.64G -1.162e+05      1.365      17.84         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183      0.025    0.00501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    166/300      2.64G -1.153e+05      1.354      17.74         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0253    0.00506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    167/300      2.64G -1.082e+05      1.347       17.7         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183      0.025    0.00554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    168/300      2.64G  -1.11e+05      1.348      17.61         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    169/300      2.64G -1.047e+05      1.362      17.66         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0257    0.00569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    170/300      2.64G -1.084e+05       1.35      17.72         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    171/300      2.64G -1.121e+05      1.354      17.65         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    172/300      2.64G -1.163e+05       1.35      17.74         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0247    0.00494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    173/300      2.64G -1.185e+05      1.347      17.68         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0253    0.00506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    174/300      2.64G -1.059e+05      1.347      17.67         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0254    0.00508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    175/300      2.64G -1.116e+05      1.357      17.74         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    176/300      2.64G -1.203e+05      1.359      17.86         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    177/300      2.64G -1.125e+05       1.36      17.74         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    178/300      2.64G -1.183e+05      1.361      17.81         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    179/300      2.64G -1.053e+05      1.334      17.61         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    180/300      2.64G -1.085e+05       1.33       17.6         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.979     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    181/300      2.64G -1.064e+05      1.353      17.74         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    182/300      2.64G -1.147e+05       1.33      17.61         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    183/300      2.64G -1.058e+05      1.339      17.71         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    184/300      2.64G -1.062e+05      1.338      17.53         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    185/300      2.64G -1.011e+05      1.344       17.6         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0255    0.00511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    186/300      2.64G  -1.15e+05      1.352      17.69         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0252    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    187/300      2.64G -1.188e+05      1.348      17.68         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    188/300      2.64G -1.137e+05      1.346      17.71         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    189/300      2.64G -1.143e+05      1.345      17.66         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    190/300      2.64G -1.105e+05      1.345      17.65         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    191/300      2.64G -1.146e+05      1.351      17.72         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    192/300      2.64G  -1.12e+05      1.347       17.7         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183      0.027     0.0054\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    193/300      2.64G -1.119e+05      1.328      17.57         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    194/300      2.64G -1.162e+05      1.344      17.75         30        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    195/300      2.64G -1.167e+05       1.35      17.73         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    196/300      2.64G -1.075e+05      1.331      17.58         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0255    0.00566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    197/300      2.64G -1.087e+05      1.331      17.65         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    198/300      2.64G -1.124e+05      1.332       17.7         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    199/300      2.64G -1.212e+05      1.345      17.73         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0263    0.00583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    200/300      2.64G -1.092e+05      1.343      17.61         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    201/300      2.64G -1.093e+05      1.336      17.65         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    202/300      2.64G -1.035e+05      1.324      17.58         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0254    0.00508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    203/300      2.64G -1.119e+05      1.331      17.68         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0258    0.00572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    204/300      2.64G -1.193e+05       1.34      17.66         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    205/300      2.64G -1.057e+05      1.317      17.57         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    206/300      2.64G -1.076e+05      1.323      17.54         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    207/300      2.64G -1.189e+05      1.313      17.52         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    208/300      2.64G -1.187e+05      1.312      17.55         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    209/300      2.64G -1.156e+05       1.33      17.67         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    210/300      2.64G -1.165e+05      1.332      17.65         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    211/300      2.64G -1.114e+05      1.313      17.49          9        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    212/300      2.64G  -1.22e+05      1.324      17.61         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    213/300      2.64G -1.125e+05      1.333      17.64         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    214/300      2.64G -1.079e+05      1.334      17.63         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0253    0.00506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    215/300      2.64G -1.106e+05      1.339      17.64         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.48     0.0183     0.0254    0.00508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    216/300      2.64G -1.172e+05      1.331      17.67         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    217/300      2.64G -1.194e+05      1.324      17.64         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    218/300      2.64G -1.235e+05      1.328      17.54         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    219/300      2.64G -1.142e+05      1.329      17.62         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    220/300      2.64G -1.109e+05      1.327      17.65         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    221/300      2.64G -1.113e+05      1.314      17.55         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    222/300      2.64G -1.119e+05      1.329      17.68         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.482     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    223/300      2.64G -1.074e+05      1.326      17.64         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0255    0.00511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    224/300      2.64G -1.155e+05      1.309      17.58         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    225/300      2.64G  -1.11e+05      1.325      17.57         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    226/300      2.64G -1.095e+05      1.318      17.65         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    227/300      2.64G -1.139e+05       1.33       17.6         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    228/300      2.64G -1.161e+05      1.322      17.69         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    229/300      2.64G -1.153e+05      1.326      17.62         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    230/300      2.64G -1.115e+05      1.324      17.61          8        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0255    0.00566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    231/300      2.64G -1.083e+05      1.319      17.63         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0254    0.00563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    232/300      2.64G  -1.22e+05      1.323      17.64         32        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0253     0.0056\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    233/300      2.64G -1.074e+05      1.308      17.55         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    234/300      2.64G -1.082e+05      1.325      17.61         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    235/300      2.64G -1.133e+05      1.324      17.65         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    236/300      2.64G -1.091e+05      1.317      17.57         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    237/300      2.64G -1.102e+05       1.32      17.59         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    238/300      2.64G -1.091e+05      1.316      17.49         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    239/300      2.64G -1.073e+05      1.319      17.56         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    240/300      2.64G -1.068e+05      1.314      17.52         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    241/300      2.64G -1.164e+05       1.31      17.59         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    242/300      2.64G -1.128e+05      1.304      17.52         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    243/300      2.64G -1.146e+05      1.312      17.59         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    244/300      2.64G -1.083e+05      1.301      17.53         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    245/300      2.64G -1.106e+05      1.318      17.61         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.73     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    246/300      2.64G -1.061e+05      1.309      17.54         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    247/300      2.64G -1.111e+05      1.314      17.52         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    248/300      2.64G -1.133e+05      1.314      17.55         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    249/300      2.64G -1.077e+05      1.309      17.52         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    250/300      2.64G -1.138e+05      1.315      17.58         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    251/300      2.64G -1.124e+05      1.315      17.44         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    252/300      2.64G -1.054e+05      1.321       17.6         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.979     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    253/300      2.64G -1.127e+05      1.319       17.6         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    254/300      2.64G -1.113e+05      1.301      17.46         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    255/300      2.64G  -1.13e+05       1.31      17.54         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    256/300      2.64G -1.098e+05      1.308      17.53         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    257/300      2.64G -1.041e+05      1.299      17.44         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    258/300      2.64G -1.168e+05      1.323       17.6         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    259/300      2.64G -1.093e+05      1.303      17.55         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    260/300      2.64G -1.136e+05      1.302      17.52         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    261/300      2.64G -1.072e+05      1.309      17.52         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    262/300      2.64G -1.113e+05      1.307      17.48         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    263/300      2.64G -1.061e+05      1.299       17.5         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    264/300      2.64G -1.128e+05      1.304      17.48         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    265/300      2.64G -1.127e+05      1.305      17.55         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    266/300      2.64G -1.128e+05      1.291      17.42         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.978     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    267/300      2.64G -1.141e+05      1.297      17.44         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    268/300      2.64G -1.112e+05      1.308      17.49         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    269/300      2.64G -1.112e+05      1.302      17.43         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    270/300      2.64G -1.082e+05      1.298       17.5         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    271/300      2.64G -1.091e+05      1.303      17.51         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    272/300      2.64G -1.163e+05      1.298      17.48         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    273/300      2.64G -1.082e+05      1.302      17.52         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    274/300      2.64G -1.111e+05      1.305      17.46         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    275/300      2.64G -1.123e+05      1.305      17.55         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    276/300      2.64G  -1.07e+05      1.289      17.45         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    277/300      2.64G -1.099e+05      1.293      17.42         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    278/300      2.64G -1.159e+05      1.309      17.53         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    279/300      2.64G -1.067e+05      1.297      17.45         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    280/300      2.64G -1.117e+05      1.299      17.54         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    281/300      2.64G -1.172e+05      1.305      17.59         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    282/300      2.64G -1.065e+05      1.301      17.52         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    283/300      2.64G -1.052e+05      1.296      17.42         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    284/300      2.64G  -1.09e+05      1.307      17.52         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    285/300      2.64G  -1.17e+05      1.304       17.5         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    286/300      2.64G -1.111e+05      1.298      17.49         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    287/300      2.64G -1.099e+05        1.3       17.5         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    288/300      2.64G -1.025e+05      1.289      17.34         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    289/300      2.64G -1.034e+05      1.306      17.54         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    290/300      2.64G -1.103e+05      1.285      17.41         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0263    0.00526\n",
      "Closing dataloader mosaic\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    291/300      2.64G -3.495e+04      1.163      16.06          9        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    292/300      2.64G -3.261e+04      1.142      15.94         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    293/300      2.64G -3.503e+04       1.16      16.04         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    294/300      2.64G -3.362e+04       1.15      15.98         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    295/300      2.64G -3.519e+04      1.158      16.02         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    296/300      2.64G -3.501e+04      1.153      15.99         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    297/300      2.64G -3.441e+04      1.153      15.98         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    298/300      2.64G  -3.47e+04      1.147      15.98         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    299/300      2.64G -3.448e+04      1.142      15.92         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    300/300      2.64G -3.512e+04      1.149      15.96         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0263    0.00614\n",
      "\n",
      "300 epochs completed in 0.768 hours.\n",
      "Optimizer stripped from runs/obb/train3/weights/last.pt, 5.8MB\n",
      "Optimizer stripped from runs/obb/train3/weights/best.pt, 5.8MB\n",
      "\n",
      "Validating runs/obb/train3/weights/best.pt...\n",
      "Ultralytics 8.3.165 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,654,503 parameters, 0 gradients, 6.6 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0263    0.00614\n",
      "        LCA-brightness         52         54          1          0          0          0\n",
      "        LCA-dilatation        103        109          1          0          0          0\n",
      "        RCA-brightness         25         25          1          0          0          0\n",
      "        RCA-dilatation         41         41      0.922     0.0732      0.105     0.0246\n",
      "Speed: 0.2ms preprocess, 0.9ms inference, 0.0ms loss, 2.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/obb/train3\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# Load a model (N-submodel)\n",
    "# model = YOLO(\"yolov8n-obb.yaml\")  # build a new model from YAML\n",
    "model = YOLO(\"yolo11n-obb.pt\")  # load a pretrained model (recommended for training)\n",
    "# model = YOLO(\"yolov8n-obb.yaml\").load(\"yolov8n.pt\")  # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "#results = model.train(data=yamldir, epochs=300, imgsz=640)\n",
    "!yolo task=obb mode=train model=yolo11n-obb.pt data={yamldir} epochs=300 imgsz=640 plots=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11s-obb.pt to 'yolo11s-obb.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.0M/19.0M [00:00<00:00, 27.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The KLD_exp Loss & IOU mode has been selected\n",
      "Ultralytics 8.3.165 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/u3618315/obb_dataset/datav11.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=300, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s-obb.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train4, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/obb/train4, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=obb, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1   1107135  ultralytics.nn.modules.head.OBB              [4, 1, [128, 256, 512]]       \n",
      "YOLO11s-obb summary: 196 layers, 9,715,519 parameters, 9,715,503 gradients, 22.5 GFLOPs\n",
      "\n",
      "Transferred 535/541 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2447.2Â±583.3 MB/s, size: 183.2 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/u3618315/obb_dataset/train/labels.cache... 1288 images, 3 \u001b[0m\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1474.1Â±1027.2 MB/s, size: 215.7 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/u3618315/obb_dataset/val/labels.cache... 184 images, 1 backg\u001b[0m\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Plotting labels to runs/obb/train4/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 87 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/obb/train4\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      1/300      4.04G -2.839e+04      5.326       5.16         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00961     0.0597    0.00756    0.00172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      2/300      4.09G -1.187e+05      4.069      10.14         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      3/300       4.1G -1.342e+05      3.396      16.32         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      4/300      4.13G -1.434e+05       3.14      22.95         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      5/300      4.14G -1.459e+05      3.179      22.36          8        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      6/300      4.14G -1.411e+05      3.202      19.24         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      7/300      4.14G -1.411e+05      3.094      21.18         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0018     0.0122   0.000965   9.65e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      8/300      4.17G -1.305e+05      3.066      19.63         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "      9/300      4.21G -1.269e+05      3.073         21         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229   0.000873     0.0122   0.000479   4.79e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     10/300      4.22G -1.206e+05      2.879      19.15         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229   0.000847     0.0061   0.000441   4.41e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     11/300      4.23G -1.198e+05       2.74      19.46         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     12/300      4.26G -1.155e+05      2.668      19.37         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     13/300      4.26G  -1.11e+05      2.505      19.21         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00305     0.0183    0.00172   0.000282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     14/300      4.26G -1.104e+05      2.461      18.92         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00119     0.0061    0.00061   0.000122\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     15/300      4.26G -1.089e+05      2.397      19.04         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00128     0.0122   0.000939   0.000134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     16/300      4.26G -1.021e+05      2.376      18.79         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229   0.000859     0.0061   0.000442   8.84e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     17/300      4.26G -1.093e+05       2.26      18.87         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00158     0.0122   0.000851    0.00017\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     18/300      4.26G -1.031e+05      2.236      18.75         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0027     0.0183    0.00172   0.000272\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     19/300      4.26G   -1.1e+05      2.148      18.68         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00764     0.0183    0.00307   0.000461\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     20/300      4.26G  -1.07e+05      2.097      18.64         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00321     0.0183    0.00189   0.000379\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     21/300      4.26G -9.954e+04       2.06      18.57         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00347     0.0183    0.00202   0.000464\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     22/300      4.26G -1.102e+05      2.023      18.53         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0121     0.0183    0.00275   0.000427\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     23/300      4.26G -1.169e+05       1.99      18.63         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00861     0.0183    0.00279   0.000352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     24/300      4.26G -1.089e+05      1.891      18.57         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00743     0.0183    0.00435   0.000871\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     25/300      4.26G -1.173e+05      1.857      18.54         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0375     0.0183    0.00786    0.00157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     26/300      4.26G -1.015e+05      1.788       18.4         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0151     0.0183    0.00486   0.000973\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     27/300      4.26G -1.074e+05      1.769      18.33         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0267     0.0183    0.00937    0.00187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     28/300      4.26G -1.149e+05      1.763      18.46         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0312     0.0183    0.00965    0.00193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     29/300      4.26G -1.092e+05       1.74      18.42         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229    0.00827     0.0122    0.00429   0.000857\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     30/300      4.26G -1.085e+05       1.75      18.41         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.192     0.0183     0.0211    0.00423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     31/300      4.26G -1.063e+05      1.743       18.2         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.296     0.0122     0.0112    0.00224\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     32/300      4.26G -1.097e+05      1.724      18.36         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.71     0.0122     0.0163    0.00326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     33/300      4.26G -1.077e+05      1.708      18.26         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.411     0.0183     0.0225    0.00449\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     34/300      4.26G -1.065e+05      1.661      18.17         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0196     0.0183     0.0116    0.00231\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     35/300      4.26G -1.075e+05      1.638      18.29         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0353     0.0183     0.0174    0.00348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     36/300      4.26G -1.129e+05      1.671      18.25         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0438     0.0183     0.0142    0.00284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     37/300      4.26G -1.067e+05      1.635      18.24         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0185     0.0183    0.00663    0.00133\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     38/300      4.26G -1.135e+05      1.638      18.21         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.029     0.0183     0.0138    0.00354\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     39/300      4.26G -1.107e+05      1.642      18.26         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.687     0.0183     0.0231    0.00462\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     40/300      4.26G -1.065e+05      1.613      18.15         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.31     0.0183     0.0157    0.00341\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     41/300      4.26G -1.118e+05      1.648      18.29         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0214    0.00428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     42/300      4.26G -1.045e+05      1.613      18.21         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.979     0.0183     0.0231    0.00498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     43/300      4.26G -1.143e+05      1.596      18.12         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.72     0.0183     0.0237    0.00474\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     44/300      4.26G -1.143e+05      1.596      18.25         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.977     0.0183     0.0228    0.00456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     45/300      4.26G -1.037e+05      1.583      18.16         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.973     0.0183     0.0229    0.00457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     46/300      4.26G -1.093e+05      1.594      18.21         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.385     0.0183     0.0226    0.00536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     47/300      4.26G -1.138e+05      1.592      18.23         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.361     0.0183     0.0189    0.00378\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     48/300      4.26G -1.144e+05      1.585      18.22         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.589     0.0183     0.0149    0.00298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     49/300      4.26G -1.079e+05       1.56      18.22         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.974     0.0183     0.0228    0.00533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     50/300      4.26G -1.052e+05      1.536      18.07         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.683     0.0183     0.0237    0.00554\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     51/300      4.26G -1.048e+05      1.547       18.1         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.656     0.0183     0.0231    0.00539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     52/300      4.26G -1.074e+05      1.536      18.09         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.66     0.0183     0.0218    0.00483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     53/300      4.26G -9.993e+04      1.541      18.08         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.452     0.0183     0.0242    0.00525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     54/300      4.26G -1.044e+05      1.545      18.04         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.355     0.0183     0.0212    0.00423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     55/300      4.26G -1.119e+05      1.542      18.04         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.726     0.0183     0.0242    0.00565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     56/300      4.26G -1.155e+05      1.551      18.07         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.874     0.0183     0.0196    0.00392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     57/300      4.26G -9.949e+04      1.566      18.07         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.635     0.0122     0.0111    0.00235\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     58/300      4.26G -1.073e+05      1.548      18.06         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.967     0.0183     0.0236    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     59/300      4.26G -1.065e+05      1.559      18.08         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.673     0.0183     0.0235     0.0047\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     60/300      4.26G  -1.08e+05      1.557      18.14         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.346     0.0183     0.0202    0.00403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     61/300      4.26G -1.068e+05      1.522      18.08         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0243    0.00527\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     62/300      4.26G -1.062e+05      1.537      18.11         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.73     0.0183      0.024     0.0048\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     63/300      4.26G -1.122e+05      1.512      18.14         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.978     0.0183     0.0242    0.00565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     64/300      4.26G -1.161e+05      1.509      18.11         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.335     0.0183     0.0226    0.00536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     65/300      4.26G -1.031e+05      1.517      18.01         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229     0.0309     0.0183     0.0187    0.00458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     66/300      4.26G  -1.16e+05      1.507       18.1         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0246    0.00575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     67/300      4.26G -1.107e+05      1.501      18.04         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.979     0.0183     0.0243    0.00569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     68/300      4.26G -1.072e+05      1.499      18.05         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.738     0.0183     0.0244    0.00571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     69/300      4.26G -1.044e+05      1.475      17.93         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0229    0.00457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     70/300      4.26G -1.132e+05      1.491      18.03         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0238    0.00555\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     71/300      4.26G  -1.08e+05      1.495      18.03         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.483     0.0183     0.0238    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     72/300      4.26G -1.168e+05      1.503      18.04         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.946     0.0183     0.0246    0.00492\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     73/300      4.26G -1.141e+05      1.498      18.11         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0238    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     74/300      4.26G -1.119e+05      1.478      18.01         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.945     0.0183     0.0249    0.00499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     75/300      4.26G -1.021e+05      1.474      17.96         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.482     0.0183      0.024     0.0048\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     76/300      4.26G -1.049e+05      1.471      17.97         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.967     0.0183     0.0242    0.00533\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     77/300      4.26G  -1.13e+05      1.467      17.96         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.977     0.0183     0.0248     0.0058\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     78/300      4.26G -1.094e+05      1.444      17.95         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0238    0.00557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     79/300      4.26G -1.072e+05      1.443      17.85         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0247    0.00578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     80/300      4.26G -1.154e+05      1.453      17.99         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0234    0.00546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     81/300      4.26G -1.068e+05       1.45      17.96         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.461     0.0183     0.0247    0.00494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     82/300      4.26G -1.112e+05      1.441      17.95         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.473     0.0183     0.0238    0.00475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     83/300      4.26G -1.129e+05      1.452      17.93         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0253    0.00506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     84/300      4.26G -1.093e+05      1.444      17.89         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.975     0.0183      0.025    0.00501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     85/300      4.26G -1.091e+05      1.446      17.95         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.45     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     86/300      4.26G -1.076e+05       1.44      17.91         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.978     0.0183     0.0242    0.00565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     87/300      4.26G -1.217e+05      1.459      18.04         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0233    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     88/300      4.26G  -1.14e+05      1.453      18.02         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.463     0.0183     0.0248    0.00496\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     89/300      4.26G -1.096e+05      1.431      17.93         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.73     0.0183     0.0249    0.00583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     90/300      4.26G -1.115e+05       1.45      17.93         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0243    0.00569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     91/300      4.26G -1.049e+05      1.434      17.91         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0242    0.00565\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     92/300      4.26G -1.135e+05       1.43      17.91         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0249    0.00552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     93/300      4.26G  -1.04e+05      1.441       17.8         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0238    0.00557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     94/300      4.26G -1.042e+05      1.436      17.87         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183     0.0248     0.0058\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     95/300      4.26G -1.158e+05       1.43      17.93         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.484     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     96/300      4.26G -1.091e+05      1.424       17.8         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0247    0.00494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     97/300      4.26G -1.104e+05      1.436      17.93         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.726     0.0183     0.0245    0.00573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     98/300      4.26G -1.032e+05      1.401      17.84         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0245    0.00573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "     99/300      4.26G -1.153e+05      1.441         18         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.728     0.0183     0.0246    0.00575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    100/300      4.26G  -1.02e+05      1.404      17.77         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    101/300      4.26G -1.086e+05      1.415      17.87         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    102/300      4.26G -1.078e+05      1.408      17.92         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.979     0.0183     0.0244    0.00571\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    103/300      4.26G -1.112e+05      1.415      17.92         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.977     0.0183     0.0245     0.0049\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    104/300      4.26G -1.065e+05      1.398      17.85         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0248     0.0058\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    105/300      4.26G -1.069e+05      1.422      17.86         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0245    0.00573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    106/300      4.26G -1.112e+05      1.417      17.87         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0247    0.00578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    107/300      4.26G -1.095e+05      1.409      17.92         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183      0.025    0.00586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    108/300      4.26G -1.071e+05      1.408      17.87         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0245    0.00573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    109/300      4.26G -1.147e+05      1.415      17.87         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0247    0.00578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    110/300      4.26G -1.095e+05      1.401      17.91         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.728     0.0183     0.0247    0.00578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    111/300      4.26G -1.119e+05      1.401      17.89         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.973     0.0183     0.0247    0.00578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    112/300      4.26G  -1.11e+05      1.413      17.87         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.727     0.0183     0.0248     0.0058\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    113/300      4.26G  -1.06e+05      1.389       17.7         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0252    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    114/300      4.26G -1.115e+05      1.396      17.86         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0247    0.00578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    115/300      4.26G -1.049e+05      1.383      17.79         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.48     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    116/300      4.26G -1.126e+05      1.386      17.81         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.216     0.0183     0.0248     0.0058\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    117/300      4.26G -1.102e+05      1.409      17.88         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0249    0.00583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    118/300      4.26G -1.105e+05       1.39      17.77         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183      0.025    0.00586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    119/300      4.26G -1.063e+05      1.379      17.76         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.475     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    120/300      4.26G -1.086e+05      1.372      17.77         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0254    0.00508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    121/300      4.26G   -1.2e+05      1.391      17.85         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.975     0.0183     0.0248     0.0058\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    122/300      4.26G -1.085e+05      1.392      17.79         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.475     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    123/300      4.26G -1.101e+05      1.392      17.81         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0253     0.0056\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    124/300      4.26G -1.058e+05      1.386      17.79         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.977     0.0183     0.0245     0.0049\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    125/300      4.26G -9.855e+04      1.365      17.72         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.724     0.0183     0.0254    0.00563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    126/300      4.26G -1.034e+05      1.386      17.75         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.979     0.0183      0.025    0.00586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    127/300      4.26G  -1.18e+05      1.405       17.9         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.476     0.0183     0.0253     0.0056\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    128/300      4.26G -1.091e+05      1.379       17.8         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0254    0.00563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    129/300      4.26G -1.036e+05      1.372      17.73         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0252    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    130/300      4.26G -1.084e+05      1.376      17.78         25        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.73     0.0183     0.0249    0.00583\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    131/300      4.26G -1.129e+05      1.368      17.81         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.726     0.0183     0.0247    0.00578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    132/300      4.26G -1.191e+05      1.371      17.79         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.727     0.0183     0.0248     0.0058\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    133/300      4.26G -1.141e+05      1.367      17.81         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.727     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    134/300      4.26G -1.095e+05      1.378      17.75         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0253    0.00506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    135/300      4.26G -1.136e+05      1.386      17.79         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    136/300      4.26G -1.118e+05      1.383      17.73         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183      0.025    0.00586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    137/300      4.26G -1.115e+05      1.372      17.75         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.476     0.0183     0.0248     0.0058\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    138/300      4.26G -1.079e+05      1.375      17.71         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.727     0.0183     0.0247    0.00578\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    139/300      4.26G -1.125e+05      1.387      17.78         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183      0.025    0.00586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    140/300      4.26G  -1.03e+05      1.363      17.64         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.979     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    141/300      4.26G -1.134e+05      1.396      17.84         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0248     0.0058\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    142/300      4.26G -1.113e+05      1.359      17.69         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.482     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    143/300      4.26G -1.135e+05      1.362      17.74         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    144/300      4.26G -1.129e+05      1.359      17.71         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0254    0.00508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    145/300      4.26G -1.107e+05      1.372       17.7         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.727     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    146/300      4.26G -1.019e+05       1.36      17.71         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    147/300      4.26G -1.112e+05      1.347      17.74         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    148/300      4.26G -1.129e+05      1.361       17.7         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.977     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    149/300      4.26G -1.176e+05      1.353      17.73         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0255    0.00511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    150/300      4.26G -1.137e+05      1.369      17.77         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0255    0.00511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    151/300      4.26G  -1.25e+05       1.35       17.8         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.972     0.0183     0.0253    0.00506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    152/300      4.26G -1.089e+05      1.349      17.65         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    153/300      4.26G  -1.16e+05      1.353      17.76         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    154/300      4.26G -1.079e+05      1.341      17.67         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.475     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    155/300      4.26G -1.039e+05      1.334      17.64         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    156/300      4.26G -1.164e+05       1.36      17.71         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    157/300      4.26G -1.138e+05      1.342      17.64         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0247    0.00494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    158/300      4.26G -1.124e+05      1.346      17.73         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    159/300      4.26G -1.127e+05      1.346      17.72         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0252    0.00557\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    160/300      4.26G -1.116e+05      1.339      17.71         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.978     0.0183     0.0261    0.00579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    161/300      4.26G -1.125e+05      1.343      17.68         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    162/300      4.26G -1.059e+05      1.321       17.6         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    163/300      4.26G -1.116e+05      1.339      17.64         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.977     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    164/300      4.26G  -1.13e+05      1.353      17.76         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.727     0.0183     0.0255    0.00511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    165/300      4.26G  -1.17e+05      1.358      17.77         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    166/300      4.26G -1.157e+05      1.346      17.69         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0255    0.00511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    167/300      4.26G -1.084e+05      1.336      17.65         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    168/300      4.26G -1.112e+05      1.329      17.58         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0255    0.00511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    169/300      4.26G -1.049e+05      1.349      17.58         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0266    0.00532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    170/300      4.26G -1.084e+05      1.328      17.65         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    171/300      4.26G -1.125e+05      1.335      17.62         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    172/300      4.26G -1.166e+05      1.336      17.69         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    173/300      4.26G -1.188e+05      1.333      17.64         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0261    0.00579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    174/300      4.26G -1.059e+05      1.328      17.61         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    175/300      4.26G -1.119e+05      1.331      17.66         27        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    176/300      4.26G -1.203e+05      1.342      17.81         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    177/300      4.26G -1.126e+05      1.337      17.66         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.731     0.0183     0.0257    0.00569\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    178/300      4.26G -1.184e+05      1.342      17.76         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.477     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    179/300      4.26G -1.053e+05      1.321      17.57         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.48     0.0183     0.0258    0.00572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    180/300      4.26G -1.088e+05      1.309      17.51         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0254    0.00508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    181/300      4.26G -1.069e+05      1.335      17.66         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    182/300      4.26G -1.148e+05      1.317      17.56         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    183/300      4.26G -1.061e+05      1.325      17.63         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.979     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    184/300      4.26G -1.068e+05      1.314      17.51         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.977     0.0183     0.0253    0.00591\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    185/300      4.26G -1.012e+05      1.316      17.51         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0249    0.00499\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    186/300      4.26G -1.156e+05       1.33      17.62         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0254    0.00508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    187/300      4.26G -1.192e+05      1.325      17.64         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    188/300      4.26G  -1.14e+05      1.336      17.66         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    189/300      4.26G -1.146e+05      1.332       17.6         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.725     0.0183     0.0254    0.00508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    190/300      4.26G  -1.11e+05      1.329      17.62         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.978     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    191/300      4.26G -1.146e+05      1.328      17.61         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.977     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    192/300      4.26G -1.123e+05      1.324      17.66         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0253    0.00506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    193/300      4.26G -1.121e+05      1.314      17.54         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    194/300      4.26G -1.161e+05      1.326      17.69         30        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    195/300      4.26G -1.169e+05      1.328       17.7         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    196/300      4.26G -1.078e+05      1.309      17.52         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    197/300      4.26G -1.091e+05      1.313       17.6         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    198/300      4.26G -1.124e+05      1.319      17.63         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    199/300      4.26G -1.212e+05      1.332      17.67         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    200/300      4.26G  -1.09e+05      1.317      17.53         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    201/300      4.26G -1.097e+05      1.315      17.61         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    202/300      4.26G -1.037e+05      1.304      17.53         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    203/300      4.26G -1.117e+05      1.321       17.6         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    204/300      4.26G -1.198e+05      1.329      17.64         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.979     0.0183     0.0255    0.00511\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    205/300      4.26G -1.059e+05      1.305      17.49         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    206/300      4.26G -1.078e+05       1.31      17.48         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    207/300      4.26G -1.189e+05      1.302      17.48         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    208/300      4.26G -1.196e+05      1.299       17.5         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    209/300      4.26G  -1.16e+05      1.319      17.62         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.979     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    210/300      4.26G -1.168e+05      1.316      17.56         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.971     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    211/300      4.26G -1.116e+05      1.297      17.46          9        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    212/300      4.26G -1.224e+05      1.309      17.57         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    213/300      4.26G -1.128e+05      1.317      17.57         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.981     0.0183     0.0254    0.00563\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    214/300      4.26G -1.082e+05      1.314      17.57         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.73     0.0183     0.0254    0.00594\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    215/300      4.26G -1.106e+05       1.32      17.57         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.729     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    216/300      4.26G -1.175e+05      1.316      17.61         26        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0252    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    217/300      4.26G -1.192e+05      1.309      17.56         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0252    0.00588\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    218/300      4.26G -1.235e+05      1.305      17.49         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0263    0.00614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    219/300      4.26G -1.142e+05      1.309      17.54         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    220/300      4.26G -1.112e+05      1.306      17.59         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    221/300      4.26G -1.113e+05      1.292      17.48         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    222/300      4.26G -1.118e+05      1.305      17.56         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    223/300      4.26G -1.078e+05      1.314       17.6         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    224/300      4.26G -1.146e+05      1.294       17.5         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    225/300      4.26G -1.111e+05      1.309      17.53         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    226/300      4.26G -1.094e+05      1.308      17.58         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229       0.98     0.0183     0.0257      0.006\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    227/300      4.26G -1.142e+05      1.311      17.55         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    228/300      4.26G -1.163e+05      1.304      17.61         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    229/300      4.26G -1.152e+05      1.308      17.53         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    230/300      4.26G -1.117e+05      1.308      17.54          8        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183      0.026    0.00607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    231/300      4.26G -1.087e+05      1.303      17.57         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0255    0.00597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    232/300      4.26G -1.222e+05        1.3      17.55         32        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    233/300      4.26G -1.077e+05      1.291      17.47         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.982     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    234/300      4.26G -1.086e+05      1.293      17.49         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    235/300      4.26G -1.137e+05      1.306      17.59         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.983     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    236/300      4.26G -1.093e+05      1.299      17.52         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0264    0.00618\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    237/300      4.26G -1.107e+05      1.307      17.51         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0261    0.00611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    238/300      4.26G -1.091e+05      1.302      17.46         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    239/300      4.26G -1.075e+05      1.297      17.47         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0258    0.00604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    240/300      4.26G  -1.07e+05      1.291      17.42         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    241/300      4.26G -1.166e+05      1.291      17.53         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    242/300      4.26G  -1.13e+05      1.288      17.44         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0257    0.00513\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    243/300      4.26G -1.149e+05      1.301      17.52         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    244/300      4.26G -1.084e+05      1.284      17.44         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    245/300      4.26G -1.105e+05      1.302      17.52         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.733     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    246/300      4.26G -1.061e+05      1.291      17.43         28        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.732     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    247/300      4.26G -1.115e+05      1.295      17.45         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.984     0.0183      0.026    0.00519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    248/300      4.26G -1.129e+05      1.296      17.46         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    249/300      4.26G  -1.08e+05      1.291      17.44         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    250/300      4.26G -1.138e+05      1.294      17.49         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    251/300      4.26G -1.127e+05      1.292      17.35         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    252/300      4.26G -1.054e+05      1.294       17.5         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    253/300      4.26G -1.128e+05      1.298      17.49         20        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0258    0.00516\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    254/300      4.26G -1.111e+05      1.284      17.39         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    255/300      4.26G  -1.13e+05      1.293      17.47         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.988     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    256/300      4.26G -1.097e+05       1.29      17.42         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    257/300      4.26G -1.039e+05      1.279      17.35         12        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    258/300      4.26G -1.175e+05        1.3       17.5         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    259/300      4.26G -1.089e+05      1.285      17.48         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    260/300      4.26G  -1.14e+05      1.276      17.43         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    261/300      4.26G -1.077e+05      1.294      17.45         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    262/300      4.26G  -1.11e+05      1.292       17.4         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    263/300      4.26G -1.061e+05      1.285      17.41         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    264/300      4.26G  -1.13e+05      1.288      17.44         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0266    0.00532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    265/300      4.26G -1.127e+05      1.292      17.45         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0266    0.00532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    266/300      4.26G -1.131e+05      1.281      17.37         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    267/300      4.26G -1.143e+05      1.275      17.35         24        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0266    0.00532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    268/300      4.26G -1.114e+05      1.291      17.43         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0266    0.00532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    269/300      4.26G -1.112e+05       1.29      17.37         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0266    0.00532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    270/300      4.26G -1.082e+05      1.287      17.41         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0266    0.00532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    271/300      4.26G -1.093e+05      1.286      17.44         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0266    0.00532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    272/300      4.26G -1.166e+05       1.28      17.39         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    273/300      4.26G  -1.08e+05      1.294      17.42         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0261    0.00522\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    274/300      4.26G -1.112e+05      1.287      17.38         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0266    0.00532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    275/300      4.26G -1.126e+05      1.289      17.46         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.986     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    276/300      4.26G -1.071e+05      1.274      17.35         16        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    277/300      4.26G -1.102e+05      1.275      17.34         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.987     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    278/300      4.26G -1.161e+05      1.296      17.45         21        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    279/300      4.26G -1.066e+05      1.278      17.38         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    280/300      4.26G -1.121e+05      1.283      17.45         23        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    281/300      4.26G -1.172e+05      1.283       17.5         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    282/300      4.26G -1.068e+05      1.285      17.45         17        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.485     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    283/300      4.26G -1.055e+05      1.277      17.34         19        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    284/300      4.26G -1.091e+05      1.292      17.44         22        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0266    0.00532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    285/300      4.26G -1.171e+05      1.285      17.42         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    286/300      4.26G -1.115e+05      1.282      17.41         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    287/300      4.26G -1.101e+05      1.282      17.42         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    288/300      4.26G -1.028e+05       1.27      17.26         18        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    289/300      4.26G -1.036e+05      1.289      17.46         15        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    290/300      4.26G -1.101e+05      1.273      17.34         14        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0263    0.00526\n",
      "Closing dataloader mosaic\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    291/300      4.36G -3.505e+04      1.144      15.96          9        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    292/300      4.36G -3.261e+04      1.125      15.82         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    293/300      4.36G -3.517e+04      1.144      15.95         13        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    294/300      4.36G -3.366e+04      1.134      15.87         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.736     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    295/300      4.36G -3.531e+04      1.138      15.91         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    296/300      4.36G -3.511e+04      1.136       15.9         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    297/300      4.36G -3.457e+04      1.139      15.89         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0263    0.00526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    298/300      4.36G -3.482e+04      1.133      15.87         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    299/300      4.36G -3.456e+04      1.129      15.82         10        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.985     0.0183     0.0264    0.00529\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "    300/300      4.36G -3.522e+04      1.134      15.86         11        640: 1\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.735     0.0183     0.0264    0.00529\n",
      "\n",
      "300 epochs completed in 0.922 hours.\n",
      "Optimizer stripped from runs/obb/train4/weights/last.pt, 19.9MB\n",
      "Optimizer stripped from runs/obb/train4/weights/best.pt, 19.9MB\n",
      "\n",
      "Validating runs/obb/train4/weights/best.pt...\n",
      "Ultralytics 8.3.165 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,700,335 parameters, 0 gradients, 22.3 GFLOPs\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\n",
      "                   all        184        229      0.734     0.0183     0.0264    0.00618\n",
      "        LCA-brightness         52         54          0          0          0          0\n",
      "        LCA-dilatation        103        109          1          0          0          0\n",
      "        RCA-brightness         25         25          1          0          0          0\n",
      "        RCA-dilatation         41         41      0.935     0.0732      0.106     0.0247\n",
      "Speed: 0.3ms preprocess, 1.8ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/obb/train4\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
     ]
    }
   ],
   "source": [
    "# Load a model (N-submodel)\n",
    "# model = YOLO(\"yolov8n-obb.yaml\")  # build a new model from YAML\n",
    "model = YOLO(\"yolo11s-obb.pt\")  # load a pretrained model (recommended for training)\n",
    "# model = YOLO(\"yolov8n-obb.yaml\").load(\"yolov8n.pt\")  # build from YAML and transfer weights\n",
    "\n",
    "# Train the model\n",
    "#results = model.train(data=yamldir, epochs=300, imgsz=640)\n",
    "!yolo task=obb mode=train model=yolo11s-obb.pt data={yamldir} epochs=300 imgsz=640 plots=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.165 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "YOLOv8n-obb summary (fused): 81 layers, 3,077,999 parameters, 0 gradients, 8.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3250.4Â±781.3 MB/s, size: 245.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/u3618315/obb_dataset/val/labels.cache... 184 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184/184 [00:00<?, ?it/s]\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        184        229      0.483     0.0183     0.0284    0.00664\n",
      "        LCA-brightness         52         54          0          0          0          0\n",
      "        LCA-dilatation        103        109          0          0          0          0\n",
      "        RCA-brightness         25         25          1          0          0          0\n",
      "        RCA-dilatation         41         41      0.934     0.0732      0.113     0.0265\n",
      "Speed: 0.4ms preprocess, 1.7ms inference, 0.0ms loss, 3.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/obb/val\u001b[0m\n",
      "Overall mAPs\n",
      "0.006636544864766081\n",
      "0.028366118421052626\n",
      "0.0\n",
      "classwise mAPs\n",
      "[          0           0           0    0.026546]\n",
      "Ultralytics 8.3.165 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "YOLOv8s-obb summary (fused): 81 layers, 11,413,119 parameters, 0 gradients, 29.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2828.5Â±489.9 MB/s, size: 204.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/u3618315/obb_dataset/val/labels.cache... 184 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184/184 [00:00<?, ?it/s]\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:01<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        184        229     0.0385     0.0122     0.0267    0.00534\n",
      "        LCA-brightness         52         54          0          0          0          0\n",
      "        LCA-dilatation        103        109          0          0          0          0\n",
      "        RCA-brightness         25         25          0          0          0          0\n",
      "        RCA-dilatation         41         41      0.154     0.0488      0.107     0.0214\n",
      "Speed: 0.7ms preprocess, 2.5ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/obb/val2\u001b[0m\n",
      "Overall mAPs\n",
      "0.005337573964497041\n",
      "0.026687869822485208\n",
      "0.0\n",
      "classwise mAPs\n",
      "[          0           0           0     0.02135]\n",
      "Ultralytics 8.3.165 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "YOLO11n-obb summary (fused): 109 layers, 2,654,503 parameters, 0 gradients, 6.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2918.8Â±568.6 MB/s, size: 246.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/u3618315/obb_dataset/val/labels.cache... 184 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184/184 [00:00<?, ?it/s]\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:02<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        184        229       0.98     0.0183     0.0264    0.00618\n",
      "        LCA-brightness         52         54          1          0          0          0\n",
      "        LCA-dilatation        103        109          1          0          0          0\n",
      "        RCA-brightness         25         25          1          0          0          0\n",
      "        RCA-dilatation         41         41      0.922     0.0732      0.106     0.0247\n",
      "Speed: 0.5ms preprocess, 1.3ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/obb/val3\u001b[0m\n",
      "Overall mAPs\n",
      "0.006184235891812866\n",
      "0.02644289473684211\n",
      "0.0\n",
      "classwise mAPs\n",
      "[          0           0           0    0.024737]\n",
      "Ultralytics 8.3.165 ðŸš€ Python-3.12.3 torch-2.6.0+cu124 CUDA:0 (Tesla V100-SXM2-32GB, 32501MiB)\n",
      "YOLO11s-obb summary (fused): 109 layers, 9,700,335 parameters, 0 gradients, 22.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3017.1Â±820.6 MB/s, size: 232.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/u3618315/obb_dataset/val/labels.cache... 184 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184/184 [00:00<?, ?it/s]\n",
      "/home/u3618315/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:02<00:00,  5.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        184        229      0.734     0.0183     0.0264    0.00618\n",
      "        LCA-brightness         52         54          0          0          0          0\n",
      "        LCA-dilatation        103        109          1          0          0          0\n",
      "        RCA-brightness         25         25          1          0          0          0\n",
      "        RCA-dilatation         41         41      0.936     0.0732      0.106     0.0247\n",
      "Speed: 0.3ms preprocess, 3.1ms inference, 0.0ms loss, 3.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/obb/val4\u001b[0m\n",
      "Overall mAPs\n",
      "0.006184235891812866\n",
      "0.02644289473684211\n",
      "0.0\n",
      "classwise mAPs\n",
      "[          0           0           0    0.024737]\n"
     ]
    }
   ],
   "source": [
    "#validation & test\n",
    "for i in range (4):\n",
    "    if i == 0:\n",
    "        weightaddress = str(f'{yolodir}runs/obb/train/weights/best.pt')\n",
    "    else:\n",
    "        weightaddress = str(f'{yolodir}runs/obb/train{i+1}/weights/best.pt')\n",
    "    model = YOLO(weightaddress)\n",
    "    val = model.val(data=yamldir)\n",
    "    \n",
    "    print(\"Overall mAPs\")\n",
    "    \n",
    "    print(val.box.map) #50/95\n",
    "    print(val.box.map50) #50\n",
    "    print(val.box.map75) #75\n",
    "    \n",
    "    print(\"classwise mAPs\")\n",
    "    print(val.box.maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir results1/\n",
    "!mkdir results2/\n",
    "!mkdir results3/\n",
    "!mkdir results4/\n",
    "#!mkdir results5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-51.png: 480x640 (no detections), 31.6ms\n",
      "Speed: 1.9ms preprocess, 31.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-51.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-33.png: 480x640 None4.8ms\n",
      "Speed: 1.8ms preprocess, 4.8ms inference, 11.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-33.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-108.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-108.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-106.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-106.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-170.png: 480x640 None5.2ms\n",
      "Speed: 2.2ms preprocess, 5.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-170.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-109.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqptamVs1103_2.png: 512x640 None31.7ms\n",
      "Speed: 1.9ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqptamVs1103_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-31.png: 480x640 None5.7ms\n",
      "Speed: 3.1ms preprocess, 5.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-31.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_3.mp4-3.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_3.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-6.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-6.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtkwqprZsKY-video1.mp4-137.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtkwqprZsKY-video1.mp4-137.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwqpta2tl1002_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 2.0ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Npwqpta2tl1002_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-31.png: 480x640 None5.1ms\n",
      "Speed: 1.8ms preprocess, 5.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-31.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-19.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-19.png: 480x640 None4.8ms\n",
      "Speed: 2.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-37.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-37.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-21.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_4.mp4-8.png: 480x640 (no detections), 6.1ms\n",
      "Speed: 2.6ms preprocess, 6.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_4.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-35.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-35.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwq1lamdk-M32069_1.mp4-75.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Npwq1lamdk-M32069_1.mp4-75.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqtoamdn1129_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqtoamdn1129_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video19.mp4-57.png: 480x640 None5.2ms\n",
      "Speed: 1.7ms preprocess, 5.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video19.mp4-57.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-66.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-66.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-11.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-118.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-119.png: 480x640 None4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-119.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-120.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-120.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1saWZp-M32069_1_1.mp4-38.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1saWZp-M32069_1_1.mp4-38.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqprY2dp1111_2.png: 512x640 (no detections), 5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqprY2dp1111_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-63.png: 480x640 None5.2ms\n",
      "Speed: 1.8ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-63.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-14.png: 480x640 None4.8ms\n",
      "Speed: 2.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-14.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-25.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-25.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video6.mp4-28.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 1.8ms preprocess, 5.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video6.mp4-28.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-119.png: 480x640 None5.1ms\n",
      "Speed: 1.8ms preprocess, 5.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-119.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtlacKbwps=-M32069_1_1.mp4-10.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtlacKbwps=-M32069_1_1.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-11.png: 480x640 None5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-178.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-178.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-86.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-86.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-163.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-163.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_4.mp4-134.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_4.mp4-134.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqpubG4=851_1.png: 512x640 (no detections), 5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtpwqpubG4=851_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-107.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.8ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-71.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.8ms preprocess, 4.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-71.png: 480x640 None4.8ms\n",
      "Speed: 2.2ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-127.png: 480x640 None4.9ms\n",
      "Speed: 2.6ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-127.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-117.png: 480x640 None5.5ms\n",
      "Speed: 2.1ms preprocess, 5.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-117.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqpsbGhj1100_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqpsbGhj1100_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-11.png: 480x640 None5.4ms\n",
      "Speed: 2.2ms preprocess, 5.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNowqxtaGdn-M32069_1_1.mp4-165.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNowqxtaGdn-M32069_1_1.mp4-165.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxpwqxma2s=1123_1.png: 512x640 None5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxpwqxma2s=1123_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqZuaGxs689_2.png: 512x640 None4.8ms\n",
      "Speed: 1.9ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqZuaGxs689_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxnwqtpZWw=936.png: 512x640 None4.7ms\n",
      "Speed: 1.9ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxnwqtpZWw=936.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1saWZp-M32069_1_2.mp4-40.png: 480x640 None5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1saWZp-M32069_1_2.mp4-40.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_4.mp4-26.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_4.mp4-26.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_4.mp4-222.png: 480x640 None4.8ms\n",
      "Speed: 1.8ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_4.mp4-222.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-42.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-42.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-46.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-46.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-150.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-150.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-39.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-39.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqtoamdn1151.png: 512x640 None5.1ms\n",
      "Speed: 1.9ms preprocess, 5.1ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqtoamdn1151.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-81.png: 480x640 None5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-81.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-62.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVuZsKXwps=-M32069_1_1.mp4-18.png: 480x640 None5.3ms\n",
      "Speed: 2.1ms preprocess, 5.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVuZsKXwps=-M32069_1_1.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-27.png: 480x640 None5.1ms\n",
      "Speed: 1.8ms preprocess, 5.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-27.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwq1lamdk-M32069_1.mp4-167.png: 480x640 (no detections), 5.4ms\n",
      "Speed: 1.9ms preprocess, 5.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Npwq1lamdk-M32069_1.mp4-167.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_4.mp4-221.png: 480x640 None5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_4.mp4-221.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-125.png: 480x640 None5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-125.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-123.png: 480x640 None4.9ms\n",
      "Speed: 2.0ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-123.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-81.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-81.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-69.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-69.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-108.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-108.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-32.png: 480x640 None5.4ms\n",
      "Speed: 2.4ms preprocess, 5.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-32.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-127.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-127.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwqxsbMKa-M32069_1_1.mp4-48.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwqxsbMKa-M32069_1_1.mp4-48.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-177.png: 480x640 None4.9ms\n",
      "Speed: 1.8ms preprocess, 4.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-177.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwqpta2tl1002_2.png: 512x640 None5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Npwqpta2tl1002_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-112.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-173.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-173.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1qY8KWwps=-M32069_1_2.mp4-109.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1qY8KWwps=-M32069_1_2.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-24.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.8ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video10.mp4-8.png: 480x640 (no detections), 5.4ms\n",
      "Speed: 2.1ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video10.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-95.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-95.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-10.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-112.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-110.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 2.4ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-110.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxjwqtmbMKZ-M32069_1_1.mp4-40.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxjwqtmbMKZ-M32069_1_1.mp4-40.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-57.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-57.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1saWZp-M32069_1_1.mp4-29.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1saWZp-M32069_1_1.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-161.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-161.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-76.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-76.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video1.mp4-55.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video1.mp4-55.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-160.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-160.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-15.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVraMKc-M32069_1_1.mp4-170.png: 480x640 None4.7ms\n",
      "Speed: 2.8ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVraMKc-M32069_1_1.mp4-170.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-77.png: 480x640 None4.7ms\n",
      "Speed: 2.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-77.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpuacKa-M32069_1_2.mp4-9.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpuacKa-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-68.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-68.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-10.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-119.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-119.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-98.png: 480x640 None4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-98.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-93.png: 480x640 None5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-93.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqxtY2Vl1163_2.png: 512x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqxtY2Vl1163_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-35.png: 480x640 (no detections), 5.5ms\n",
      "Speed: 1.7ms preprocess, 5.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-35.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-18.png: 480x640 None5.3ms\n",
      "Speed: 1.8ms preprocess, 5.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-118.png: 480x640 None5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-70.png: 480x640 None5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-70.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-44.png: 480x640 None5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-44.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqlnZ8KawqA=-M32069_1_1.mp4-161.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqlnZ8KawqA=-M32069_1_1.mp4-161.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-171.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-171.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video1.mp4-128.png: 480x640 None4.8ms\n",
      "Speed: 2.1ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video1.mp4-128.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNpwqxtY8KV-M32069_1_1.mp4-41.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNpwqxtY8KV-M32069_1_1.mp4-41.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-8.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-9.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-62.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-63.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-63.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_4.mp4-154.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_4.mp4-154.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-4.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-4.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_4.mp4-16.png: 480x640 None4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_4.mp4-16.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNpwqxoY8KVwpk=-M32069_1_1.mp4-40.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 2.1ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNpwqxoY8KVwpk=-M32069_1_1.mp4-40.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-108.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-108.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-169.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-169.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-169.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-169.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-100.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVqacKVwpc=-M32069_1_1.mp4-3.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 2.8ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVqacKVwpc=-M32069_1_1.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-10.png: 480x640 None5.5ms\n",
      "Speed: 2.4ms preprocess, 5.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-116.png: 480x640 None5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-116.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-86.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-86.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-12.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-12.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-29.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video6.mp4-3.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video6.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-34.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-34.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video3.mp4-155.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video3.mp4-155.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-92.png: 480x640 None4.8ms\n",
      "Speed: 2.1ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-92.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video5.mp4-1.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video5.mp4-1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-112.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtnwqloa8KZ-M32069_1_1.mp4-169.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtnwqloa8KZ-M32069_1_1.mp4-169.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-161.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-161.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-4.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-4.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-7.png: 480x640 None5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-7.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-131.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-131.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-150.png: 480x640 None4.7ms\n",
      "Speed: 2.1ms preprocess, 4.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-150.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-80.png: 480x640 (no detections), 5.4ms\n",
      "Speed: 1.9ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-80.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-144.png: 480x640 None4.7ms\n",
      "Speed: 2.0ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-144.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-22.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-22.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-101.png: 480x640 None5.5ms\n",
      "Speed: 2.0ms preprocess, 5.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-101.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_4.mp4-14.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_4.mp4-14.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-63.png: 480x640 None5.3ms\n",
      "Speed: 2.9ms preprocess, 5.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-63.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-118.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-176.png: 480x640 None4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-176.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-121.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-121.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-152.png: 480x640 None5.2ms\n",
      "Speed: 2.2ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-152.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-17.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-28.png: 480x640 None4.9ms\n",
      "Speed: 1.8ms preprocess, 4.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-28.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-23.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 2.3ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-23.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-77.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-77.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdraG5o940_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 2.0ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqdraG5o940_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-31.png: 480x640 None5.2ms\n",
      "Speed: 1.8ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-31.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-19.png: 480x640 None5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-24.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVoa8KT-M32069_1_2.mp4-82.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVoa8KT-M32069_1_2.mp4-82.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtmwqpua2w=463.png: 512x640 None5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtmwqpua2w=463.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-136.png: 480x640 None5.7ms\n",
      "Speed: 2.2ms preprocess, 5.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-136.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-156.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-156.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-18.png: 480x640 None5.3ms\n",
      "Speed: 1.8ms preprocess, 5.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-96.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-96.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-90.png: 480x640 None4.9ms\n",
      "Speed: 1.8ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-90.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_2.mp4-41.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.8ms preprocess, 5.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_2.mp4-41.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video8.mp4-58.png: 480x640 None5.1ms\n",
      "Speed: 1.9ms preprocess, 5.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video8.mp4-58.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-158.png: 480x640 None4.9ms\n",
      "Speed: 2.2ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-158.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video19.mp4-179.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video19.mp4-179.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-162.png: 480x640 None4.7ms\n",
      "Speed: 2.2ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-162.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-2.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-64.png: 480x640 None5.4ms\n",
      "Speed: 2.1ms preprocess, 5.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-64.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-100.png: 480x640 None5.7ms\n",
      "Speed: 2.3ms preprocess, 5.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-174.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-174.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-88.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-88.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-13.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-13.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video11.mp4-44.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video11.mp4-44.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_3.mp4-113.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_3.mp4-113.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-38.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 2.1ms preprocess, 5.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-38.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxpwqZpaWw=1018.png: 512x640 (no detections), 5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxpwqZpaWw=1018.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-102.png: 480x640 None6.1ms\n",
      "Speed: 2.3ms preprocess, 6.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-102.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-131.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-131.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-11.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-19.png: 480x640 (no detections), 5.4ms\n",
      "Speed: 2.2ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video3.mp4-52.png: 480x640 (no detections), 5.6ms\n",
      "Speed: 2.5ms preprocess, 5.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video3.mp4-52.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-73.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-73.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxnwqxmbGg=-M32069_1_4.mp4-47.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxnwqxmbGg=-M32069_1_4.mp4-47.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-27.png: 480x640 None4.7ms\n",
      "Speed: 3.3ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-27.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-144.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.8ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-144.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-62.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwqxsbMKa-M32069_1_1.mp4-72.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwqxsbMKa-M32069_1_1.mp4-72.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqpuY8KYwpk=-M32069_1_1.mp4-17.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqpuY8KYwpk=-M32069_1_1.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-88.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-88.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-66.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-66.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq5lbMKZwps=-M32069_1_1.mp4-118.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 2.3ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq5lbMKZwps=-M32069_1_1.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-122.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-122.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_1.mp4-25.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_1.mp4-25.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-71.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqtnZGdo1044.png: 512x640 None5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqtnZGdo1044.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-173.png: 480x640 None5.2ms\n",
      "Speed: 1.7ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-173.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-15.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video11.mp4-8.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 2.0ms preprocess, 5.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video11.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVuZsKXwps=-M32069_1_2.mp4-79.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVuZsKXwps=-M32069_1_2.mp4-79.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_3.mp4-15.png: 480x640 None5.1ms\n",
      "Speed: 2.8ms preprocess, 5.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_3.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwqxsaWw=911_2.png: 512x640 None5.3ms\n",
      "Speed: 2.2ms preprocess, 5.3ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxmwqxsaWw=911_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-107.png: 480x640 None5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-175.png: 480x640 None4.8ms\n",
      "Speed: 2.4ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-175.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-24.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-53.png: 480x640 None5.2ms\n",
      "Speed: 2.1ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-53.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqlmaWtq823.png: 512x640 None5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqlmaWtq823.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVsZcKVwp8=-M32069_1_2.mp4-5.png: 480x640 (no detections), 5.6ms\n",
      "Speed: 1.8ms preprocess, 5.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVsZcKVwp8=-M32069_1_2.mp4-5.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVsZcKVwp8=-M32069_1_2.mp4-9.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVsZcKVwp8=-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video10.mp4-22.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video10.mp4-22.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_5.mp4-18.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 2.9ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_5.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_2.mp4-83.png: 480x640 None5.6ms\n",
      "Speed: 2.6ms preprocess, 5.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_2.mp4-83.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-82.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-82.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1qY8KWwps=-M32069_1_1.mp4-15.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1qY8KWwps=-M32069_1_1.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-73.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-73.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-90.png: 480x640 None4.8ms\n",
      "Speed: 1.8ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-90.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_1.mp4-12.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 2.1ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_1.mp4-12.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_1.mp4-30.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_1.mp4-30.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-21.png: 480x640 None4.8ms\n",
      "Speed: 2.1ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-114.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-114.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxkwq5qaWw=779_2.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 2.2ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxkwq5qaWw=779_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtkwqprZsKY-video1.mp4-56.png: 480x640 None5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtkwqprZsKY-video1.mp4-56.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxjwqtmbMKZ-M32069_1_2.mp4-20.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxjwqtmbMKZ-M32069_1_2.mp4-20.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-143.png: 480x640 None5.8ms\n",
      "Speed: 2.4ms preprocess, 5.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-143.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-18.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-111.png: 480x640 None5.2ms\n",
      "Speed: 2.0ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-111.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video3.mp4-73.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video3.mp4-73.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video2.mp4-72.png: 480x640 None5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video2.mp4-72.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-61.png: 480x640 None5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-61.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-126.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-126.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-146.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-146.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-111.png: 480x640 None4.9ms\n",
      "Speed: 16.3ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-111.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-25.png: 480x640 None4.8ms\n",
      "Speed: 1.8ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-25.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-153.png: 480x640 None5.3ms\n",
      "Speed: 2.1ms preprocess, 5.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-153.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-86.png: 480x640 None5.2ms\n",
      "Speed: 2.8ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-86.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqhoZMKTwpo=-832005_1_4.mp4-57.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NowqhoZMKTwpo=-832005_1_4.mp4-57.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-83.png: 480x640 None4.7ms\n",
      "Speed: 1.8ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-83.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqxtY2Vl1164_1.png: 512x640 None5.2ms\n",
      "Speed: 2.0ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqxtY2Vl1164_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video18.mp4-135.png: 480x640 None5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video18.mp4-135.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqhoZGVm-832005_1_2.mp4-3.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NowqhoZGVm-832005_1_2.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-135.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-135.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-28.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-28.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video8.mp4-59.png: 480x640 None4.7ms\n",
      "Speed: 2.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video8.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-62.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxnwqxmbGg=-M32069_1_5.mp4-46.png: 480x640 None4.7ms\n",
      "Speed: 2.3ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxnwqxmbGg=-M32069_1_5.mp4-46.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-9.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video14.mp4-0.png: 480x640 None5.6ms\n",
      "Speed: 2.1ms preprocess, 5.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video14.mp4-0.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVoa8KT-M32069_1_1.mp4-38.png: 480x640 None5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVoa8KT-M32069_1_1.mp4-38.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-99.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-99.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtoZW1n1122.png: 512x640 (no detections), 5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqtoZW1n1122.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-72.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.7ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-72.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-70.png: 480x640 None4.8ms\n",
      "Speed: 2.1ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-70.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtrwqZmZGg=811_2.png: 512x640 None5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtrwqZmZGg=811_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video6.mp4-29.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 3.2ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video6.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-172.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-172.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtkwqprZsKY-video1.mp4-51.png: 480x640 None4.9ms\n",
      "Speed: 1.8ms preprocess, 4.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtkwqprZsKY-video1.mp4-51.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-103.png: 480x640 None4.9ms\n",
      "Speed: 2.0ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-103.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqpsZGZp992_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqpsZGZp992_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-130.png: 480x640 None5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-130.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-104.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-104.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqttZ8KXwqA=-M32069_1_2.mp4-39.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqttZ8KXwqA=-M32069_1_2.mp4-39.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_2.mp4-105.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_2.mp4-105.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtlacKbwps=-M32069_1_1.mp4-41.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtlacKbwps=-M32069_1_1.mp4-41.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-11.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-20.png: 480x640 None4.8ms\n",
      "Speed: 1.8ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-20.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-205.png: 480x640 None6.0ms\n",
      "Speed: 2.3ms preprocess, 6.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-205.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq5paWll1215_1.png: 512x640 (no detections), 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwq5paWll1215_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVuZsKXwps=-M32069_1_2.mp4-9.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVuZsKXwps=-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-174.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-174.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqhuaMKYwpk=-832005_1_1.mp4-100.png: 480x640 None4.8ms\n",
      "Speed: 2.7ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NowqhuaMKYwpk=-832005_1_1.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video4.mp4-8.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video4.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pam0=348_1.png: 512x640 None5.7ms\n",
      "Speed: 2.0ms preprocess, 5.7ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtiwq1pam0=348_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqVua2Vj910.png: 512x640 (no detections), 4.9ms\n",
      "Speed: 1.9ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqVua2Vj910.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-175.png: 480x640 None6.0ms\n",
      "Speed: 2.2ms preprocess, 6.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-175.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-52.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-52.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video4.mp4-85.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video4.mp4-85.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_3.mp4-14.png: 480x640 None5.5ms\n",
      "Speed: 2.8ms preprocess, 5.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_3.mp4-14.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-95.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-95.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video19.mp4-181.png: 480x640 None4.9ms\n",
      "Speed: 3.0ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video19.mp4-181.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVsaMKXwpo=-M32069_1_1.mp4-19.png: 480x640 None5.1ms\n",
      "Speed: 2.1ms preprocess, 5.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVsaMKXwpo=-M32069_1_1.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NnwqplZm1r613_2.png: 512x640 None5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NnwqplZm1r613_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-158.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-158.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-162.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-162.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-76.png: 480x640 None4.9ms\n",
      "Speed: 1.8ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-76.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_4.mp4-46.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_4.mp4-46.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-59.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-18.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqtoamdn1129_2.png: 512x640 (no detections), 5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqtoamdn1129_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-112.png: 480x640 None5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqpram5p1087_1.png: 512x640 (no detections), 5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqpram5p1087_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-4.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-4.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVoa8KT-M32069_1_2.mp4-125.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVoa8KT-M32069_1_2.mp4-125.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video7.mp4-19.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video7.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVmaWZp1197.png: 512x640 (no detections), 5.1ms\n",
      "Speed: 1.9ms preprocess, 5.1ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amRiwqVmaWZp1197.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-100.png: 480x640 None5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-177.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-177.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-2.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxowq5pZGk=-M32069_1_1.mp4-21.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxowq5pZGk=-M32069_1_1.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-109.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNowqxtaGdn-M32069_1_1.mp4-147.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNowqxtaGdn-M32069_1_1.mp4-147.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-17.png: 480x640 None5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-170.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-170.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-145.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-145.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-32.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-32.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-95.png: 480x640 None5.6ms\n",
      "Speed: 2.1ms preprocess, 5.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-95.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtrZcKWwpw=-M32069_1_1.mp4-79.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtrZcKWwpw=-M32069_1_1.mp4-79.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-61.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-61.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-71.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-129.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-129.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNpwq1sZGg=1023_2.png: 512x640 None5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amNpwq1sZGg=1023_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-88.png: 480x640 None5.6ms\n",
      "Speed: 1.8ms preprocess, 5.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-88.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-53.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-53.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-75.png: 480x640 None5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-75.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-32.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-32.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-74.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-74.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNowqxtaGdn-M32069_1_1.mp4-24.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNowqxtaGdn-M32069_1_1.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-127.png: 480x640 None5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-127.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-160.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-160.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-135.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-135.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-149.png: 480x640 None4.7ms\n",
      "Speed: 1.9ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-149.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1qY8KWwps=-M32069_1_2.mp4-107.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1qY8KWwps=-M32069_1_2.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-149.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-149.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-9.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-58.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-58.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-56.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-56.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-59.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video1.mp4-109.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video1.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video5.mp4-171.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video5.mp4-171.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpoZ8Kc-M32069_1_2.mp4-85.png: 480x640 None5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpoZ8Kc-M32069_1_2.mp4-85.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_1.mp4-29.png: 480x640 None5.3ms\n",
      "Speed: 2.1ms preprocess, 5.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_1.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-123.png: 480x640 None4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-123.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-54.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 2.2ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-54.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-126.png: 480x640 None5.2ms\n",
      "Speed: 2.0ms preprocess, 5.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-126.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-47.png: 480x640 None5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-47.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-12.png: 480x640 None5.6ms\n",
      "Speed: 2.2ms preprocess, 5.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-12.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-162.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 2.0ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-162.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-115.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-115.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-180.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-180.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-103.png: 480x640 None5.9ms\n",
      "Speed: 2.3ms preprocess, 5.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-103.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-83.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-83.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-67.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-67.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-17.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-70.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-70.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_6.mp4-155.png: 480x640 None4.7ms\n",
      "Speed: 2.1ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_6.mp4-155.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_4.mp4-15.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_4.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpoZ8Kc-M32069_1_2.mp4-91.png: 480x640 None4.7ms\n",
      "Speed: 2.8ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpoZ8Kc-M32069_1_2.mp4-91.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpoZ8Kc-M32069_1_2.mp4-84.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpoZ8Kc-M32069_1_2.mp4-84.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video5.mp4-59.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video5.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtlacKbwps=-M32069_1_1.mp4-107.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 2.8ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtlacKbwps=-M32069_1_1.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_4.mp4-9.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 2.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_4.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-112.png: 480x640 None4.7ms\n",
      "Speed: 1.8ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVqacKVwpc=-M32069_1_1.mp4-16.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVqacKVwpc=-M32069_1_1.mp4-16.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-105.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-105.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-78.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-78.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video12.mp4-5.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video12.mp4-5.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtlwqxuZ2g=427_1.png: 512x640 None5.3ms\n",
      "Speed: 2.0ms preprocess, 5.3ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtlwqxuZ2g=427_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-171.png: 480x640 None5.1ms\n",
      "Speed: 2.1ms preprocess, 5.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-171.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqpuY8KYwpk=-M32069_1_1.mp4-102.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqpuY8KYwpk=-M32069_1_1.mp4-102.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-7.png: 480x640 None5.4ms\n",
      "Speed: 1.9ms preprocess, 5.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-7.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-172.png: 480x640 None4.7ms\n",
      "Speed: 2.0ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-172.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video9.mp4-21.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video9.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video4.mp4-13.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video4.mp4-13.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-75.png: 480x640 None4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-75.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-18.png: 480x640 None4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-117.png: 480x640 None4.7ms\n",
      "Speed: 2.5ms preprocess, 4.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-117.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-51.png: 480x640 (no detections), 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-51.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-33.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.8ms preprocess, 4.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-33.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-108.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.8ms preprocess, 4.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-108.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-106.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-106.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-170.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-170.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-109.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqptamVs1103_2.png: 512x640 (no detections), 30.3ms\n",
      "Speed: 1.9ms preprocess, 30.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqptamVs1103_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-31.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-31.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_3.mp4-3.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 2.1ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_3.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-6.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-6.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtkwqprZsKY-video1.mp4-137.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtkwqprZsKY-video1.mp4-137.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwqpta2tl1002_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Npwqpta2tl1002_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-31.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-31.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-19.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-19.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 1.8ms preprocess, 5.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-37.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-37.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-21.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_4.mp4-8.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_4.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-35.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-35.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwq1lamdk-M32069_1.mp4-75.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Npwq1lamdk-M32069_1.mp4-75.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqtoamdn1129_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqtoamdn1129_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video19.mp4-57.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video19.mp4-57.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-66.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-66.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-11.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 2.1ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-118.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-119.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-119.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-120.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-120.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1saWZp-M32069_1_1.mp4-38.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1saWZp-M32069_1_1.mp4-38.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqprY2dp1111_2.png: 512x640 (no detections), 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqprY2dp1111_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-63.png: 480x640 (no detections), 5.4ms\n",
      "Speed: 1.7ms preprocess, 5.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-63.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-14.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-14.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-25.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-25.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video6.mp4-28.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video6.mp4-28.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-119.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 2.2ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-119.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtlacKbwps=-M32069_1_1.mp4-10.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtlacKbwps=-M32069_1_1.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-11.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-178.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-178.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-86.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-86.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-163.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-163.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_4.mp4-134.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_4.mp4-134.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqpubG4=851_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtpwqpubG4=851_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-107.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-71.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-71.png: 480x640 (no detections), 5.4ms\n",
      "Speed: 2.1ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-127.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-127.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-117.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-117.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqpsbGhj1100_1.png: 512x640 (no detections), 5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqpsbGhj1100_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-11.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.7ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNowqxtaGdn-M32069_1_1.mp4-165.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNowqxtaGdn-M32069_1_1.mp4-165.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxpwqxma2s=1123_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxpwqxma2s=1123_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqZuaGxs689_2.png: 512x640 (no detections), 4.9ms\n",
      "Speed: 1.9ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqZuaGxs689_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxnwqtpZWw=936.png: 512x640 (no detections), 4.9ms\n",
      "Speed: 1.9ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxnwqtpZWw=936.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1saWZp-M32069_1_2.mp4-40.png: 480x640 (no detections), 5.6ms\n",
      "Speed: 1.7ms preprocess, 5.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1saWZp-M32069_1_2.mp4-40.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_4.mp4-26.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_4.mp4-26.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_4.mp4-222.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_4.mp4-222.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-42.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-42.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-46.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-46.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-150.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-150.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-39.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-39.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqtoamdn1151.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqtoamdn1151.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-81.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.7ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-81.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-62.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 2.7ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVuZsKXwps=-M32069_1_1.mp4-18.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVuZsKXwps=-M32069_1_1.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-27.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-27.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwq1lamdk-M32069_1.mp4-167.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Npwq1lamdk-M32069_1.mp4-167.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_4.mp4-221.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_4.mp4-221.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-125.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-125.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-123.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 2.9ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-123.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-81.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-81.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-69.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-69.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-108.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-108.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-32.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 2.2ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-32.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-127.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.9ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-127.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwqxsbMKa-M32069_1_1.mp4-48.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwqxsbMKa-M32069_1_1.mp4-48.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-177.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-177.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwqpta2tl1002_2.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Npwqpta2tl1002_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-112.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-173.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-173.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1qY8KWwps=-M32069_1_2.mp4-109.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 2.0ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1qY8KWwps=-M32069_1_2.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-24.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video10.mp4-8.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video10.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-95.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-95.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-10.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-112.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-110.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-110.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxjwqtmbMKZ-M32069_1_1.mp4-40.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxjwqtmbMKZ-M32069_1_1.mp4-40.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-57.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-57.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1saWZp-M32069_1_1.mp4-29.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1saWZp-M32069_1_1.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-161.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-161.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-76.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-76.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video1.mp4-55.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video1.mp4-55.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-160.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-160.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-15.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVraMKc-M32069_1_1.mp4-170.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVraMKc-M32069_1_1.mp4-170.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-77.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-77.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpuacKa-M32069_1_2.mp4-9.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpuacKa-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-68.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-68.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-10.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-119.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-119.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-98.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-98.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-93.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-93.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqxtY2Vl1163_2.png: 512x640 (no detections), 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqxtY2Vl1163_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-35.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-35.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-18.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-118.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-70.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-70.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-44.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 1.8ms preprocess, 5.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-44.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqlnZ8KawqA=-M32069_1_1.mp4-161.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqlnZ8KawqA=-M32069_1_1.mp4-161.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-171.png: 480x640 (no detections), 5.5ms\n",
      "Speed: 2.2ms preprocess, 5.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-171.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video1.mp4-128.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video1.mp4-128.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNpwqxtY8KV-M32069_1_1.mp4-41.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNpwqxtY8KV-M32069_1_1.mp4-41.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-8.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-9.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-62.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-63.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-63.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_4.mp4-154.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 2.0ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_4.mp4-154.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-4.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-4.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_4.mp4-16.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_4.mp4-16.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNpwqxoY8KVwpk=-M32069_1_1.mp4-40.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNpwqxoY8KVwpk=-M32069_1_1.mp4-40.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-108.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-108.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-169.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-169.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-169.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-169.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-100.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVqacKVwpc=-M32069_1_1.mp4-3.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVqacKVwpc=-M32069_1_1.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-10.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-116.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-116.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-86.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-86.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-12.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-12.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-29.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video6.mp4-3.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 2.6ms preprocess, 5.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video6.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-34.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-34.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video3.mp4-155.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video3.mp4-155.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-92.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-92.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video5.mp4-1.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video5.mp4-1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-112.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtnwqloa8KZ-M32069_1_1.mp4-169.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtnwqloa8KZ-M32069_1_1.mp4-169.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-161.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-161.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-4.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-4.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-7.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-7.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-131.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-131.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-150.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-150.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-80.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-80.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-144.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-144.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-22.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-22.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-101.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-101.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_4.mp4-14.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_4.mp4-14.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-63.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-63.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-118.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-176.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-176.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-121.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-121.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-152.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-152.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-17.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-28.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-28.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-23.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-23.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-77.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-77.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdraG5o940_1.png: 512x640 (no detections), 5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqdraG5o940_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-31.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.7ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-31.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-19.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-24.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVoa8KT-M32069_1_2.mp4-82.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVoa8KT-M32069_1_2.mp4-82.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtmwqpua2w=463.png: 512x640 (no detections), 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtmwqpua2w=463.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-136.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-136.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-156.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-156.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-18.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-96.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-96.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-90.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-90.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_2.mp4-41.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_2.mp4-41.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video8.mp4-58.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video8.mp4-58.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-158.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-158.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video19.mp4-179.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video19.mp4-179.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-162.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-162.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-2.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-64.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-64.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-100.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-174.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-174.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-88.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-88.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-13.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-13.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video11.mp4-44.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video11.mp4-44.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_3.mp4-113.png: 480x640 (no detections), 5.4ms\n",
      "Speed: 2.9ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_3.mp4-113.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-38.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-38.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxpwqZpaWw=1018.png: 512x640 (no detections), 5.7ms\n",
      "Speed: 2.0ms preprocess, 5.7ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxpwqZpaWw=1018.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-102.png: 480x640 (no detections), 5.6ms\n",
      "Speed: 1.7ms preprocess, 5.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-102.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-131.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-131.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-11.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-19.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video3.mp4-52.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video3.mp4-52.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-73.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 1.7ms preprocess, 5.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-73.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxnwqxmbGg=-M32069_1_4.mp4-47.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxnwqxmbGg=-M32069_1_4.mp4-47.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-27.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-27.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-144.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-144.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-62.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwqxsbMKa-M32069_1_1.mp4-72.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwqxsbMKa-M32069_1_1.mp4-72.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqpuY8KYwpk=-M32069_1_1.mp4-17.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqpuY8KYwpk=-M32069_1_1.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-88.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 3.0ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-88.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-66.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-66.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq5lbMKZwps=-M32069_1_1.mp4-118.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq5lbMKZwps=-M32069_1_1.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-122.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-122.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_1.mp4-25.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_1.mp4-25.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-71.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqtnZGdo1044.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqtnZGdo1044.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-173.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.7ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-173.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-15.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video11.mp4-8.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video11.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVuZsKXwps=-M32069_1_2.mp4-79.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVuZsKXwps=-M32069_1_2.mp4-79.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_3.mp4-15.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_3.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwqxsaWw=911_2.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxmwqxsaWw=911_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-107.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-175.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.8ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-175.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-24.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-53.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-53.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqlmaWtq823.png: 512x640 (no detections), 5.4ms\n",
      "Speed: 2.0ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqlmaWtq823.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVsZcKVwp8=-M32069_1_2.mp4-5.png: 480x640 (no detections), 5.6ms\n",
      "Speed: 1.8ms preprocess, 5.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVsZcKVwp8=-M32069_1_2.mp4-5.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVsZcKVwp8=-M32069_1_2.mp4-9.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.7ms preprocess, 5.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVsZcKVwp8=-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video10.mp4-22.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video10.mp4-22.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_5.mp4-18.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 2.4ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_5.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_2.mp4-83.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_2.mp4-83.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-82.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.8ms preprocess, 5.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-82.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1qY8KWwps=-M32069_1_1.mp4-15.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 1.8ms preprocess, 5.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1qY8KWwps=-M32069_1_1.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-73.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-73.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-90.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-90.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_1.mp4-12.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_1.mp4-12.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_1.mp4-30.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_1.mp4-30.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-21.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-114.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-114.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxkwq5qaWw=779_2.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxkwq5qaWw=779_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtkwqprZsKY-video1.mp4-56.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.7ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtkwqprZsKY-video1.mp4-56.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxjwqtmbMKZ-M32069_1_2.mp4-20.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.8ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxjwqtmbMKZ-M32069_1_2.mp4-20.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-143.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 2.1ms preprocess, 5.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-143.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-18.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-111.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-111.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video3.mp4-73.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video3.mp4-73.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video2.mp4-72.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video2.mp4-72.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-61.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-61.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-126.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-126.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-146.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-146.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-111.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-111.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-25.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-25.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-153.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-153.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-86.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-86.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqhoZMKTwpo=-832005_1_4.mp4-57.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NowqhoZMKTwpo=-832005_1_4.mp4-57.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-83.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-83.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqxtY2Vl1164_1.png: 512x640 (no detections), 5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqxtY2Vl1164_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video18.mp4-135.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.7ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video18.mp4-135.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqhoZGVm-832005_1_2.mp4-3.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NowqhoZGVm-832005_1_2.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-135.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-135.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-28.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-28.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video8.mp4-59.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video8.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-62.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxnwqxmbGg=-M32069_1_5.mp4-46.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxnwqxmbGg=-M32069_1_5.mp4-46.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-9.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video14.mp4-0.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video14.mp4-0.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVoa8KT-M32069_1_1.mp4-38.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVoa8KT-M32069_1_1.mp4-38.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-99.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-99.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtoZW1n1122.png: 512x640 (no detections), 5.4ms\n",
      "Speed: 1.9ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqtoZW1n1122.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-72.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-72.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-70.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-70.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtrwqZmZGg=811_2.png: 512x640 (no detections), 5.4ms\n",
      "Speed: 1.9ms preprocess, 5.4ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtrwqZmZGg=811_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video6.mp4-29.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video6.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-172.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-172.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtkwqprZsKY-video1.mp4-51.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtkwqprZsKY-video1.mp4-51.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-103.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-103.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqpsZGZp992_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqpsZGZp992_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-130.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.7ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-130.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-104.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-104.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqttZ8KXwqA=-M32069_1_2.mp4-39.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqttZ8KXwqA=-M32069_1_2.mp4-39.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_2.mp4-105.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 1.8ms preprocess, 5.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_2.mp4-105.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtlacKbwps=-M32069_1_1.mp4-41.png: 480x640 (no detections), 5.0ms\n",
      "Speed: 1.8ms preprocess, 5.0ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtlacKbwps=-M32069_1_1.mp4-41.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-11.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-20.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-20.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-205.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-205.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq5paWll1215_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwq5paWll1215_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVuZsKXwps=-M32069_1_2.mp4-9.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.7ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVuZsKXwps=-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-174.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-174.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqhuaMKYwpk=-832005_1_1.mp4-100.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NowqhuaMKYwpk=-832005_1_1.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video4.mp4-8.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video4.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pam0=348_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtiwq1pam0=348_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqVua2Vj910.png: 512x640 (no detections), 4.9ms\n",
      "Speed: 1.9ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqVua2Vj910.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-175.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-175.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-52.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-52.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video4.mp4-85.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video4.mp4-85.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_3.mp4-14.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_3.mp4-14.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-95.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-95.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video19.mp4-181.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video19.mp4-181.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVsaMKXwpo=-M32069_1_1.mp4-19.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVsaMKXwpo=-M32069_1_1.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NnwqplZm1r613_2.png: 512x640 (no detections), 5.2ms\n",
      "Speed: 1.9ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NnwqplZm1r613_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-158.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-158.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-162.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-162.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-76.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-76.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_4.mp4-46.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_4.mp4-46.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-59.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-18.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 1.8ms preprocess, 5.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqtoamdn1129_2.png: 512x640 (no detections), 5.4ms\n",
      "Speed: 1.9ms preprocess, 5.4ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqtoamdn1129_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-112.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqpram5p1087_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqpram5p1087_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-4.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-4.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVoa8KT-M32069_1_2.mp4-125.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVoa8KT-M32069_1_2.mp4-125.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video7.mp4-19.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video7.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVmaWZp1197.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amRiwqVmaWZp1197.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-100.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-177.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-177.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-2.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxowq5pZGk=-M32069_1_1.mp4-21.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxowq5pZGk=-M32069_1_1.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-109.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNowqxtaGdn-M32069_1_1.mp4-147.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNowqxtaGdn-M32069_1_1.mp4-147.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-17.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-170.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-170.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-145.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-145.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-32.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-32.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-95.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-95.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtrZcKWwpw=-M32069_1_1.mp4-79.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtrZcKWwpw=-M32069_1_1.mp4-79.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-61.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-61.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-71.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-129.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-129.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNpwq1sZGg=1023_2.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amNpwq1sZGg=1023_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-88.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 1.7ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-88.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-53.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-53.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-75.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 2.1ms preprocess, 5.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-75.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-32.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-32.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-74.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 2.3ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-74.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNowqxtaGdn-M32069_1_1.mp4-24.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 2.3ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNowqxtaGdn-M32069_1_1.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-127.png: 480x640 (no detections), 5.2ms\n",
      "Speed: 2.1ms preprocess, 5.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-127.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-160.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-160.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-135.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-135.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-149.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-149.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1qY8KWwps=-M32069_1_2.mp4-107.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1qY8KWwps=-M32069_1_2.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-149.png: 480x640 (no detections), 5.1ms\n",
      "Speed: 2.1ms preprocess, 5.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-149.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-9.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-58.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-58.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-56.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-56.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-59.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video1.mp4-109.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video1.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video5.mp4-171.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video5.mp4-171.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpoZ8Kc-M32069_1_2.mp4-85.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 2.1ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpoZ8Kc-M32069_1_2.mp4-85.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_1.mp4-29.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_1.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-123.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.7ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-123.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-54.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-54.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-126.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-126.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-47.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-47.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-12.png: 480x640 (no detections), 4.7ms\n",
      "Speed: 1.7ms preprocess, 4.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-12.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-162.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-162.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-115.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.9ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-115.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-180.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-180.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-103.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 2.1ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-103.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-83.png: 480x640 (no detections), 5.5ms\n",
      "Speed: 2.4ms preprocess, 5.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-83.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-67.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-67.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-17.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-70.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-70.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_6.mp4-155.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_6.mp4-155.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_4.mp4-15.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_4.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpoZ8Kc-M32069_1_2.mp4-91.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpoZ8Kc-M32069_1_2.mp4-91.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpoZ8Kc-M32069_1_2.mp4-84.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpoZ8Kc-M32069_1_2.mp4-84.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video5.mp4-59.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video5.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtlacKbwps=-M32069_1_1.mp4-107.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtlacKbwps=-M32069_1_1.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_4.mp4-9.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_4.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-112.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVqacKVwpc=-M32069_1_1.mp4-16.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVqacKVwpc=-M32069_1_1.mp4-16.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-105.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-105.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-78.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-78.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video12.mp4-5.png: 480x640 (no detections), 4.9ms\n",
      "Speed: 1.9ms preprocess, 4.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video12.mp4-5.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtlwqxuZ2g=427_1.png: 512x640 (no detections), 5.3ms\n",
      "Speed: 1.9ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtlwqxuZ2g=427_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-171.png: 480x640 (no detections), 5.3ms\n",
      "Speed: 1.7ms preprocess, 5.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-171.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqpuY8KYwpk=-M32069_1_1.mp4-102.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqpuY8KYwpk=-M32069_1_1.mp4-102.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-7.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-7.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-172.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-172.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video9.mp4-21.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video9.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video4.mp4-13.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video4.mp4-13.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-75.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-75.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-18.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-117.png: 480x640 (no detections), 4.8ms\n",
      "Speed: 1.7ms preprocess, 4.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-117.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-51.png: 480x640 None17.9ms\n",
      "Speed: 1.9ms preprocess, 17.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-51.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-33.png: 480x640 None6.6ms\n",
      "Speed: 1.8ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-33.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-108.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.8ms preprocess, 6.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-108.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-106.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-106.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-170.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-170.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-109.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqptamVs1103_2.png: 512x640 None18.0ms\n",
      "Speed: 1.9ms preprocess, 18.0ms inference, 2.1ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqptamVs1103_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-31.png: 480x640 None7.2ms\n",
      "Speed: 2.2ms preprocess, 7.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-31.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_3.mp4-3.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_3.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-6.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-6.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtkwqprZsKY-video1.mp4-137.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtkwqprZsKY-video1.mp4-137.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwqpta2tl1002_1.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Npwqpta2tl1002_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-31.png: 480x640 None6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-31.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-19.png: 480x640 None6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-19.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-37.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-37.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-21.png: 480x640 None6.4ms\n",
      "Speed: 2.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_4.mp4-8.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_4.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-35.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-35.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwq1lamdk-M32069_1.mp4-75.png: 480x640 (no detections), 7.0ms\n",
      "Speed: 2.3ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Npwq1lamdk-M32069_1.mp4-75.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqtoamdn1129_1.png: 512x640 (no detections), 6.9ms\n",
      "Speed: 2.0ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqtoamdn1129_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video19.mp4-57.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video19.mp4-57.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-66.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-66.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-11.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-118.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-119.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-119.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-120.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-120.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1saWZp-M32069_1_1.mp4-38.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1saWZp-M32069_1_1.mp4-38.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqprY2dp1111_2.png: 512x640 (no detections), 7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqprY2dp1111_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-63.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-63.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-14.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-14.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-25.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-25.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video6.mp4-28.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video6.mp4-28.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-119.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-119.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtlacKbwps=-M32069_1_1.mp4-10.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtlacKbwps=-M32069_1_1.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-11.png: 480x640 None6.7ms\n",
      "Speed: 2.9ms preprocess, 6.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-178.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-178.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-86.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-86.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-163.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-163.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_4.mp4-134.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_4.mp4-134.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqpubG4=851_1.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtpwqpubG4=851_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-107.png: 480x640 (no detections), 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-71.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-71.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-127.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-127.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-117.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-117.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqpsbGhj1100_1.png: 512x640 (no detections), 6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqpsbGhj1100_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-11.png: 480x640 None6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNowqxtaGdn-M32069_1_1.mp4-165.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNowqxtaGdn-M32069_1_1.mp4-165.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxpwqxma2s=1123_1.png: 512x640 (no detections), 6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxpwqxma2s=1123_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqZuaGxs689_2.png: 512x640 None6.6ms\n",
      "Speed: 1.9ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqZuaGxs689_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxnwqtpZWw=936.png: 512x640 None6.6ms\n",
      "Speed: 1.9ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxnwqtpZWw=936.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1saWZp-M32069_1_2.mp4-40.png: 480x640 (no detections), 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1saWZp-M32069_1_2.mp4-40.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_4.mp4-26.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_4.mp4-26.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_4.mp4-222.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_4.mp4-222.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-42.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-42.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-46.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-46.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-150.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-150.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-39.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-39.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqtoamdn1151.png: 512x640 (no detections), 6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqtoamdn1151.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-81.png: 480x640 None6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-81.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-62.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVuZsKXwps=-M32069_1_1.mp4-18.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVuZsKXwps=-M32069_1_1.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-27.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-27.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwq1lamdk-M32069_1.mp4-167.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Npwq1lamdk-M32069_1.mp4-167.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_4.mp4-221.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_4.mp4-221.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-125.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-125.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-123.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-123.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-81.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-81.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-69.png: 480x640 None6.7ms\n",
      "Speed: 1.8ms preprocess, 6.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-69.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-108.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-108.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-32.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-32.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-127.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-127.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwqxsbMKa-M32069_1_1.mp4-48.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwqxsbMKa-M32069_1_1.mp4-48.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-177.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-177.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwqpta2tl1002_2.png: 512x640 (no detections), 7.1ms\n",
      "Speed: 1.9ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Npwqpta2tl1002_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-112.png: 480x640 (no detections), 7.2ms\n",
      "Speed: 1.7ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-173.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-173.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1qY8KWwps=-M32069_1_2.mp4-109.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1qY8KWwps=-M32069_1_2.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-24.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video10.mp4-8.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video10.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-95.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-95.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-10.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-112.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-110.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-110.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxjwqtmbMKZ-M32069_1_1.mp4-40.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxjwqtmbMKZ-M32069_1_1.mp4-40.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-57.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-57.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1saWZp-M32069_1_1.mp4-29.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1saWZp-M32069_1_1.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-161.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-161.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-76.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-76.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video1.mp4-55.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video1.mp4-55.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-160.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-160.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-15.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVraMKc-M32069_1_1.mp4-170.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVraMKc-M32069_1_1.mp4-170.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-77.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-77.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpuacKa-M32069_1_2.mp4-9.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpuacKa-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-68.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-68.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-10.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-119.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-119.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-98.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-98.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-93.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-93.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqxtY2Vl1163_2.png: 512x640 (no detections), 6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqxtY2Vl1163_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-35.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-35.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-18.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-118.png: 480x640 None6.6ms\n",
      "Speed: 2.0ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-70.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-70.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-44.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-44.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqlnZ8KawqA=-M32069_1_1.mp4-161.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqlnZ8KawqA=-M32069_1_1.mp4-161.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-171.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-171.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video1.mp4-128.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video1.mp4-128.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNpwqxtY8KV-M32069_1_1.mp4-41.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNpwqxtY8KV-M32069_1_1.mp4-41.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-8.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-9.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-62.png: 480x640 None7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-63.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-63.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_4.mp4-154.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_4.mp4-154.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-4.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-4.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_4.mp4-16.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_4.mp4-16.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNpwqxoY8KVwpk=-M32069_1_1.mp4-40.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNpwqxoY8KVwpk=-M32069_1_1.mp4-40.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-108.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-108.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-169.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-169.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-169.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-169.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-100.png: 480x640 (no detections), 7.0ms\n",
      "Speed: 2.6ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVqacKVwpc=-M32069_1_1.mp4-3.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.9ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVqacKVwpc=-M32069_1_1.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-10.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-116.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-116.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-86.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-86.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-12.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-12.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-29.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video6.mp4-3.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video6.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-34.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-34.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video3.mp4-155.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video3.mp4-155.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-92.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-92.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video5.mp4-1.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video5.mp4-1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-112.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtnwqloa8KZ-M32069_1_1.mp4-169.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtnwqloa8KZ-M32069_1_1.mp4-169.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-161.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-161.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-4.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-4.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-7.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-7.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-131.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-131.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-150.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-150.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-80.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-80.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-144.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-144.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-22.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-22.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-101.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-101.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_4.mp4-14.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_4.mp4-14.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-63.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-63.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-118.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-176.png: 480x640 None7.1ms\n",
      "Speed: 2.0ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-176.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-121.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-121.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-152.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-152.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-17.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-28.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-28.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-23.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-23.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-77.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-77.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdraG5o940_1.png: 512x640 None7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqdraG5o940_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-31.png: 480x640 (no detections), 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-31.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-19.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-24.png: 480x640 None7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVoa8KT-M32069_1_2.mp4-82.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVoa8KT-M32069_1_2.mp4-82.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtmwqpua2w=463.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtmwqpua2w=463.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-136.png: 480x640 None6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-136.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-156.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-156.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-18.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-96.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-96.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-90.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-90.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_2.mp4-41.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_2.mp4-41.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video8.mp4-58.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video8.mp4-58.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-158.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-158.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video19.mp4-179.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video19.mp4-179.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-162.png: 480x640 (no detections), 7.3ms\n",
      "Speed: 2.3ms preprocess, 7.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-162.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-2.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-64.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-64.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-100.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-174.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-174.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-88.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-88.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-13.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-13.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video11.mp4-44.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video11.mp4-44.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_3.mp4-113.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_3.mp4-113.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-38.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-38.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxpwqZpaWw=1018.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxpwqZpaWw=1018.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-102.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-102.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-131.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-131.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-11.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-19.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video3.mp4-52.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video3.mp4-52.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-73.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-73.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxnwqxmbGg=-M32069_1_4.mp4-47.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxnwqxmbGg=-M32069_1_4.mp4-47.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-27.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-27.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-144.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-144.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-62.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwqxsbMKa-M32069_1_1.mp4-72.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwqxsbMKa-M32069_1_1.mp4-72.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqpuY8KYwpk=-M32069_1_1.mp4-17.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqpuY8KYwpk=-M32069_1_1.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-88.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-88.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-66.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-66.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq5lbMKZwps=-M32069_1_1.mp4-118.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq5lbMKZwps=-M32069_1_1.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-122.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-122.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_1.mp4-25.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_1.mp4-25.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-71.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqtnZGdo1044.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqtnZGdo1044.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-173.png: 480x640 None6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-173.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-15.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video11.mp4-8.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video11.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVuZsKXwps=-M32069_1_2.mp4-79.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVuZsKXwps=-M32069_1_2.mp4-79.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_3.mp4-15.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_3.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwqxsaWw=911_2.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxmwqxsaWw=911_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-107.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-175.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-175.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-24.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-53.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-53.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqlmaWtq823.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqlmaWtq823.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVsZcKVwp8=-M32069_1_2.mp4-5.png: 480x640 None6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVsZcKVwp8=-M32069_1_2.mp4-5.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVsZcKVwp8=-M32069_1_2.mp4-9.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVsZcKVwp8=-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video10.mp4-22.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video10.mp4-22.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_5.mp4-18.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_5.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_2.mp4-83.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_2.mp4-83.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-82.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-82.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1qY8KWwps=-M32069_1_1.mp4-15.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1qY8KWwps=-M32069_1_1.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-73.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-73.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-90.png: 480x640 None6.5ms\n",
      "Speed: 2.1ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-90.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_1.mp4-12.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_1.mp4-12.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_1.mp4-30.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_1.mp4-30.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-21.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-114.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-114.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxkwq5qaWw=779_2.png: 512x640 (no detections), 6.9ms\n",
      "Speed: 2.1ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxkwq5qaWw=779_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtkwqprZsKY-video1.mp4-56.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtkwqprZsKY-video1.mp4-56.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxjwqtmbMKZ-M32069_1_2.mp4-20.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxjwqtmbMKZ-M32069_1_2.mp4-20.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-143.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-143.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-18.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-111.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-111.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video3.mp4-73.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video3.mp4-73.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video2.mp4-72.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video2.mp4-72.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-61.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-61.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-126.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-126.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-146.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-146.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-111.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-111.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-25.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-25.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-153.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-153.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-86.png: 480x640 None6.4ms\n",
      "Speed: 1.8ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-86.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqhoZMKTwpo=-832005_1_4.mp4-57.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NowqhoZMKTwpo=-832005_1_4.mp4-57.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-83.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-83.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqxtY2Vl1164_1.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqxtY2Vl1164_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video18.mp4-135.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video18.mp4-135.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqhoZGVm-832005_1_2.mp4-3.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NowqhoZGVm-832005_1_2.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-135.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-135.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-28.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-28.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video8.mp4-59.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video8.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-62.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxnwqxmbGg=-M32069_1_5.mp4-46.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxnwqxmbGg=-M32069_1_5.mp4-46.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-9.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video14.mp4-0.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 2.8ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video14.mp4-0.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVoa8KT-M32069_1_1.mp4-38.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVoa8KT-M32069_1_1.mp4-38.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-99.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-99.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtoZW1n1122.png: 512x640 (no detections), 6.8ms\n",
      "Speed: 1.9ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqtoZW1n1122.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-72.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-72.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-70.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-70.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtrwqZmZGg=811_2.png: 512x640 None6.8ms\n",
      "Speed: 1.9ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtrwqZmZGg=811_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video6.mp4-29.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video6.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-172.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-172.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtkwqprZsKY-video1.mp4-51.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtkwqprZsKY-video1.mp4-51.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-103.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-103.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqpsZGZp992_1.png: 512x640 (no detections), 7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqpsZGZp992_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-130.png: 480x640 None6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-130.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-104.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-104.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqttZ8KXwqA=-M32069_1_2.mp4-39.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqttZ8KXwqA=-M32069_1_2.mp4-39.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_2.mp4-105.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_2.mp4-105.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtlacKbwps=-M32069_1_1.mp4-41.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtlacKbwps=-M32069_1_1.mp4-41.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-11.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-20.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.8ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-20.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-205.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-205.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq5paWll1215_1.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwq5paWll1215_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVuZsKXwps=-M32069_1_2.mp4-9.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.8ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVuZsKXwps=-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-174.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-174.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqhuaMKYwpk=-832005_1_1.mp4-100.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NowqhuaMKYwpk=-832005_1_1.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video4.mp4-8.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video4.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pam0=348_1.png: 512x640 (no detections), 6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtiwq1pam0=348_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqVua2Vj910.png: 512x640 (no detections), 6.5ms\n",
      "Speed: 1.9ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqVua2Vj910.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-175.png: 480x640 None7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-175.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-52.png: 480x640 None6.9ms\n",
      "Speed: 1.8ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-52.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video4.mp4-85.png: 480x640 None6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video4.mp4-85.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_3.mp4-14.png: 480x640 None6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_3.mp4-14.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-95.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-95.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video19.mp4-181.png: 480x640 (no detections), 7.1ms\n",
      "Speed: 1.8ms preprocess, 7.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video19.mp4-181.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVsaMKXwpo=-M32069_1_1.mp4-19.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVsaMKXwpo=-M32069_1_1.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NnwqplZm1r613_2.png: 512x640 None7.1ms\n",
      "Speed: 1.9ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NnwqplZm1r613_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-158.png: 480x640 (no detections), 7.0ms\n",
      "Speed: 1.7ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-158.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-162.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-162.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-76.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-76.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_4.mp4-46.png: 480x640 None6.5ms\n",
      "Speed: 3.6ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_4.mp4-46.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-59.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-18.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqtoamdn1129_2.png: 512x640 (no detections), 7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqtoamdn1129_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-112.png: 480x640 None6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqpram5p1087_1.png: 512x640 (no detections), 7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqpram5p1087_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-4.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-4.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVoa8KT-M32069_1_2.mp4-125.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVoa8KT-M32069_1_2.mp4-125.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video7.mp4-19.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video7.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVmaWZp1197.png: 512x640 None7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amRiwqVmaWZp1197.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-100.png: 480x640 None7.3ms\n",
      "Speed: 2.2ms preprocess, 7.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-177.png: 480x640 None6.6ms\n",
      "Speed: 1.8ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-177.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-2.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxowq5pZGk=-M32069_1_1.mp4-21.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxowq5pZGk=-M32069_1_1.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-109.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNowqxtaGdn-M32069_1_1.mp4-147.png: 480x640 (no detections), 6.9ms\n",
      "Speed: 1.8ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNowqxtaGdn-M32069_1_1.mp4-147.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-17.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-170.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-170.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-145.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-145.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-32.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-32.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-95.png: 480x640 None7.0ms\n",
      "Speed: 1.8ms preprocess, 7.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-95.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtrZcKWwpw=-M32069_1_1.mp4-79.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtrZcKWwpw=-M32069_1_1.mp4-79.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-61.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-61.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-71.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-129.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-129.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNpwq1sZGg=1023_2.png: 512x640 None7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amNpwq1sZGg=1023_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-88.png: 480x640 None6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-88.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-53.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-53.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-75.png: 480x640 None6.8ms\n",
      "Speed: 1.8ms preprocess, 6.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-75.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-32.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-32.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-74.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-74.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNowqxtaGdn-M32069_1_1.mp4-24.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNowqxtaGdn-M32069_1_1.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-127.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-127.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-160.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-160.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-135.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-135.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-149.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-149.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1qY8KWwps=-M32069_1_2.mp4-107.png: 480x640 None6.9ms\n",
      "Speed: 1.8ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1qY8KWwps=-M32069_1_2.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-149.png: 480x640 None6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-149.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-9.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-58.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-58.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-56.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-56.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-59.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video1.mp4-109.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video1.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video5.mp4-171.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video5.mp4-171.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpoZ8Kc-M32069_1_2.mp4-85.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpoZ8Kc-M32069_1_2.mp4-85.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_1.mp4-29.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_1.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-123.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-123.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-54.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-54.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-126.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-126.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-47.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-47.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-12.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-12.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-162.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-162.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-115.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-115.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-180.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-180.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-103.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-103.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-83.png: 480x640 None6.4ms\n",
      "Speed: 1.9ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-83.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-67.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-67.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-17.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-70.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-70.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_6.mp4-155.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_6.mp4-155.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_4.mp4-15.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_4.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpoZ8Kc-M32069_1_2.mp4-91.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpoZ8Kc-M32069_1_2.mp4-91.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpoZ8Kc-M32069_1_2.mp4-84.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpoZ8Kc-M32069_1_2.mp4-84.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video5.mp4-59.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video5.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtlacKbwps=-M32069_1_1.mp4-107.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtlacKbwps=-M32069_1_1.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_4.mp4-9.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_4.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-112.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 2.0ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVqacKVwpc=-M32069_1_1.mp4-16.png: 480x640 None6.4ms\n",
      "Speed: 2.1ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVqacKVwpc=-M32069_1_1.mp4-16.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-105.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-105.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-78.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-78.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video12.mp4-5.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video12.mp4-5.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtlwqxuZ2g=427_1.png: 512x640 None7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtlwqxuZ2g=427_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-171.png: 480x640 None6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-171.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqpuY8KYwpk=-M32069_1_1.mp4-102.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqpuY8KYwpk=-M32069_1_1.mp4-102.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-7.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.8ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-7.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-172.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-172.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video9.mp4-21.png: 480x640 None6.6ms\n",
      "Speed: 2.8ms preprocess, 6.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video9.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video4.mp4-13.png: 480x640 None6.4ms\n",
      "Speed: 1.8ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video4.mp4-13.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-75.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-75.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-18.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-117.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-117.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-51.png: 480x640 None15.0ms\n",
      "Speed: 1.8ms preprocess, 15.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-51.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-33.png: 480x640 None6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-33.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-108.png: 480x640 None7.2ms\n",
      "Speed: 1.8ms preprocess, 7.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-108.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-106.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-106.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-170.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-170.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-109.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqptamVs1103_2.png: 512x640 (no detections), 15.1ms\n",
      "Speed: 1.9ms preprocess, 15.1ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqptamVs1103_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-31.png: 480x640 None7.0ms\n",
      "Speed: 1.7ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-31.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_3.mp4-3.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_3.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-6.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-6.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtkwqprZsKY-video1.mp4-137.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtkwqprZsKY-video1.mp4-137.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwqpta2tl1002_1.png: 512x640 None7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Npwqpta2tl1002_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-31.png: 480x640 None7.4ms\n",
      "Speed: 1.8ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-31.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-19.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-19.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-37.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-37.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-21.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_4.mp4-8.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_4.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-35.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-35.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwq1lamdk-M32069_1.mp4-75.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Npwq1lamdk-M32069_1.mp4-75.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqtoamdn1129_1.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqtoamdn1129_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video19.mp4-57.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video19.mp4-57.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-66.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-66.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-11.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-118.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-119.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-119.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-120.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-120.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1saWZp-M32069_1_1.mp4-38.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.8ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1saWZp-M32069_1_1.mp4-38.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqprY2dp1111_2.png: 512x640 (no detections), 6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqprY2dp1111_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-63.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 2.0ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-63.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-14.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-14.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-25.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-25.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video6.mp4-28.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video6.mp4-28.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-119.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-119.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtlacKbwps=-M32069_1_1.mp4-10.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtlacKbwps=-M32069_1_1.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-11.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-178.png: 480x640 None6.4ms\n",
      "Speed: 1.8ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-178.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-86.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-86.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-163.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-163.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_4.mp4-134.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_4.mp4-134.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqpubG4=851_1.png: 512x640 (no detections), 7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtpwqpubG4=851_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-107.png: 480x640 (no detections), 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-71.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-71.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-127.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-127.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-117.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-117.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqpsbGhj1100_1.png: 512x640 (no detections), 6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqpsbGhj1100_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-11.png: 480x640 None6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNowqxtaGdn-M32069_1_1.mp4-165.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 3.3ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNowqxtaGdn-M32069_1_1.mp4-165.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxpwqxma2s=1123_1.png: 512x640 (no detections), 7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxpwqxma2s=1123_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqZuaGxs689_2.png: 512x640 (no detections), 6.6ms\n",
      "Speed: 2.0ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqZuaGxs689_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxnwqtpZWw=936.png: 512x640 None6.5ms\n",
      "Speed: 1.9ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxnwqtpZWw=936.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1saWZp-M32069_1_2.mp4-40.png: 480x640 (no detections), 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1saWZp-M32069_1_2.mp4-40.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_4.mp4-26.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_4.mp4-26.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_4.mp4-222.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_4.mp4-222.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-42.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-42.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-46.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-46.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-150.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-150.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-39.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-39.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqtoamdn1151.png: 512x640 (no detections), 6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqtoamdn1151.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-81.png: 480x640 None6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-81.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-62.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVuZsKXwps=-M32069_1_1.mp4-18.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVuZsKXwps=-M32069_1_1.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-27.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-27.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwq1lamdk-M32069_1.mp4-167.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Npwq1lamdk-M32069_1.mp4-167.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_4.mp4-221.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_4.mp4-221.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-125.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-125.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-123.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-123.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-81.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-81.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-69.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-69.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-108.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-108.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-32.png: 480x640 None6.4ms\n",
      "Speed: 2.0ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-32.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-127.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-127.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwqxsbMKa-M32069_1_1.mp4-48.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwqxsbMKa-M32069_1_1.mp4-48.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-177.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-177.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Npwqpta2tl1002_2.png: 512x640 (no detections), 7.2ms\n",
      "Speed: 2.0ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Npwqpta2tl1002_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-112.png: 480x640 (no detections), 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-173.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-173.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1qY8KWwps=-M32069_1_2.mp4-109.png: 480x640 None6.5ms\n",
      "Speed: 3.1ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1qY8KWwps=-M32069_1_2.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-24.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video10.mp4-8.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video10.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-95.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-95.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-10.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-112.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-110.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-110.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxjwqtmbMKZ-M32069_1_1.mp4-40.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxjwqtmbMKZ-M32069_1_1.mp4-40.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-57.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-57.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1saWZp-M32069_1_1.mp4-29.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1saWZp-M32069_1_1.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-161.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-161.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-76.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-76.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video1.mp4-55.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video1.mp4-55.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-160.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-160.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-15.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVraMKc-M32069_1_1.mp4-170.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVraMKc-M32069_1_1.mp4-170.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-77.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.8ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-77.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpuacKa-M32069_1_2.mp4-9.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpuacKa-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-68.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-68.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-10.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-119.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-119.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-98.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-98.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-93.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-93.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqxtY2Vl1163_2.png: 512x640 (no detections), 7.1ms\n",
      "Speed: 1.9ms preprocess, 7.1ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqxtY2Vl1163_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-35.png: 480x640 (no detections), 7.0ms\n",
      "Speed: 1.7ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-35.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-18.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-118.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-70.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-70.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-44.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-44.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqlnZ8KawqA=-M32069_1_1.mp4-161.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 3.2ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqlnZ8KawqA=-M32069_1_1.mp4-161.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-171.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-171.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video1.mp4-128.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video1.mp4-128.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNpwqxtY8KV-M32069_1_1.mp4-41.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNpwqxtY8KV-M32069_1_1.mp4-41.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-8.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-9.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-62.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-63.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-63.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_4.mp4-154.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_4.mp4-154.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-4.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-4.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_4.mp4-16.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_4.mp4-16.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNpwqxoY8KVwpk=-M32069_1_1.mp4-40.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNpwqxoY8KVwpk=-M32069_1_1.mp4-40.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-108.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-108.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-169.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_2.mp4-169.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-169.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-169.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-100.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 2.1ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVqacKVwpc=-M32069_1_1.mp4-3.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVqacKVwpc=-M32069_1_1.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-10.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-10.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-116.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-116.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-86.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-86.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-12.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-12.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-29.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video6.mp4-3.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video6.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-34.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-34.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video3.mp4-155.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video3.mp4-155.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-92.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 2.2ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-92.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video5.mp4-1.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video5.mp4-1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-112.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtnwqloa8KZ-M32069_1_1.mp4-169.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtnwqloa8KZ-M32069_1_1.mp4-169.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-161.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-161.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-4.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-4.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-7.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-7.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-131.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-131.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-150.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-150.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-80.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-80.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-144.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-144.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-22.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-22.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_5.mp4-101.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_5.mp4-101.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_4.mp4-14.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_4.mp4-14.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-63.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-63.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-118.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-176.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-176.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-121.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-121.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-152.png: 480x640 None7.1ms\n",
      "Speed: 1.9ms preprocess, 7.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-152.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-17.png: 480x640 None6.9ms\n",
      "Speed: 2.0ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-28.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-28.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-23.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-23.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-77.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-77.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdraG5o940_1.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqdraG5o940_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-31.png: 480x640 (no detections), 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-31.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-19.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-24.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVoa8KT-M32069_1_2.mp4-82.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVoa8KT-M32069_1_2.mp4-82.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtmwqpua2w=463.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtmwqpua2w=463.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-136.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-136.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-156.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-156.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-18.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-96.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-96.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-90.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-90.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_2.mp4-41.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_2.mp4-41.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video8.mp4-58.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video8.mp4-58.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-158.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-158.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video19.mp4-179.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video19.mp4-179.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-162.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-162.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-2.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-64.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-64.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-100.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-174.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-174.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-88.png: 480x640 None6.6ms\n",
      "Speed: 2.1ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-88.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-13.png: 480x640 None6.5ms\n",
      "Speed: 1.8ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-13.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video11.mp4-44.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video11.mp4-44.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_3.mp4-113.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_3.mp4-113.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-38.png: 480x640 (no detections), 7.1ms\n",
      "Speed: 1.7ms preprocess, 7.1ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-38.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxpwqZpaWw=1018.png: 512x640 (no detections), 7.4ms\n",
      "Speed: 1.9ms preprocess, 7.4ms inference, 0.5ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxpwqZpaWw=1018.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-102.png: 480x640 (no detections), 7.2ms\n",
      "Speed: 1.8ms preprocess, 7.2ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-102.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-131.png: 480x640 None6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-131.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-11.png: 480x640 None6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-19.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video3.mp4-52.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video3.mp4-52.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-73.png: 480x640 None6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-73.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxnwqxmbGg=-M32069_1_4.mp4-47.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxnwqxmbGg=-M32069_1_4.mp4-47.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-27.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-27.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-144.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-144.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-62.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwqxsbMKa-M32069_1_1.mp4-72.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwqxsbMKa-M32069_1_1.mp4-72.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqpuY8KYwpk=-M32069_1_1.mp4-17.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqpuY8KYwpk=-M32069_1_1.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-88.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-88.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-66.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-66.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq5lbMKZwps=-M32069_1_1.mp4-118.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq5lbMKZwps=-M32069_1_1.mp4-118.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-122.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-122.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_1.mp4-25.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_1.mp4-25.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-71.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqtnZGdo1044.png: 512x640 None7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqtnZGdo1044.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-173.png: 480x640 None6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-173.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-15.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video11.mp4-8.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video11.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVuZsKXwps=-M32069_1_2.mp4-79.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVuZsKXwps=-M32069_1_2.mp4-79.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_3.mp4-15.png: 480x640 None6.4ms\n",
      "Speed: 2.6ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_3.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwqxsaWw=911_2.png: 512x640 None7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxmwqxsaWw=911_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-107.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-175.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-175.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-24.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-53.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-53.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqlmaWtq823.png: 512x640 None6.8ms\n",
      "Speed: 1.9ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqlmaWtq823.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVsZcKVwp8=-M32069_1_2.mp4-5.png: 480x640 None6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVsZcKVwp8=-M32069_1_2.mp4-5.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVsZcKVwp8=-M32069_1_2.mp4-9.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVsZcKVwp8=-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video10.mp4-22.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video10.mp4-22.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_5.mp4-18.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 2.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_5.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_2.mp4-83.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_2.mp4-83.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-82.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-82.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1qY8KWwps=-M32069_1_1.mp4-15.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1qY8KWwps=-M32069_1_1.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-73.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-73.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-90.png: 480x640 None6.4ms\n",
      "Speed: 1.9ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-90.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_1.mp4-12.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_1.mp4-12.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_1.mp4-30.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_1.mp4-30.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-21.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video1.mp4-114.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video1.mp4-114.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxkwq5qaWw=779_2.png: 512x640 (no detections), 7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amxkwq5qaWw=779_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtkwqprZsKY-video1.mp4-56.png: 480x640 (no detections), 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtkwqprZsKY-video1.mp4-56.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxjwqtmbMKZ-M32069_1_2.mp4-20.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxjwqtmbMKZ-M32069_1_2.mp4-20.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-143.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-143.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-18.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-111.png: 480x640 (no detections), 6.9ms\n",
      "Speed: 2.6ms preprocess, 6.9ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-111.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video3.mp4-73.png: 480x640 None6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video3.mp4-73.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video2.mp4-72.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video2.mp4-72.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-61.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-61.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-126.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-126.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-146.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-146.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video9.mp4-111.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video9.mp4-111.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-25.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-25.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-153.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-153.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-86.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-86.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqhoZMKTwpo=-832005_1_4.mp4-57.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NowqhoZMKTwpo=-832005_1_4.mp4-57.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_1.mp4-83.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_1.mp4-83.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqxtY2Vl1164_1.png: 512x640 None7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NowqxtY2Vl1164_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video18.mp4-135.png: 480x640 (no detections), 6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video18.mp4-135.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqhoZGVm-832005_1_2.mp4-3.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NowqhoZGVm-832005_1_2.mp4-3.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-135.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-135.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video1.mp4-28.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video1.mp4-28.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video8.mp4-59.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video8.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-62.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-62.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxnwqxmbGg=-M32069_1_5.mp4-46.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxnwqxmbGg=-M32069_1_5.mp4-46.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-9.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video14.mp4-0.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video14.mp4-0.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVoa8KT-M32069_1_1.mp4-38.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVoa8KT-M32069_1_1.mp4-38.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-99.png: 480x640 None6.6ms\n",
      "Speed: 2.1ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-99.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtoZW1n1122.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NrwqtoZW1n1122.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-72.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 2.3ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-72.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-70.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-70.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtrwqZmZGg=811_2.png: 512x640 (no detections), 7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtrwqZmZGg=811_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video6.mp4-29.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video6.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-172.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-172.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtkwqprZsKY-video1.mp4-51.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtkwqprZsKY-video1.mp4-51.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-103.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-103.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqpsZGZp992_1.png: 512x640 (no detections), 6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqpsZGZp992_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-130.png: 480x640 None6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-130.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-104.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-104.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqttZ8KXwqA=-M32069_1_2.mp4-39.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqttZ8KXwqA=-M32069_1_2.mp4-39.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVuacKTwp0=-M32069_1_2.mp4-105.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVuacKTwp0=-M32069_1_2.mp4-105.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtlacKbwps=-M32069_1_1.mp4-41.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtlacKbwps=-M32069_1_1.mp4-41.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-11.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-11.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_4.mp4-20.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_4.mp4-20.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-205.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-205.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq5paWll1215_1.png: 512x640 (no detections), 7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwq5paWll1215_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVuZsKXwps=-M32069_1_2.mp4-9.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVuZsKXwps=-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-174.png: 480x640 None7.4ms\n",
      "Speed: 2.2ms preprocess, 7.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-174.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NowqhuaMKYwpk=-832005_1_1.mp4-100.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NowqhuaMKYwpk=-832005_1_1.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video4.mp4-8.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video4.mp4-8.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pam0=348_1.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtiwq1pam0=348_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqVua2Vj910.png: 512x640 None6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NpwqVua2Vj910.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-175.png: 480x640 None6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-175.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-52.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-52.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video4.mp4-85.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video4.mp4-85.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_3.mp4-14.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_3.mp4-14.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtpY8KYwpc=-M32069_1_3.mp4-95.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtpY8KYwpc=-M32069_1_3.mp4-95.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video19.mp4-181.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video19.mp4-181.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVsaMKXwpo=-M32069_1_1.mp4-19.png: 480x640 (no detections), 7.5ms\n",
      "Speed: 2.2ms preprocess, 7.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVsaMKXwpo=-M32069_1_1.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NnwqplZm1r613_2.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2NnwqplZm1r613_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNnwq5lY8Kb-video2.mp4-158.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNnwq5lY8Kb-video2.mp4-158.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-162.png: 480x640 None6.5ms\n",
      "Speed: 2.0ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-162.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-76.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-76.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_4.mp4-46.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_4.mp4-46.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-59.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-18.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqtoamdn1129_2.png: 512x640 (no detections), 6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqtoamdn1129_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-112.png: 480x640 None6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwqpram5p1087_1.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: a2Nrwqpram5p1087_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-4.png: 480x640 (no detections), 6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-4.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwqVoa8KT-M32069_1_2.mp4-125.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwqVoa8KT-M32069_1_2.mp4-125.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video7.mp4-19.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video7.mp4-19.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVmaWZp1197.png: 512x640 (no detections), 6.8ms\n",
      "Speed: 1.9ms preprocess, 6.8ms inference, 0.4ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amRiwqVmaWZp1197.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-100.png: 480x640 None6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-100.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-177.png: 480x640 None6.4ms\n",
      "Speed: 2.0ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-177.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxrwq5macKX-M32069_1_1.mp4-2.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxrwq5macKX-M32069_1_1.mp4-2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxowq5pZGk=-M32069_1_1.mp4-21.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxowq5pZGk=-M32069_1_1.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_7.mp4-109.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_7.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNowqxtaGdn-M32069_1_1.mp4-147.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNowqxtaGdn-M32069_1_1.mp4-147.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-17.png: 480x640 None6.9ms\n",
      "Speed: 2.1ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-170.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-170.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-145.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-145.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-32.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-32.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-95.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-95.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtrZcKWwpw=-M32069_1_1.mp4-79.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtrZcKWwpw=-M32069_1_1.mp4-79.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-61.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-61.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-71.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-71.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video1.mp4-129.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video1.mp4-129.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNpwq1sZGg=1023_2.png: 512x640 None6.9ms\n",
      "Speed: 1.9ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amNpwq1sZGg=1023_2.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-88.png: 480x640 None6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video2.mp4-88.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-53.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-53.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqxsaMKYwps=-M32069_1_2.mp4-75.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqxsaMKYwps=-M32069_1_2.mp4-75.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-32.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1pZ8KUwp8=-M32069_1_1.mp4-32.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-74.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-74.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ZmNowqxtaGdn-M32069_1_1.mp4-24.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ZmNowqxtaGdn-M32069_1_1.mp4-24.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-127.png: 480x640 None6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-127.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-160.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-160.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-135.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-135.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-149.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-149.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2Nrwq1qY8KWwps=-M32069_1_2.mp4-107.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2Nrwq1qY8KWwps=-M32069_1_2.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-149.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-149.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqZnY2xn-M32069_1_2.mp4-9.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqZnY2xn-M32069_1_2.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video2.mp4-58.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video2.mp4-58.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video7.mp4-56.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video7.mp4-56.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-59.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video1.mp4-109.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video1.mp4-109.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video5.mp4-171.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video5.mp4-171.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpoZ8Kc-M32069_1_2.mp4-85.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpoZ8Kc-M32069_1_2.mp4-85.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_1.mp4-29.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_1.mp4-29.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhramk=-video2.mp4-123.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhramk=-video2.mp4-123.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-54.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 2.8ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2Rmwq1lZ8KTwp0=-M32069_1_3.mp4-54.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq1uZ8Ka-832005_1_1.mp4-126.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq1uZ8Ka-832005_1_1.mp4-126.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-47.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-47.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-12.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-12.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqtqa8KY-M32069_1_1.mp4-162.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqtqa8KY-M32069_1_1.mp4-162.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-115.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-115.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video3.mp4-180.png: 480x640 None6.8ms\n",
      "Speed: 1.7ms preprocess, 6.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video3.mp4-180.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-103.png: 480x640 None6.9ms\n",
      "Speed: 2.6ms preprocess, 6.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-103.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-83.png: 480x640 None6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-83.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxmwq5rZMKV-M32069_1_1.mp4-67.png: 480x640 None7.0ms\n",
      "Speed: 3.2ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxmwq5rZMKV-M32069_1_1.mp4-67.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-17.png: 480x640 (no detections), 6.7ms\n",
      "Speed: 1.7ms preprocess, 6.7ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-17.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video4.mp4-70.png: 480x640 None6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video4.mp4-70.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwq1oaMKT-M32069_1_6.mp4-155.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwq1oaMKT-M32069_1_6.mp4-155.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amNowqlpY8KZ-M32069_1_4.mp4-15.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amNowqlpY8KZ-M32069_1_4.mp4-15.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpoZ8Kc-M32069_1_2.mp4-91.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpoZ8Kc-M32069_1_2.mp4-91.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amxqwqpoZ8Kc-M32069_1_2.mp4-84.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amxqwqpoZ8Kc-M32069_1_2.mp4-84.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video5.mp4-59.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video5.mp4-59.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqtlacKbwps=-M32069_1_1.mp4-107.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 2.1ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqtlacKbwps=-M32069_1_1.mp4-107.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_4.mp4-9.png: 480x640 (no detections), 6.3ms\n",
      "Speed: 1.7ms preprocess, 6.3ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_4.mp4-9.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-112.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video3.mp4-112.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2RiwqVqacKVwpc=-M32069_1_1.mp4-16.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2RiwqVqacKVwpc=-M32069_1_1.mp4-16.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video3.mp4-105.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video3.mp4-105.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-78.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-78.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video12.mp4-5.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video12.mp4-5.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtlwqxuZ2g=427_1.png: 512x640 None7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 1.9ms postprocess per image at shape (1, 3, 512, 640)\n",
      "Detection results saved for: amtlwqxuZ2g=427_1.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVla8KTwps=-M32069_1_1.mp4-171.png: 480x640 None6.9ms\n",
      "Speed: 1.7ms preprocess, 6.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amRiwqVla8KTwps=-M32069_1_1.mp4-171.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NrwqpuY8KYwpk=-M32069_1_1.mp4-102.png: 480x640 (no detections), 6.6ms\n",
      "Speed: 1.7ms preprocess, 6.6ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NrwqpuY8KYwpk=-M32069_1_1.mp4-102.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/a2NpwqdqZMKWwpg=-M32069_1_1.mp4-7.png: 480x640 (no detections), 6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: a2NpwqdqZMKWwpg=-M32069_1_1.mp4-7.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-172.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-172.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video9.mp4-21.png: 480x640 None6.5ms\n",
      "Speed: 1.7ms preprocess, 6.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video9.mp4-21.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/ampnwqZsacKW-video4.mp4-13.png: 480x640 None6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: ampnwqZsacKW-video4.mp4-13.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtpwqhrasKX-832005_1_1.mp4-75.png: 480x640 None6.3ms\n",
      "Speed: 1.9ms preprocess, 6.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtpwqhrasKX-832005_1_1.mp4-75.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video5.mp4-18.png: 480x640 (no detections), 6.4ms\n",
      "Speed: 1.7ms preprocess, 6.4ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: Z2NiwqllasKUwp0=-video5.mp4-18.png\n",
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-117.png: 480x640 None7.1ms\n",
      "Speed: 2.3ms preprocess, 7.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Detection results saved for: amtiwq1pasKb-video6.mp4-117.png\n"
     ]
    }
   ],
   "source": [
    "#batch detection test\n",
    "import os\n",
    "from pathlib import Path  # Improved file path handling\n",
    "import random\n",
    "#from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import cv2\n",
    "\n",
    "for i in range (4):\n",
    "    if i == 0:\n",
    "        weightaddress = str(f'{yolodir}runs/obb/train/weights/best.pt')\n",
    "    else:\n",
    "        weightaddress = str(f'{yolodir}runs/obb/train{i+1}/weights/best.pt')\n",
    "    model = YOLO(weightaddress)\n",
    "    \n",
    "    # Define the test image directory\n",
    "    test_dir = Path(f\"{filedir}/test/images/\")  # Use Path for better handling\n",
    "    \n",
    "    # Loop through all image files\n",
    "    for image_path in test_dir.glob(\"*.png\"):  # Modify extension if needed (e.g., *.png)\n",
    "        # Perform detection\n",
    "        results = model(str(image_path))  # Convert Path to string for YOLO\n",
    "        \n",
    "        # Extract filename\n",
    "        filename = image_path.name\n",
    "        \n",
    "        # Process and annotate detections (same as your code)\n",
    "        detections = sv.Detections.from_ultralytics(results[0])\n",
    "        oriented_box_annotator = sv.OrientedBoxAnnotator()\n",
    "        annotated_frame = oriented_box_annotator.annotate(\n",
    "            scene=cv2.imread(str(image_path)),\n",
    "            detections=detections\n",
    "        )\n",
    "        \n",
    "        # Define output path (modify as needed)\n",
    "        output_path = Path(f\"{homedir}/results{i+1}/{filename}\")\n",
    "        \n",
    "        # Save the annotated image (replace with desired format if needed)\n",
    "        cv2.imwrite(str(output_path), annotated_frame)\n",
    "        \n",
    "        # Optional: Print progress\n",
    "        print(f\"Detection results saved for: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/Z2NiwqllasKUwp0=-video3.mp4-112.png: 480x640 None5.6ms\n",
      "Speed: 1.8ms preprocess, 5.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amRiwqVuZsKXwps=-M32069_1_2.mp4-9.png: 480x640 (no detections), 5.6ms\n",
      "Speed: 1.8ms preprocess, 5.6ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video2.mp4-10.png: 480x640 None6.8ms\n",
      "Speed: 1.8ms preprocess, 6.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/u3618315/obb_dataset/test/images/amtiwq1pasKb-video6.mp4-117.png: 480x640 None7.0ms\n",
      "Speed: 1.9ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#random detection test\n",
    "for i in range (4):\n",
    "    if i == 0:\n",
    "        weightaddress = str(f'{yolodir}runs/obb/train/weights/best.pt')\n",
    "    else:\n",
    "        weightaddress = str(f'{yolodir}runs/obb/train{i+1}/weights/best.pt')\n",
    "    model = YOLO(weightaddress)\n",
    "    \n",
    "    random_file = random.choice(os.listdir(test_dir))\n",
    "    file_name = os.path.join(test_dir, random_file)\n",
    "    \n",
    "    results = model(file_name)\n",
    "    \n",
    "    detections = sv.Detections.from_ultralytics(results[0])\n",
    "    \n",
    "    oriented_box_annotator = sv.OrientedBoxAnnotator()\n",
    "    annotated_frame = oriented_box_annotator.annotate(\n",
    "        scene=cv2.imread(file_name),\n",
    "        detections=detections\n",
    "    )\n",
    "    \n",
    "    sv.plot_image(image=annotated_frame, size=(16, 16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://archive.ubuntu.com/ubuntu noble InRelease [256 kB]\n",
      "Get:2 http://security.ubuntu.com/ubuntu noble-security InRelease [126 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu noble-updates InRelease [126 kB]m\u001b[33m\n",
      "Get:4 http://security.ubuntu.com/ubuntu noble-security/multiverse amd64 Packages [23.0 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu noble-backports InRelease [126 kB]      \u001b[0m\u001b[33m\n",
      "Get:6 http://security.ubuntu.com/ubuntu noble-security/main amd64 Packages [1239 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu noble/restricted amd64 Packages [117 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu noble/main amd64 Packages [1808 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu noble-security/restricted amd64 Packages [1735 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu noble/universe amd64 Packages [19.3 MB]\u001b[0m\u001b[33m\n",
      "Get:11 http://security.ubuntu.com/ubuntu noble-security/universe amd64 Packages [1124 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu noble/multiverse amd64 Packages [331 kB][0m\u001b[33m\n",
      "Get:13 http://archive.ubuntu.com/ubuntu noble-updates/restricted amd64 Packages [1800 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu noble-updates/universe amd64 Packages [1434 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu noble-updates/multiverse amd64 Packages [28.1 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 Packages [1568 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu noble-backports/universe amd64 Packages [33.0 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu noble-backports/main amd64 Packages [48.8 kB]\n",
      "Fetched 31.2 MB in 5s (6716 kB/s)33m                         \u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "73 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  zip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 73 not upgraded.\n",
      "Need to get 176 kB of archives.\n",
      "After this operation, 549 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu noble-updates/main amd64 zip amd64 3.0-13ubuntu0.2 [176 kB]\n",
      "Fetched 176 kB in 1s (140 kB/s)[0m\u001b[33m\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 79, <STDIN> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "cannot stat initial working directory for /home/u3618315/yolo_alternative_loss_functions: Permission denied at /usr/sbin/dpkg-preconfigure line 75.\n",
      "cannot stat initial working directory for /home/u3618315/yolo_alternative_loss_functions: Permission denied at /usr/sbin/dpkg-preconfigure line 182.\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package zip.\n",
      "(Reading database ... 30630 files and directories currently installed.)\n",
      "Preparing to unpack .../zip_3.0-13ubuntu0.2_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 20%]\u001b[49m\u001b[39m [###########...............................................] \u001b8Unpacking zip (3.0-13ubuntu0.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 40%]\u001b[49m\u001b[39m [#######################...................................] \u001b8Setting up zip (3.0-13ubuntu0.2) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 60%]\u001b[49m\u001b[39m [##################################........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 80%]\u001b[49m\u001b[39m [##############################################............] \u001b8\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[J"
     ]
    }
   ],
   "source": [
    "#in case zip is npt found in the shell environment\n",
    "!sudo apt update\n",
    "!sudo apt install zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: results1/ (stored 0%)\n",
      "  adding: results2/ (stored 0%)\n",
      "  adding: results3/ (stored 0%)\n",
      "  adding: results4/ (stored 0%)\n",
      "  adding: runs/ (stored 0%)\n",
      "  adding: runs/obb/ (stored 0%)\n",
      "  adding: runs/obb/train3/ (stored 0%)\n",
      "  adding: runs/obb/train3/val_batch1_labels.jpg (deflated 17%)\n",
      "  adding: runs/obb/train3/val_batch2_pred.jpg (deflated 19%)\n",
      "  adding: runs/obb/train3/BoxPR_curve.png (deflated 22%)\n",
      "  adding: runs/obb/train3/train_batch0.jpg (deflated 13%)\n",
      "  adding: runs/obb/train3/train_batch1.jpg (deflated 14%)\n",
      "  adding: runs/obb/train3/BoxP_curve.png (deflated 14%)\n",
      "  adding: runs/obb/train3/train_batch23492.jpg (deflated 20%)\n",
      "  adding: runs/obb/train3/val_batch2_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/train3/val_batch1_pred.jpg (deflated 14%)\n",
      "  adding: runs/obb/train3/BoxF1_curve.png (deflated 23%)\n",
      "  adding: runs/obb/train3/results.png (deflated 8%)\n",
      "  adding: runs/obb/train3/weights/ (stored 0%)\n",
      "  adding: runs/obb/train3/weights/last.pt (deflated 11%)\n",
      "  adding: runs/obb/train3/weights/best.pt (deflated 11%)\n",
      "  adding: runs/obb/train3/confusion_matrix.png (deflated 26%)\n",
      "  adding: runs/obb/train3/train_batch23490.jpg (deflated 19%)\n",
      "  adding: runs/obb/train3/val_batch0_pred.jpg (deflated 19%)\n",
      "  adding: runs/obb/train3/labels_correlogram.jpg (deflated 38%)\n",
      "  adding: runs/obb/train3/train_batch2.jpg (deflated 13%)\n",
      "  adding: runs/obb/train3/confusion_matrix_normalized.png (deflated 25%)\n",
      "  adding: runs/obb/train3/results.csv (deflated 67%)\n",
      "  adding: runs/obb/train3/BoxR_curve.png (deflated 24%)\n",
      "  adding: runs/obb/train3/labels.jpg (deflated 34%)\n",
      "  adding: runs/obb/train3/train_batch23491.jpg (deflated 21%)\n",
      "  adding: runs/obb/train3/args.yaml (deflated 53%)\n",
      "  adding: runs/obb/train3/val_batch0_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/val3/ (stored 0%)\n",
      "  adding: runs/obb/val3/val_batch1_labels.jpg (deflated 17%)\n",
      "  adding: runs/obb/val3/val_batch2_pred.jpg (deflated 19%)\n",
      "  adding: runs/obb/val3/BoxPR_curve.png (deflated 21%)\n",
      "  adding: runs/obb/val3/BoxP_curve.png (deflated 14%)\n",
      "  adding: runs/obb/val3/val_batch2_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/val3/val_batch1_pred.jpg (deflated 15%)\n",
      "  adding: runs/obb/val3/BoxF1_curve.png (deflated 23%)\n",
      "  adding: runs/obb/val3/confusion_matrix.png (deflated 26%)\n",
      "  adding: runs/obb/val3/val_batch0_pred.jpg (deflated 18%)\n",
      "  adding: runs/obb/val3/confusion_matrix_normalized.png (deflated 25%)\n",
      "  adding: runs/obb/val3/BoxR_curve.png (deflated 25%)\n",
      "  adding: runs/obb/val3/val_batch0_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/val4/ (stored 0%)\n",
      "  adding: runs/obb/val4/val_batch1_labels.jpg (deflated 17%)\n",
      "  adding: runs/obb/val4/val_batch2_pred.jpg (deflated 19%)\n",
      "  adding: runs/obb/val4/BoxPR_curve.png (deflated 21%)\n",
      "  adding: runs/obb/val4/BoxP_curve.png (deflated 14%)\n",
      "  adding: runs/obb/val4/val_batch2_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/val4/val_batch1_pred.jpg (deflated 15%)\n",
      "  adding: runs/obb/val4/BoxF1_curve.png (deflated 23%)\n",
      "  adding: runs/obb/val4/confusion_matrix.png (deflated 25%)\n",
      "  adding: runs/obb/val4/val_batch0_pred.jpg (deflated 19%)\n",
      "  adding: runs/obb/val4/confusion_matrix_normalized.png (deflated 25%)\n",
      "  adding: runs/obb/val4/BoxR_curve.png (deflated 25%)\n",
      "  adding: runs/obb/val4/val_batch0_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/train/ (stored 0%)\n",
      "  adding: runs/obb/train/val_batch1_labels.jpg (deflated 17%)\n",
      "  adding: runs/obb/train/val_batch2_pred.jpg (deflated 19%)\n",
      "  adding: runs/obb/train/BoxPR_curve.png (deflated 21%)\n",
      "  adding: runs/obb/train/train_batch0.jpg (deflated 13%)\n",
      "  adding: runs/obb/train/train_batch1.jpg (deflated 14%)\n",
      "  adding: runs/obb/train/BoxP_curve.png (deflated 14%)\n",
      "  adding: runs/obb/train/train_batch23492.jpg (deflated 20%)\n",
      "  adding: runs/obb/train/val_batch2_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/train/val_batch1_pred.jpg (deflated 15%)\n",
      "  adding: runs/obb/train/BoxF1_curve.png (deflated 23%)\n",
      "  adding: runs/obb/train/results.png (deflated 7%)\n",
      "  adding: runs/obb/train/weights/ (stored 0%)\n",
      "  adding: runs/obb/train/weights/last.pt (deflated 10%)\n",
      "  adding: runs/obb/train/weights/best.pt (deflated 10%)\n",
      "  adding: runs/obb/train/confusion_matrix.png (deflated 25%)\n",
      "  adding: runs/obb/train/train_batch23490.jpg (deflated 19%)\n",
      "  adding: runs/obb/train/val_batch0_pred.jpg (deflated 17%)\n",
      "  adding: runs/obb/train/labels_correlogram.jpg (deflated 38%)\n",
      "  adding: runs/obb/train/train_batch2.jpg (deflated 13%)\n",
      "  adding: runs/obb/train/confusion_matrix_normalized.png (deflated 25%)\n",
      "  adding: runs/obb/train/results.csv (deflated 67%)\n",
      "  adding: runs/obb/train/BoxR_curve.png (deflated 25%)\n",
      "  adding: runs/obb/train/labels.jpg (deflated 34%)\n",
      "  adding: runs/obb/train/train_batch23491.jpg (deflated 21%)\n",
      "  adding: runs/obb/train/args.yaml (deflated 53%)\n",
      "  adding: runs/obb/train/val_batch0_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/train4/ (stored 0%)\n",
      "  adding: runs/obb/train4/val_batch1_labels.jpg (deflated 17%)\n",
      "  adding: runs/obb/train4/val_batch2_pred.jpg (deflated 20%)\n",
      "  adding: runs/obb/train4/BoxPR_curve.png (deflated 21%)\n",
      "  adding: runs/obb/train4/train_batch0.jpg (deflated 13%)\n",
      "  adding: runs/obb/train4/train_batch1.jpg (deflated 14%)\n",
      "  adding: runs/obb/train4/BoxP_curve.png (deflated 14%)\n",
      "  adding: runs/obb/train4/train_batch23492.jpg (deflated 20%)\n",
      "  adding: runs/obb/train4/val_batch2_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/train4/val_batch1_pred.jpg (deflated 15%)\n",
      "  adding: runs/obb/train4/BoxF1_curve.png (deflated 23%)\n",
      "  adding: runs/obb/train4/results.png (deflated 7%)\n",
      "  adding: runs/obb/train4/weights/ (stored 0%)\n",
      "  adding: runs/obb/train4/weights/last.pt (deflated 9%)\n",
      "  adding: runs/obb/train4/weights/best.pt (deflated 9%)\n",
      "  adding: runs/obb/train4/confusion_matrix.png (deflated 25%)\n",
      "  adding: runs/obb/train4/train_batch23490.jpg (deflated 19%)\n",
      "  adding: runs/obb/train4/val_batch0_pred.jpg (deflated 19%)\n",
      "  adding: runs/obb/train4/labels_correlogram.jpg (deflated 38%)\n",
      "  adding: runs/obb/train4/train_batch2.jpg (deflated 13%)\n",
      "  adding: runs/obb/train4/confusion_matrix_normalized.png (deflated 25%)\n",
      "  adding: runs/obb/train4/results.csv (deflated 67%)\n",
      "  adding: runs/obb/train4/BoxR_curve.png (deflated 24%)\n",
      "  adding: runs/obb/train4/labels.jpg (deflated 34%)\n",
      "  adding: runs/obb/train4/train_batch23491.jpg (deflated 21%)\n",
      "  adding: runs/obb/train4/args.yaml (deflated 52%)\n",
      "  adding: runs/obb/train4/val_batch0_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/val2/ (stored 0%)\n",
      "  adding: runs/obb/val2/val_batch1_labels.jpg (deflated 17%)\n",
      "  adding: runs/obb/val2/val_batch2_pred.jpg (deflated 22%)\n",
      "  adding: runs/obb/val2/BoxPR_curve.png (deflated 22%)\n",
      "  adding: runs/obb/val2/BoxP_curve.png (deflated 19%)\n",
      "  adding: runs/obb/val2/val_batch2_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/val2/val_batch1_pred.jpg (deflated 19%)\n",
      "  adding: runs/obb/val2/BoxF1_curve.png (deflated 26%)\n",
      "  adding: runs/obb/val2/confusion_matrix.png (deflated 28%)\n",
      "  adding: runs/obb/val2/val_batch0_pred.jpg (deflated 24%)\n",
      "  adding: runs/obb/val2/confusion_matrix_normalized.png (deflated 29%)\n",
      "  adding: runs/obb/val2/BoxR_curve.png (deflated 26%)\n",
      "  adding: runs/obb/val2/val_batch0_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/val/ (stored 0%)\n",
      "  adding: runs/obb/val/val_batch1_labels.jpg (deflated 17%)\n",
      "  adding: runs/obb/val/val_batch2_pred.jpg (deflated 18%)\n",
      "  adding: runs/obb/val/BoxPR_curve.png (deflated 21%)\n",
      "  adding: runs/obb/val/BoxP_curve.png (deflated 15%)\n",
      "  adding: runs/obb/val/val_batch2_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/val/val_batch1_pred.jpg (deflated 15%)\n",
      "  adding: runs/obb/val/BoxF1_curve.png (deflated 23%)\n",
      "  adding: runs/obb/val/confusion_matrix.png (deflated 25%)\n",
      "  adding: runs/obb/val/val_batch0_pred.jpg (deflated 17%)\n",
      "  adding: runs/obb/val/confusion_matrix_normalized.png (deflated 25%)\n",
      "  adding: runs/obb/val/BoxR_curve.png (deflated 24%)\n",
      "  adding: runs/obb/val/val_batch0_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/train2/ (stored 0%)\n",
      "  adding: runs/obb/train2/val_batch1_labels.jpg (deflated 17%)\n",
      "  adding: runs/obb/train2/val_batch2_pred.jpg (deflated 22%)\n",
      "  adding: runs/obb/train2/BoxPR_curve.png (deflated 22%)\n",
      "  adding: runs/obb/train2/train_batch0.jpg (deflated 13%)\n",
      "  adding: runs/obb/train2/train_batch1.jpg (deflated 14%)\n",
      "  adding: runs/obb/train2/BoxP_curve.png (deflated 19%)\n",
      "  adding: runs/obb/train2/val_batch2_labels.jpg (deflated 19%)\n",
      "  adding: runs/obb/train2/val_batch1_pred.jpg (deflated 19%)\n",
      "  adding: runs/obb/train2/BoxF1_curve.png (deflated 26%)\n",
      "  adding: runs/obb/train2/results.png (deflated 7%)\n",
      "  adding: runs/obb/train2/weights/ (stored 0%)\n",
      "  adding: runs/obb/train2/weights/last.pt (deflated 9%)\n",
      "  adding: runs/obb/train2/weights/best.pt (deflated 9%)\n",
      "  adding: runs/obb/train2/confusion_matrix.png (deflated 28%)\n",
      "  adding: runs/obb/train2/val_batch0_pred.jpg (deflated 23%)\n",
      "  adding: runs/obb/train2/labels_correlogram.jpg (deflated 38%)\n",
      "  adding: runs/obb/train2/train_batch2.jpg (deflated 13%)\n",
      "  adding: runs/obb/train2/confusion_matrix_normalized.png (deflated 29%)\n",
      "  adding: runs/obb/train2/results.csv (deflated 63%)\n",
      "  adding: runs/obb/train2/BoxR_curve.png (deflated 26%)\n",
      "  adding: runs/obb/train2/labels.jpg (deflated 34%)\n",
      "  adding: runs/obb/train2/args.yaml (deflated 53%)\n",
      "  adding: runs/obb/train2/val_batch0_labels.jpg (deflated 19%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r yolov8_kld_exp.zip results1 results2 results3 results4 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r results1 results2 results3 results4 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
